import os
import json
import requests
import re
import hashlib
import sqlite3
import time
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_file, redirect, url_for, flash, session
from flask_cors import CORS
from flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user
from werkzeug.security import generate_password_hash, check_password_hash
import firebase_admin
from firebase_admin import credentials, auth as firebase_auth
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_ALIGN
from pptx.dml.color import RGBColor
from pptx.enum.shapes import MSO_AUTO_SHAPE_TYPE
from dotenv import load_dotenv
import uuid
import io
import stripe  # Stripe payment integration

# CLIP services for semantic image matching
try:
    from services.clip_client import is_clip_available, get_text_embedding
    from services.image_matcher import pick_best_image_for_slide as clip_pick_best_image
    CLIP_IMPORT_SUCCESS = True
except ImportError as e:
    print(f"‚ö†Ô∏è CLIP services import failed: {e}")
    print("   ‚Üí Install dependencies: pip install torch sentence-transformers")
    CLIP_IMPORT_SUCCESS = False
    clip_pick_best_image = None
    is_clip_available = lambda: False

TRANSLATION_CACHE = {}
CYRILLIC_RE = re.compile('[–∞-—è–ê-–Ø]')

# Load environment variables
load_dotenv()

app = Flask(__name__)
CORS(app)  # Enable CORS for cross-origin requests
app.secret_key = os.getenv('SECRET_KEY', 'your-secret-key-here-change-in-production')  # Needed for Flask-Login

# ============================================================================
# üö® CLIP INITIALIZATION - OPTIONAL FOR PRODUCTION
# ============================================================================
# For Railway deployment: CLIP dependencies are disabled to prevent crashes
# For local development: Install CLIP dependencies and enable

IS_RAILWAY = os.getenv('RAILWAY_ENVIRONMENT') is not None
CLIP_FORCE_DISABLE = os.getenv('CLIP_FORCE_DISABLE', 'false').lower() in ('true', '1', 'yes')

print("\n" + "="*70)
print("üîß CLIP INITIALIZATION CHECK")
print("="*70)
print(f"Environment: {'Railway (Production)' if IS_RAILWAY else 'Local Development'}")
print(f"CLIP Force Disable: {CLIP_FORCE_DISABLE}")

if IS_RAILWAY or CLIP_FORCE_DISABLE:
    print("\n‚ö†Ô∏è  CLIP DISABLED for this environment")
    print("   ‚Üí Running in production mode without CLIP")
    print("   ‚Üí Image search will use keyword-based matching only")
    print("="*70 + "\n")
    
    CLIP_AVAILABLE = False
    CLIP_IMPORT_SUCCESS = False
    
else:
    print("\nüîÑ Attempting CLIP initialization...")
    print("   (This may take a minute on first run)\n")
    
    try:
        # STEP 1: Check PyTorch
        print("[1/5] Checking PyTorch...")
        import torch
        print(f"   ‚úÖ PyTorch version: {torch.__version__}")
        print(f"   ‚úÖ CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   ‚úÖ CUDA version: {torch.version.cuda}")
            print(f"   ‚úÖ GPU device: {torch.cuda.get_device_name(0)}")
            target_device = "CUDA"
        else:
            print(f"   ‚ö†Ô∏è  CUDA not available, using CPU")
            target_device = "CPU"
        
        # STEP 2: Check CLIP library
        print("\n[2/5] Checking CLIP library...")
        import clip
        print(f"   ‚úÖ CLIP library imported successfully")
        
        # STEP 3: Force load CLIP model
        print(f"\n[3/5] üî• Loading CLIP model (ViT-B/32 on {target_device})...")
        
        clip_load_start = time.perf_counter()
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # Import clip_client and force initialization
        from services import clip_client
        
        # Force model load
        print(f"   ‚Üí Loading model to {device.upper()}...")
        clip_client._device = device
        model, preprocess = clip.load("ViT-B/32", device=device)
        model.eval()
        
        # Set global variables
        clip_client._clip_model = model
        clip_client._clip_preprocess = preprocess
        clip_client._clip_available = True
        
        clip_load_time = time.perf_counter() - clip_load_start
        
        print(f"   ‚úÖ CLIP model loaded successfully!")
        print(f"   ‚è±Ô∏è  Load time: {clip_load_time:.2f}s")
        
        # STEP 4: Load image cache
        print("\n[4/5] Loading image embedding cache...")
        clip_client._load_image_cache()
        cache_size = len(clip_client._image_embedding_cache)
        print(f"   ‚úÖ Loaded {cache_size} cached embeddings")
        
        # STEP 5: Verify model is working
        print("\n[5/5] Testing CLIP functionality...")
        test_text = clip.tokenize(["test"]).to(device)
        with torch.no_grad():
            test_features = model.encode_text(test_text)
        print(f"   ‚úÖ CLIP is functional (test embedding: {test_features.shape})")
        
        # SUCCESS!
        print("\n" + "="*70)
        print("üéØ CLIP INITIALIZATION COMPLETE - ALL SYSTEMS GO!")
        print("="*70)
        print(f"   üß† Model: ViT-B/32")
        print(f"   üíª Device: {device.upper()}")
        print(f"   üìä Embedding dim: 512")
        print(f"   üíæ Cached embeddings: {cache_size}")
        print(f"   ‚è±Ô∏è  Total init time: {clip_load_time:.2f}s")
        print("="*70 + "\n")
        
        # Set global flags
        CLIP_AVAILABLE = True
        CLIP_IMPORT_SUCCESS = True
        
    except ImportError as e:
        print("\n" + "="*70)
        print("‚ö†Ô∏è  CLIP DEPENDENCIES NOT AVAILABLE")
        print("="*70)
        print(f"Import Error: {e}\n")
        print("‚Üí Running without CLIP (keyword-based image search only)")
        print("‚Üí For CLIP support, install: torch, torchvision, sentence-transformers")
        print("="*70 + "\n")
        
        CLIP_AVAILABLE = False
        CLIP_IMPORT_SUCCESS = False
        
    except Exception as e:
        print("\n" + "="*70)
        print("‚ö†Ô∏è  CLIP INITIALIZATION FAILED")
        print("="*70)
        print(f"Error type: {type(e).__name__}")
        print(f"Error message: {e}\n")
        print("Full traceback:")
        print("‚îÄ" * 70)
        import traceback
        traceback.print_exc()
        print("‚îÄ" * 70)
        print("\n‚Üí Running without CLIP (keyword-based image search only)")
        print("="*70 + "\n")
        
        CLIP_AVAILABLE = False
        CLIP_IMPORT_SUCCESS = False

# ============================================================================
# CLIP CONFIGURATION
# ============================================================================
CLIP_ENABLED = CLIP_AVAILABLE  # Based on initialization result
CLIP_SIMILARITY_THRESHOLD = float(os.getenv('CLIP_SIMILARITY_THRESHOLD', '0.30'))
CLIP_MIN_CANDIDATES = int(os.getenv('CLIP_MIN_CANDIDATES', '8'))
CLIP_MAX_CANDIDATES = int(os.getenv('CLIP_MAX_CANDIDATES', '20'))

print("\n" + "="*70)
print("ü§ñ CLIP CONFIGURATION")
print("="*70)
print(f"CLIP_ENABLED: {CLIP_ENABLED}")
print(f"CLIP_AVAILABLE: {CLIP_AVAILABLE}")
print(f"CLIP_SIMILARITY_THRESHOLD: {CLIP_SIMILARITY_THRESHOLD}")
print(f"CLIP_MIN_CANDIDATES: {CLIP_MIN_CANDIDATES}")
print(f"CLIP_MAX_CANDIDATES: {CLIP_MAX_CANDIDATES}")
if not CLIP_AVAILABLE:
    print("\n‚ö†Ô∏è  Image search will use keyword-based matching only")
print("="*70 + "\n")

# ============================================================================
# TRANSLATION CONFIGURATION (Universal Layer)
# ============================================================================
# Universal translation layer for image search queries
# Supports multiple providers and can be enabled/disabled independently

# Main toggle for translation
TRANSLATION_ENABLED = os.getenv('TRANSLATION_ENABLED', 'false').lower() in ('true', '1', 'yes')

# Translation provider: 'none', 'libre', 'external'
TRANSLATION_PROVIDER = os.getenv('TRANSLATION_PROVIDER', 'none').lower()

# Target language for image searches (usually 'en' for better stock photo results)
TRANSLATION_TARGET_LANG = os.getenv('TRANSLATION_TARGET_LANG', 'en')

# LibreTranslate configuration (used when TRANSLATION_PROVIDER='libre')
LIBRETRANSLATE_URL = os.getenv('LIBRETRANSLATE_URL', 'http://localhost:5001')
LIBRETRANSLATE_TIMEOUT = int(os.getenv('LIBRETRANSLATE_TIMEOUT', '10'))

# External translation service configuration (used when TRANSLATION_PROVIDER='external')
EXTERNAL_TRANSLATE_URL = os.getenv('EXTERNAL_TRANSLATE_URL', '')
EXTERNAL_TRANSLATE_API_KEY = os.getenv('EXTERNAL_TRANSLATE_API_KEY', '')
EXTERNAL_TRANSLATE_TIMEOUT = float(os.getenv('EXTERNAL_TRANSLATE_TIMEOUT', '5.0'))

print("="*70)
print("üåê TRANSLATION CONFIGURATION (Image Search)")
print("="*70)
print(f"TRANSLATION_ENABLED: {TRANSLATION_ENABLED}")
print(f"TRANSLATION_PROVIDER: {TRANSLATION_PROVIDER}")
print(f"TRANSLATION_TARGET_LANG: {TRANSLATION_TARGET_LANG}")

if not TRANSLATION_ENABLED:
    print("‚ö†Ô∏è Translation DISABLED for image search")
    print("   ‚Üí Using original text for all image queries")
    print("   ‚Üí Relying on CLIP semantic matching + multilingual photo stocks")
elif TRANSLATION_PROVIDER == 'none':
    print("‚ÑπÔ∏è Translation enabled but provider set to 'none'")
    print("   ‚Üí No actual translation will occur")
    print("   ‚Üí Using original text (same as TRANSLATION_ENABLED=false)")
elif TRANSLATION_PROVIDER == 'libre':
    print(f"‚úÖ Translation provider: LibreTranslate")
    print(f"   ‚Üí LibreTranslate URL: {LIBRETRANSLATE_URL}")
    print(f"   ‚Üí Target language: {TRANSLATION_TARGET_LANG}")
    print("   ‚Üí Note: Ensure LibreTranslate service is running")
elif TRANSLATION_PROVIDER == 'external':
    if EXTERNAL_TRANSLATE_URL:
        print(f"‚úÖ Translation provider: External API")
        print(f"   ‚Üí External URL: {EXTERNAL_TRANSLATE_URL}")
        print(f"   ‚Üí Target language: {TRANSLATION_TARGET_LANG}")
        print(f"   ‚Üí Timeout: {EXTERNAL_TRANSLATE_TIMEOUT}s")
    else:
        print("‚ö†Ô∏è Translation provider set to 'external' but EXTERNAL_TRANSLATE_URL not configured")
        print("   ‚Üí Falling back to original text")
else:
    print(f"‚ö†Ô∏è Unknown translation provider: '{TRANSLATION_PROVIDER}'")
    print("   ‚Üí Valid values: none, libre, external")
    print("   ‚Üí Falling back to original text")

print("="*70 + "\n")

# ============================================================================
# IMAGE SEARCH MODE CONFIGURATION
# ============================================================================
# Control image search behavior: legacy (stable) vs advanced (experimental)

# USE_IMAGE_PROMPT: Whether to use LLM-generated image_prompt field
# - false (default): Legacy mode - ignores image_prompt, uses search_keyword/title/content
# - true: Advanced mode - uses image_prompt for better search queries
USE_IMAGE_PROMPT = os.getenv('USE_IMAGE_PROMPT', 'false').lower() in ('true', '1', 'yes')

# USE_STRICT_CLIP_FILTER: Whether CLIP should block images below threshold
# - false (default): Soft mode - CLIP only ranks, always picks best candidate
# - true: Strict mode - CLIP rejects images below CLIP_SIMILARITY_THRESHOLD
USE_STRICT_CLIP_FILTER = os.getenv('USE_STRICT_CLIP_FILTER', 'false').lower() in ('true', '1', 'yes')

print("="*70)
print("üñºÔ∏è  IMAGE SEARCH MODE")
print("="*70)
print(f"USE_IMAGE_PROMPT: {USE_IMAGE_PROMPT}")
print(f"USE_STRICT_CLIP_FILTER: {USE_STRICT_CLIP_FILTER}")

if not USE_IMAGE_PROMPT and not USE_STRICT_CLIP_FILTER:
    print("üìå Mode: LEGACY (stable, production-ready)")
    print("   ‚Üí Uses search_keyword/title/content for queries")
    print("   ‚Üí CLIP only ranks candidates (no threshold blocking)")
    print("   ‚Üí Maximum stability across RU/EN languages")
elif USE_IMAGE_PROMPT and not USE_STRICT_CLIP_FILTER:
    print("üìå Mode: ADVANCED with soft CLIP")
    print("   ‚Üí Uses image_prompt when available")
    print("   ‚Üí CLIP ranks but doesn't block images")
    print("   ‚Üí Better quality with legacy fallback")
elif not USE_IMAGE_PROMPT and USE_STRICT_CLIP_FILTER:
    print("üìå Mode: LEGACY with strict CLIP")
    print("   ‚Üí Uses search_keyword/title/content")
    print("   ‚Üí CLIP can reject images below threshold")
    print("   ‚Üí May skip images if relevance is low")
else:  # Both enabled
    print("üìå Mode: ADVANCED (experimental)")
    print("   ‚Üí Uses image_prompt for queries")
    print("   ‚Üí CLIP strictly filters by threshold")
    print("   ‚Üí Best quality but may fail more often")
    print("   ‚Üí Recommended only after thorough testing")

print("="*70 + "\n")

# ============================================================================
# DEVELOPMENT MODE CONFIGURATION
# ============================================================================
# Toggle payment verification for development/testing
# Set PAYMENTS_ENABLED=false in .env to disable payment checks
PAYMENTS_ENABLED = os.getenv('PAYMENTS_ENABLED', 'true').lower() in ('true', '1', 'yes')

if not PAYMENTS_ENABLED:
    print("‚ö†Ô∏è  ========================================")
    print("‚ö†Ô∏è  [DEV MODE] PAYMENTS DISABLED")
    print("‚ö†Ô∏è  All payment checks will be bypassed")
    print("‚ö†Ô∏è  This should ONLY be used for development/testing")
    print("‚ö†Ô∏è  Set PAYMENTS_ENABLED=true for production")
    print("‚ö†Ô∏è  ========================================")
else:
    print("‚úÖ Payment verification: ENABLED (production mode)")

# ============================================================================
# Stripe Configuration
# ============================================================================
# Initialize Stripe with secret key from environment
STRIPE_SECRET_KEY = os.getenv('STRIPE_SECRET_KEY')
STRIPE_WEBHOOK_SECRET = os.getenv('STRIPE_WEBHOOK_SECRET')

if STRIPE_SECRET_KEY:
    stripe.api_key = STRIPE_SECRET_KEY
    print("‚úÖ Stripe initialized successfully")
    print(f"   ‚Üí API Key: {STRIPE_SECRET_KEY[:7]}...{STRIPE_SECRET_KEY[-4:]}")
else:
    print("‚ö†Ô∏è Stripe not configured: STRIPE_SECRET_KEY not found")
    print("   ‚Üí Payment features will NOT work")

if STRIPE_WEBHOOK_SECRET:
    print("‚úÖ Stripe webhook secret configured")
else:
    print("‚ö†Ô∏è STRIPE_WEBHOOK_SECRET not configured")
    print("   ‚Üí Webhook signature verification will be skipped (INSECURE for production)")

# ============================================================================
# Firebase Admin SDK Initialization
# ============================================================================
# This section initializes Firebase Admin SDK for server-side authentication
# The SDK requires a service account key JSON file for secure communication
# with Firebase services

# Global flag to track Firebase initialization status
FIREBASE_INITIALIZED = False

try:
    # Step 1: Get service account key path from environment or use default
    firebase_cred_path = os.getenv('FIREBASE_SERVICE_ACCOUNT_KEY', 'serviceAccountKey.json')
    print(f"üîç Checking Firebase service account key at: {firebase_cred_path}")
    
    # Step 2: Verify that the service account key file exists
    if not os.path.exists(firebase_cred_path):
        raise FileNotFoundError(f"Service account key not found at: {firebase_cred_path}")
    
    # Step 3: Validate JSON format and required fields with explicit UTF-8 encoding
    with open(firebase_cred_path, 'r', encoding='utf-8') as f:
        key_data = json.load(f)
        required_fields = ['type', 'project_id', 'private_key_id', 'private_key', 'client_email']
        missing_fields = [field for field in required_fields if field not in key_data]
        
        if missing_fields:
            raise ValueError(f"Service account key missing required fields: {missing_fields}")
        
        if key_data.get('type') != 'service_account':
            raise ValueError(f"Invalid key type: expected 'service_account', got '{key_data.get('type')}'")
        
        print(f"‚úÖ Service account key validated: Project ID = {key_data.get('project_id')}")
    
    # Step 4: Initialize Firebase Admin SDK with credentials
    # Check if already initialized to prevent reinitialization errors
    if not firebase_admin._apps:
        cred = credentials.Certificate(firebase_cred_path)
        firebase_admin.initialize_app(cred)
        FIREBASE_INITIALIZED = True
        
        print("‚úÖ Firebase Admin SDK initialized successfully")
        print("   ‚Üí Token verification: ENABLED")
        print("   ‚Üí User authentication: READY")
    else:
        print("‚ÑπÔ∏è Firebase Admin SDK already initialized")
        FIREBASE_INITIALIZED = True
    
except FileNotFoundError as e:
    print(f"‚ö†Ô∏è Firebase initialization failed: {e}")
    print("   ‚Üí Firebase authentication will NOT work")
    print("   ‚Üí Please add serviceAccountKey.json to project root")
    print("   ‚Üí Download from: Firebase Console ‚Üí Project Settings ‚Üí Service Accounts")
    FIREBASE_INITIALIZED = False
    
except ValueError as e:
    print(f"‚ö†Ô∏è Firebase initialization failed: {e}")
    print("   ‚Üí Invalid or corrupted service account key")
    print("   ‚Üí Please download a new key from Firebase Console")
    FIREBASE_INITIALIZED = False
    
except Exception as e:
    print(f"‚ö†Ô∏è Firebase initialization error: {e}")
    print(f"   ‚Üí Error type: {type(e).__name__}")
    print("   ‚Üí Firebase authentication may not work correctly")
    FIREBASE_INITIALIZED = False

# Initialize Flask-Login
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'admin_login'
login_manager.login_message = 'Please log in to access this page.'

# Simple admin user storage
ADMIN_USERS = {
    'admin': {
        'password_hash': generate_password_hash(os.getenv('ADMIN_PASSWORD', 'admin123')),
        'id': 'admin'
    }
}

class User(UserMixin):
    def __init__(self, user_id, email=None, is_admin_user=False, name=None, picture=None):
        self.id = user_id
        self.email = email
        self.is_admin_user = is_admin_user
        self.name = name or email
        self.picture = picture

    def is_admin(self):
        return self.is_admin_user

# Lookup user by ID from SQLite
def get_user_by_id(user_id):
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute('SELECT id, email, name, picture, status FROM users WHERE id = ?', (user_id,))
        row = cursor.fetchone()
        conn.close()
        return dict(row) if row else None
    except Exception as e:
        print(f"Error fetching user by id: {e}")
        return None

@login_manager.user_loader
def load_user(user_id):
    # Admin shortcut
    if user_id in ADMIN_USERS:
        return User(user_id, is_admin_user=True)
    # Regular user
    try:
        int_id = int(user_id)
    except (ValueError, TypeError):
        return None
    user_data = get_user_by_id(int_id)
    if not user_data:
        return None
    return User(
        user_data['id'],
        email=user_data.get('email'),
        is_admin_user=False,
        name=user_data.get('name'),
        picture=user_data.get('picture')
    )

# Helper functions for Firebase user management
def get_or_create_firebase_user(firebase_uid, email, name='', picture=''):
    """
    Get existing user by Firebase UID or create new one
    Returns (user_data, error)
    """
    conn = None
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # Try to find user by Firebase UID
        cursor.execute('SELECT * FROM users WHERE firebase_uid = ?', (firebase_uid,))
        user = cursor.fetchone()
        
        if user:
            # User exists, return their data
            return dict(user), None
        
        # Check if user exists by email (migrating from email/password auth)
        cursor.execute('SELECT * FROM users WHERE email = ?', (email,))
        user = cursor.fetchone()
        
        if user:
            # Update existing user with Firebase UID
            cursor.execute(
                'UPDATE users SET firebase_uid = ?, name = ?, picture = ? WHERE email = ?',
                (firebase_uid, name, picture, email)
            )
            conn.commit()
            cursor.execute('SELECT * FROM users WHERE email = ?', (email,))
            user = cursor.fetchone()
            return dict(user), None
        
        # Create new user
        cursor.execute(
            '''INSERT INTO users (email, firebase_uid, name, picture, status, free_credits)
               VALUES (?, ?, ?, ?, 'active', 3)''',
            (email, firebase_uid, name, picture)
        )
        conn.commit()
        user_id = cursor.lastrowid
        
        print(f"‚úÖ New Firebase user created: {email} (ID: {user_id})")
        print(f"   ‚Üí Free credits: 3 presentations")
        
        cursor.execute('SELECT * FROM users WHERE id = ?', (user_id,))
        user = cursor.fetchone()
        return dict(user), None
        
    except sqlite3.Error as e:
        if conn:
            conn.rollback()
        print(f"Database error in get_or_create_firebase_user: {e}")
        return None, f"Database error: {str(e)}"
    except Exception as e:
        if conn:
            conn.rollback()
        print(f"Error in get_or_create_firebase_user: {e}")
        return None, str(e)
    finally:
        if conn:
            conn.close()

# Helper functions for email/password authentication
def validate_email(email):
    """
    Validate email format
    Returns (is_valid, error_message)
    """
    if not email or len(email) < 3:
        return False, "Email is too short"
    if '@' not in email or '.' not in email:
        return False, "Invalid email format"
    if len(email) > 255:
        return False, "Email is too long"
    return True, None

def validate_password(password):
    """
    Validate password strength
    Returns (is_valid, error_message)
    """
    if not password or len(password) < 6:
        return False, "Password must be at least 6 characters"
    if len(password) > 128:
        return False, "Password is too long"
    return True, None

def create_user(email, password):
    """
    Create new user with email and password
    Returns (user_id, error)
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Check if user already exists
        cursor.execute('SELECT id FROM users WHERE email = ?', (email,))
        if cursor.fetchone():
            conn.close()
            return None, "User with this email already exists"
        
        # Create user
        password_hash = generate_password_hash(password)
        cursor.execute(
            '''INSERT INTO users (email, password_hash, status, free_credits)
               VALUES (?, ?, 'active', 3)''',
            (email, password_hash)
        )
        conn.commit()
        user_id = cursor.lastrowid
        conn.close()
        
        print(f"‚úÖ New user created: {email} (ID: {user_id})")
        print(f"   ‚Üí Free credits: 3 presentations")
        
        return user_id, None
        
    except Exception as e:
        print(f"Error creating user: {e}")
        return None, "Failed to create user"

def authenticate_user(email, password):
    """
    Authenticate user with email and password
    Returns (user_data, error)
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM users WHERE email = ?', (email,))
        user = cursor.fetchone()
        conn.close()
        
        if not user:
            return None, "Invalid email or password"
        
        if not user['password_hash']:
            return None, "Please sign in with Firebase/Google"
        
        if not check_password_hash(user['password_hash'], password):
            return None, "Invalid email or password"
        
        if user['status'] == 'blocked':
            return None, "Your account has been blocked"
        
        return dict(user), None
        
    except Exception as e:
        print(f"Error authenticating user: {e}")
        return None, "Authentication failed"

# Admin helper functions
def get_all_users():
    """
    Get all users from database
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM users ORDER BY registration_date DESC')
        users = [dict(row) for row in cursor.fetchall()]
        conn.close()
        return users
    except Exception as e:
        print(f"Error fetching users: {e}")
        return []

def update_user_status(user_id, status):
    """
    Update user status (active/blocked)
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute('UPDATE users SET status = ? WHERE id = ?', (status, user_id))
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"Error updating user status: {e}")
        return False

def delete_user(user_id):
    """
    Delete user and their presentations
    """
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        # Delete user's presentations first
        cursor.execute('DELETE FROM presentations WHERE user_id = ?', (user_id,))
        # Delete user
        cursor.execute('DELETE FROM users WHERE id = ?', (user_id,))
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"Error deleting user: {e}")
        return False

# API Keys from environment variables
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
PEXELS_API_KEY = os.getenv('PEXELS_API_KEY')
UNSPLASH_ACCESS_KEY = os.getenv('UNSPLASH_ACCESS_KEY')  # Added Unsplash support

# ============================================================================
# IMAGE PROVIDER CONFIGURATION
# ============================================================================
# Configure image provider strategy: 'pexels', 'unsplash', or 'mixed'
# - 'pexels': Only use Pexels API
# - 'unsplash': Only use Unsplash API  
# - 'mixed': Try Pexels first, fallback to Unsplash (recommended)
IMAGE_PROVIDER_MODE = os.getenv('IMAGE_PROVIDER_MODE', 'mixed').lower()

# Configuration
OUTPUT_DIR = 'output'
IMAGE_CACHE_DIR = 'image_cache'

if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
if not os.path.exists(IMAGE_CACHE_DIR):
    os.makedirs(IMAGE_CACHE_DIR)

# Initialize SQLite database for users
DB_PATH = 'users.db'

def init_db():
    """Initialize the database with users table"""
    conn = None
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Create users table
        # Note: firebase_uid is added via migration below, not in CREATE TABLE
        # to avoid conflicts with existing databases
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                email TEXT UNIQUE NOT NULL,
                password_hash TEXT,
                google_id TEXT UNIQUE,
                name TEXT,
                picture TEXT,
                status TEXT DEFAULT 'active',
                registration_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Create presentations table to track user activity
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS presentations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                topic TEXT NOT NULL,
                num_slides INTEGER,
                filename TEXT,
                presentation_type TEXT DEFAULT 'business',
                creation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (id)
            )
        ''')
        
        # Create table to track used images (prevent duplicates)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS used_images (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                image_url TEXT NOT NULL,
                image_query TEXT,
                used_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users (id)
            )
        ''')
        
        # Create index for faster image lookups
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index' AND name='idx_used_images_user'")
        if not cursor.fetchone():
            try:
                cursor.execute('CREATE INDEX idx_used_images_user ON used_images(user_id, image_url)')
                print("‚úÖ Migration: Created index on used_images table")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: idx_used_images_user index may already exist - {e}")
        
        # Migration: Add missing columns to users table
        # Safe pattern: check column existence before adding to avoid errors
        cursor.execute("PRAGMA table_info(users)")
        existing_columns = [column[1] for column in cursor.fetchall()]
        
        # Add firebase_uid column if missing
        if 'firebase_uid' not in existing_columns:
            try:
                cursor.execute('ALTER TABLE users ADD COLUMN firebase_uid TEXT')
                print("‚úÖ Migration: Added firebase_uid column to users table")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: firebase_uid column may already exist - {e}")
        
        # Add name column if missing
        if 'name' not in existing_columns:
            try:
                cursor.execute('ALTER TABLE users ADD COLUMN name TEXT')
                print("‚úÖ Migration: Added name column to users table")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: name column may already exist - {e}")
        
        # Add picture column if missing
        if 'picture' not in existing_columns:
            try:
                cursor.execute('ALTER TABLE users ADD COLUMN picture TEXT')
                print("‚úÖ Migration: Added picture column to users table")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: picture column may already exist - {e}")
        
        # Add google_id column if missing (for backward compatibility)
        if 'google_id' not in existing_columns:
            try:
                cursor.execute('ALTER TABLE users ADD COLUMN google_id TEXT')
                print("‚úÖ Migration: Added google_id column to users table")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: google_id column may already exist - {e}")
        
        # Create unique index on firebase_uid if it doesn't exist
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index' AND name='idx_firebase_uid'")
        if not cursor.fetchone():
            try:
                cursor.execute('CREATE UNIQUE INDEX idx_firebase_uid ON users(firebase_uid)')
                print("‚úÖ Migration: Created unique index on firebase_uid column")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: idx_firebase_uid index may already exist - {e}")
        
        # Migration: Add presentation_type column if it doesn't exist
        cursor.execute("PRAGMA table_info(presentations)")
        columns = [column[1] for column in cursor.fetchall()]
        if 'presentation_type' not in columns:
            cursor.execute('ALTER TABLE presentations ADD COLUMN presentation_type TEXT DEFAULT "business"')
            print("‚úÖ Migration: Added presentation_type column to presentations table")
        
        # Migration: Add Stripe-related columns to users table
        cursor.execute("PRAGMA table_info(users)")
        existing_columns = [column[1] for column in cursor.fetchall()]
        
        # Add stripe_customer_id column if missing
        if 'stripe_customer_id' not in existing_columns:
            try:
                cursor.execute('ALTER TABLE users ADD COLUMN stripe_customer_id TEXT')
                print("‚úÖ Migration: Added stripe_customer_id column to users table")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: stripe_customer_id column may already exist - {e}")
        
        # Add subscription_plan column if missing
        if 'subscription_plan' not in existing_columns:
            try:
                cursor.execute('ALTER TABLE users ADD COLUMN subscription_plan TEXT DEFAULT "free"')
                print("‚úÖ Migration: Added subscription_plan column to users table")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: subscription_plan column may already exist - {e}")
        
        # Add subscription_status column if missing
        if 'subscription_status' not in existing_columns:
            try:
                cursor.execute('ALTER TABLE users ADD COLUMN subscription_status TEXT DEFAULT "inactive"')
                print("‚úÖ Migration: Added subscription_status column to users table")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: subscription_status column may already exist - {e}")
        
        # Migration: Add free_credits column to users table (3 free presentations for new users)
        if 'free_credits' not in existing_columns:
            try:
                cursor.execute('ALTER TABLE users ADD COLUMN free_credits INTEGER NOT NULL DEFAULT 3')
                print("‚úÖ Migration: Added free_credits column to users table")
                print("   ‚Üí New users will get 3 free presentations")
            except sqlite3.OperationalError as e:
                print(f"‚ö†Ô∏è Migration: free_credits column may already exist - {e}")
        
        conn.commit()
        
    except sqlite3.Error as e:
        print(f"‚ùå Database initialization error: {e}")
        if conn:
            conn.rollback()
        raise
    except Exception as e:
        print(f"‚ùå Unexpected error during database initialization: {e}")
        if conn:
            conn.rollback()
        raise
    finally:
        if conn:
            conn.close()

# Initialize database on startup
init_db()

# Presentation types configuration
# Presentation types configuration - REFACTORED TO 3 TYPES
PRESENTATION_TYPES = {
    'business': {
        'name_ru': '–î–µ–ª–æ–≤–∞—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è',
        'name_en': 'Business Presentation',
        'icon': 'üíº',
        'color': '#667eea',
        'temperature': 0.6,  # Confident, professional tone
        'structure': [
            {'title': '–¢–∏—Ç—É–ª—å–Ω—ã–π —Å–ª–∞–π–¥', 'description': '–ù–∞–∑–≤–∞–Ω–∏–µ, –∫–æ–º–ø–∞–Ω–∏—è, –∫–æ–Ω—Ç–µ–∫—Å—Ç'},
            {'title': '–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø—Ä–æ–±–ª–µ–º–∞', 'description': '–¢–µ–∫—É—â–∞—è —Å–∏—Ç—É–∞—Ü–∏—è, –≤—ã–∑–æ–≤—ã'},
            {'title': '–ù–∞—à–µ —Ä–µ—à–µ–Ω–∏–µ/–ø—Ä–æ–¥—É–∫—Ç', 'description': '–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ'},
            {'title': '–¶–µ–Ω–Ω–æ—Å—Ç—å –∏ –≤—ã–≥–æ–¥—ã', 'description': '–ö–∞–∫—É—é –ø–æ–ª—å–∑—É –ø—Ä–∏–Ω–æ—Å–∏—Ç'},
            {'title': '–ö–ª—é—á–µ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏', 'description': '–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏'},
            {'title': '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã/–∫–µ–π—Å—ã', 'description': '–î–æ—Å—Ç–∏–∂–µ–Ω–∏—è, –ø—Ä–∏–º–µ—Ä—ã'},
            {'title': '–ü–ª–∞–Ω/–¥–æ—Ä–æ–∂–Ω–∞—è –∫–∞—Ä—Ç–∞', 'description': '–ü–ª–∞–Ω—ã —Ä–∞–∑–≤–∏—Ç–∏—è'},
            {'title': '–ö–æ–º–∞–Ω–¥–∞/—Ä–µ—Å—É—Ä—Å—ã', 'description': '–ö—Ç–æ —Ä–µ–∞–ª–∏–∑—É–µ—Ç'},
            {'title': '–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏/CTA', 'description': '–ü—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é'},
            {'title': '–ö–æ–Ω—Ç–∞–∫—Ç—ã', 'description': '–ö–∞–∫ —Å–≤—è–∑–∞—Ç—å—Å—è'}
        ],
        'tips': '–î–µ–ª–æ–≤–æ–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Ç–æ–Ω –±–µ–∑ –ø–∞—Ñ–æ—Å–∞. –ü—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫ –¥–ª—è –±–∏–∑–Ω–µ—Å-–∞—É–¥–∏—Ç–æ—Ä–∏–∏. –§–æ–∫—É—Å –Ω–∞ —Ñ–∞–∫—Ç–∞—Ö –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö.'
    },
    'scientific': {
        'name_ru': '–ù–∞—É—á–Ω–∞—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è',
        'name_en': 'Scientific Presentation',
        'icon': 'üî¨',
        'color': '#27ae60',
        'temperature': 0.2,  # Academic, formal, highly detailed and precise
        'structure': [
            {'title': '–¢–∏—Ç—É–ª –∏ —Ç–µ–º–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è', 'description': '–ù–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã'},
            {'title': '–í–≤–µ–¥–µ–Ω–∏–µ –∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å', 'description': '–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ'},
            {'title': '–û–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã', 'description': '–ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–∞–±–æ—Ç—ã'},
            {'title': '–¶–µ–ª—å –∏ –∑–∞–¥–∞—á–∏', 'description': '–ß—Ç–æ –∏—Å—Å–ª–µ–¥—É–µ–º'},
            {'title': '–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è', 'description': '–ö–∞–∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞–ª–∏'},
            {'title': '–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', 'description': '–î–∞–Ω–Ω—ã–µ –∏ —Ü–∏—Ñ—Ä—ã'},
            {'title': '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ', 'description': '–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'},
            {'title': '–í—ã–≤–æ–¥—ã', 'description': '–ì–ª–∞–≤–Ω—ã–µ –∑–∞–∫–ª—é—á–µ–Ω–∏—è'},
            {'title': '–î–∞–ª—å–Ω–µ–π—à–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è', 'description': '–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã'},
            {'title': '–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏', 'description': '–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞'}
        ],
        'tips': '–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å. –û—Å—Ç–æ—Ä–æ–∂–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ ("–ø–æ –¥–∞–Ω–Ω—ã–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π", "—Å–æ–≥–ª–∞—Å–Ω–æ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ"). –ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏, –º–∏–Ω–∏–º—É–º —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.'
    },
    'general': {
        'name_ru': '–û–±—â–∞—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è',
        'name_en': 'General Presentation',
        'icon': 'üìä',
        'color': '#3498db',
        'temperature': 0.7,  # Friendly, explaining tone
        'structure': [
            {'title': '–¢–∏—Ç—É–ª—å–Ω—ã–π —Å–ª–∞–π–¥', 'description': '–¢–µ–º–∞ –∏ —Ü–µ–ª–∏'},
            {'title': '–ü–æ—á–µ–º—É —Ç–µ–º–∞ –≤–∞–∂–Ω–∞', 'description': '–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏ –∑–Ω–∞—á–∏–º–æ—Å—Ç—å'},
            {'title': '–ö–ª—é—á–µ–≤—ã–µ –ø–æ–Ω—è—Ç–∏—è', 'description': '–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã'},
            {'title': '–û—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏', 'description': '–ì–ª–∞–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã'},
            {'title': '–ü—Ä–∏–º–µ—Ä—ã –∏–∑ –∂–∏–∑–Ω–∏', 'description': '–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∫–µ–π—Å—ã'},
            {'title': '–ü–æ—à–∞–≥–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ', 'description': '–î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä'},
            {'title': '–¢–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏', 'description': '–ß–µ–≥–æ –∏–∑–±–µ–≥–∞—Ç—å'},
            {'title': '–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ', 'description': '–û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã'},
            {'title': '–í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏', 'description': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π'},
            {'title': '–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã', 'description': '–î–ª—è —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è'}
        ],
        'tips': '–î—Ä—É–∂–µ–ª—é–±–Ω—ã–π –æ–±—ä—è—Å–Ω—è—é—â–∏–π —Å—Ç–∏–ª—å. –ú–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ –ø—Ä–æ—Å—Ç—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫. –Ø–∑—ã–∫ –¥–æ—Å—Ç—É–ø–Ω—ã–π –¥–ª—è —à–∏—Ä–æ–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏.'
    }
}

# Supported languages
SUPPORTED_LANGUAGES = {
    'ru': 'Russian',
    'en': 'English',
    'es': 'Spanish',
    'zh': 'Chinese',
    'fr': 'French'
}

# AI role prompts per presentation type and language - REFACTORED TO 3 TYPES
def get_ai_role_prompt(presentation_type, language):
    """Get AI system role prompt based on presentation type and language"""
    prompts = {
        'business': {
            'ru': "–¢—ã –æ–ø—ã—Ç–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –∏ —Å—Ç—Ä–∞—Ç–µ–≥. –°–æ–∑–¥–∞–π –¥–µ–ª–æ–≤—É—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –æ –∫–æ–º–ø–∞–Ω–∏–∏, –ø—Ä–æ–¥—É–∫—Ç–µ –∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö. –ò—Å–ø–æ–ª—å–∑—É–π –¥–µ–ª–æ–≤–æ–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Ç–æ–Ω –±–µ–∑ –ø–∞—Ñ–æ—Å–∞, –ø—Ä–æ—Å—Ç–æ–π —è–∑—ã–∫ –¥–ª—è –±–∏–∑–Ω–µ—Å-–∞—É–¥–∏—Ç–æ—Ä–∏–∏. –§–æ–∫—É—Å –Ω–∞ —Ñ–∞–∫—Ç–∞—Ö, –¥–∞–Ω–Ω—ã—Ö, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö.",
            'en': "You are an experienced business consultant and strategist. Create a business presentation about company, product or results. Use confident professional tone without hype, simple language for business audience. Focus on facts, data, and concrete results.",
            'es': "Eres un consultor empresarial experimentado. Crea una presentaci√≥n empresarial profesional en espa√±ol con tono confiado y lenguaje simple.",
            'zh': "‰Ω†ÊòØÁªèÈ™å‰∏∞ÂØåÁöÑÂïÜ‰∏öÈ°æÈóÆ„ÄÇËØ∑Áî®‰∏≠ÊñáÂàõÂª∫‰∏ì‰∏öÁöÑÂïÜÂä°ÊºîÁ§∫ÊñáÁ®øÔºå‰ΩøÁî®Ëá™‰ø°ÁöÑËØ≠Ë∞É„ÄÇ",
            'fr': "Vous √™tes un consultant en affaires exp√©riment√©. Cr√©ez une pr√©sentation professionnelle en fran√ßais avec un ton confiant."
        },
        'scientific': {
            'ru': "–¢—ã –Ω–∞—É—á–Ω—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å —Å –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–º –æ–ø—ã—Ç–æ–º. –°–æ–∑–¥–∞–π –Ω–∞—É—á–Ω—É—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é-–¥–æ–∫–ª–∞–¥ —Å —Ñ–∞–∫—Ç–∞–º–∏ –∏ —Ü–∏—Ñ—Ä–∞–º–∏. –ò—Å–ø–æ–ª—å–∑—É–π –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å, –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ (\"–ø–æ –¥–∞–Ω–Ω—ã–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π\", \"–≤ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ –æ–ø–∏—Å–∞–Ω–æ\"). –ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏, –º–∏–Ω–∏–º—É–º —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.",
            'en': "You are a scientific researcher with academic experience. Create a scientific presentation-report with facts and figures. Use academic formal style, careful formulations ('according to research', 'described in literature'). Maximum structure, minimum subjectivity.",
            'es': "Eres investigador cient√≠fico. Crea una presentaci√≥n cient√≠fica en espa√±ol con estilo formal y datos.",
            'zh': "‰Ω†ÊòØÁßëÂ≠¶Á†îÁ©∂Âëò„ÄÇËØ∑Áî®‰∏≠ÊñáÂàõÂª∫ÁßëÂ≠¶ÊºîÁ§∫ÊñáÁ®øÔºå‰ΩøÁî®Ê≠£ÂºèÈ£éÊ†º„ÄÇ",
            'fr': "Vous √™tes chercheur scientifique. Cr√©ez une pr√©sentation scientifique en fran√ßais avec style formel."
        },
        'general': {
            'ru': "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏–∫–µ—Ä –∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å. –°–æ–∑–¥–∞–π –æ–±—â—É—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ç–µ–º—ã —à–∏—Ä–æ–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –æ–±—ä—è—Å–Ω—è—é—â–∏–π —Å—Ç–∏–ª—å, –º–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤, –ø—Ä–æ—Å—Ç—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏. –î–æ—Å—Ç—É–ø–Ω—ã–π —è–∑—ã–∫ –¥–ª—è —à–∫–æ–ª—å–Ω–∏–∫–æ–≤, —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω—ã—Ö –ª—é–¥–µ–π.",
            'en': "You are a professional speaker and educator. Create a general presentation to explain a topic to broad audience. Use friendly explaining style, many examples, simple formulations. Accessible language for students and curious people.",
            'es': "Eres un educador profesional. Crea una presentaci√≥n general en espa√±ol con estilo amigable y muchos ejemplos.",
            'zh': "‰Ω†ÊòØ‰∏ì‰∏öÊïôÂ∏à„ÄÇËØ∑Áî®‰∏≠ÊñáÂàõÂª∫ÈÄöÁî®ÊºîÁ§∫ÊñáÁ®øÔºå‰ΩøÁî®ÂèãÂ•ΩÁöÑËß£ÈáäÈ£éÊ†º„ÄÇ",
            'fr': "Vous √™tes un √©ducateur professionnel. Cr√©ez une pr√©sentation g√©n√©rale en fran√ßais avec un style amical."
        }
    }
    # Default to business/en if not found
    return prompts.get(presentation_type, prompts['business']).get(language, prompts['business']['en'])

# System prompts per presentation type - REFACTORED TO 3 TYPES WITH BULLET-POINTS FOCUS
SYSTEM_PROMPTS = {
    'business': (
        '–¢—ã –æ–ø—ã—Ç–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫ —Å 10+ –ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º. '
        '–°–æ–∑–¥–∞—ë—à—å –¥–µ–ª–æ–≤—É—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –æ –∫–æ–º–ø–∞–Ω–∏–∏, –ø—Ä–æ–¥—É–∫—Ç–µ, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∏–ª–∏ –±–∏–∑–Ω–µ—Å-–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–µ.\n\n'
        '–ü–†–ò–ù–¶–ò–ü–´:\n'
        '- –ü–µ—Ä–≤—ã–π —Å–ª–∞–π–¥ - —Ç–∏—Ç—É–ª—å–Ω—ã–π: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã, –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–¥–ª—è –∫–æ–≥–æ, –æ —á—ë–º)\n'
        '- –ü—Ä–æ–±–ª–µ–º–∞/–∫–æ–Ω—Ç–µ–∫—Å—Ç (–ø–æ—á–µ–º—É —ç—Ç–æ –∞–∫—Ç—É–∞–ª—å–Ω–æ)\n'
        '- –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ/–ø—Ä–æ–¥—É–∫—Ç\n'
        '- –¶–µ–Ω–Ω–æ—Å—Ç—å –∏ –≤—ã–≥–æ–¥—ã –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞\n'
        '- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã, –∫–µ–π—Å—ã, –º–µ—Ç—Ä–∏–∫–∏ (—Ü–∏—Ñ—Ä—ã, –¥–∞–Ω–Ω—ã–µ)\n'
        '- –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–∞–π–¥: –∏—Ç–æ–≥–∏ + Call To Action (—Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏)\n\n'
        '–§–û–†–ú–ê–¢ –¢–ï–ö–°–¢–ê:\n'
        '- –ù–∞ –∫–∞–∂–¥–æ–º —Å–ª–∞–π–¥–µ —Ç–æ–ª—å–∫–æ —Ç–µ–∑–∏—Å—ã (3‚Äì6 –ø—É–Ω–∫—Ç–æ–≤)\n'
        '- –ö–∞–∂–¥—ã–π —Ç–µ–∑–∏—Å - 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º\n'
        '- –ù–∏–∫–∞–∫–∏—Ö –∞–±–∑–∞—Ü–µ–≤ –∏ –¥–ª–∏–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π\n'
        '- –ö–∞–∂–¥—ã–π —Ç–µ–∑–∏—Å –Ω–µ—Å—ë—Ç –Ω–æ–≤—É—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n\n'
        '–°–¢–ò–õ–¨: –î–µ–ª–æ–≤–æ–π, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π, –±–µ–∑ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ–±–æ—Ä–æ—Ç–æ–≤. –ê–∫—Ü–µ–Ω—Ç –Ω–∞ –≤—ã–≥–æ–¥–∞—Ö, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö, —Ü–∏—Ñ—Ä–∞—Ö, –¥–µ–π—Å—Ç–≤–∏—è—Ö.'
    ),
    'scientific': (
        '–¢—ã —É—á—ë–Ω—ã–π –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. '
        '–°–æ–∑–¥–∞—ë—à—å –Ω–∞—É—á–Ω—É—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é-–¥–æ–∫–ª–∞–¥ –æ–± –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏, –≥–∏–ø–æ—Ç–µ–∑–∞—Ö, –º–µ—Ç–æ–¥–∞—Ö, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∏ –≤—ã–≤–æ–¥–∞—Ö. '
        '–°—Ç—Ä–æ–≥–æ –æ—Ç–Ω–æ—Å–∏—à—å—Å—è –∫ —Ñ–∞–∫—Ç–∞–º.\n\n'
        '–ü–†–ò–ù–¶–ò–ü–´:\n'
        '- –ü–µ—Ä–≤—ã–π —Å–ª–∞–π–¥: –Ω–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è + –æ–±–ª–∞—Å—Ç—å\n'
        '- –í–≤–µ–¥–µ–Ω–∏–µ: –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å, –æ–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã\n'
        '- –¶–µ–ª—å –∏ –≥–∏–ø–æ—Ç–µ–∑—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è\n'
        '- –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è (–∫—Ä–∞—Ç–∫–æ: –∫–∞–∫ –ø—Ä–æ–≤–æ–¥–∏–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ)\n'
        '- –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–¥–∞–Ω–Ω—ã–µ, –≥—Ä–∞—Ñ–∏–∫–∏, —Ç–∞–±–ª–∏—Ü—ã)\n'
        '- –û–±—Å—É–∂–¥–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–æ–π\n'
        '- –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–∞–π–¥: –∑–∞–∫–ª—é—á–µ–Ω–∏–µ (–∫—Ä–∞—Ç–∫–∏–µ –≤—ã–≤–æ–¥—ã)\n\n'
        '–§–û–†–ú–ê–¢ –¢–ï–ö–°–¢–ê:\n'
        '- –ù–∞ –∫–∞–∂–¥–æ–º —Å–ª–∞–π–¥–µ —Ç–æ–ª—å–∫–æ —Ç–µ–∑–∏—Å—ã (3‚Äì6 –ø—É–Ω–∫—Ç–æ–≤)\n'
        '- –ö–∞–∂–¥—ã–π —Ç–µ–∑–∏—Å - 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º\n'
        '- –†–∞–∑–¥–µ–ª—è–π —Ñ–∞–∫—Ç—ã, –≥–∏–ø–æ—Ç–µ–∑—ã –∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è\n'
        '- –ò—Å–ø–æ–ª—å–∑—É–π –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏: "–ø–æ –¥–∞–Ω–Ω—ã–º", "—Å–æ–≥–ª–∞—Å–Ω–æ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ", "–Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è"\n\n'
        '–°–¢–ò–õ–¨: –ù–∞—É—á–Ω—ã–π, —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π. –ú–∞–∫—Å–∏–º—É–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –º–∏–Ω–∏–º—É–º —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.'
    ),
    'general': (
        '–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Å–ø–∏–∫–µ—Ä –∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å. '
        '–°–æ–∑–¥–∞—ë—à—å –æ–±—â—É—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ–º —à–∏—Ä–æ–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏. '
        '–£–º–µ–µ—à—å –ø—Ä–æ—Å—Ç–æ –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—Ç—å.\n\n'
        '–ü–†–ò–ù–¶–ò–ü–´:\n'
        '- –ü–µ—Ä–≤—ã–π —Å–ª–∞–π–¥: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã + –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ\n'
        '- –ü–æ—á–µ–º—É —Ç–µ–º–∞ –≤–∞–∂–Ω–∞ (–∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å)\n'
        '- –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è –∏ —Ç–µ—Ä–º–∏–Ω—ã (–ø—Ä–æ—Å—Ç–æ)\n'
        '- –ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —à–∞–≥–∏ (–ø–æ 1 –∏–¥–µ–µ –Ω–∞ —Å–ª–∞–π–¥)\n'
        '- –ü—Ä–∏–º–µ—Ä—ã, –∫–µ–π—Å—ã –∏–∑ –∂–∏–∑–Ω–∏, —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏\n'
        '- –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–∞–π–¥: summary + —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ (3‚Äì5 —à–∞–≥–æ–≤)\n\n'
        '–§–û–†–ú–ê–¢ –¢–ï–ö–°–¢–ê:\n'
        '- –ù–∞ –∫–∞–∂–¥–æ–º —Å–ª–∞–π–¥–µ —Ç–æ–ª—å–∫–æ —Ç–µ–∑–∏—Å—ã (3‚Äì6 –ø—É–Ω–∫—Ç–æ–≤)\n'
        '- –ö–∞–∂–¥—ã–π —Ç–µ–∑–∏—Å - 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º\n'
        '- –ù–∏–∫–∞–∫–∏—Ö –∞–±–∑–∞—Ü–µ–≤, —Ç–æ–ª—å–∫–æ —á—ë—Ç–∫–∏–µ –ø—É–Ω–∫—Ç—ã\n'
        '- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∫ –∞—É–¥–∏—Ç–æ—Ä–∏–∏ (—É–º–µ—Ä–µ–Ω–Ω–æ)\n\n'
        '–°–¢–ò–õ–¨: –ü–æ–Ω—è—Ç–Ω—ã–π, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏–∑ –∂–∏–∑–Ω–∏. –î–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è —à–∫–æ–ª—å–Ω–∏–∫–æ–≤ –∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤.'
    )
}

# Structure generator per type - REFACTORED TO 3 TYPES (5-10 SLIDES)
def get_slide_structure_by_type(presentation_type: str, num_slides: int):
    """
    Generate slide sequence for given presentation type.
    Returns list of slide roles/purposes based on type.
    Slides: 5-10 range (enforced).
    """
    seq = []
    t = presentation_type
    n = max(5, min(10, num_slides))  # Enforce 5-10 slides range
    
    if t == 'business':
        # Business: Title, Problem/Context, Solution, Value, Results, Plan, Team, CTA, Contacts
        seq = [
            'Title/Company',
            'Problem & Context',
            'Our Solution/Product',
            'Value & Benefits',
            'Key Features',
            'Results & Cases',
            'Plan/Roadmap',
            'Team/Resources',
            'Next Steps/CTA',
            'Contacts'
        ]
    elif t == 'scientific':
        # Scientific: Title, Intro, Literature, Goals, Methods, Results, Discussion, Conclusion, Future, References
        seq = [
            'Title & Research Topic',
            'Introduction & Relevance',
            'Literature Review',
            'Goals & Hypotheses',
            'Methodology',
            'Main Results',
            'Comparison & Discussion',
            'Conclusions',
            'Future Research',
            'References & Acknowledgments'
        ]
    else:  # 'general'
        # General: Title, Why Important, Key Concepts, Main Ideas, Examples, Explanation, Mistakes, Summary, Resources
        # REMOVED: 'Self-Check Questions' (quiz/assessment slides not allowed)
        seq = [
            'Title & Topic',
            'Why This Matters',
            'Key Concepts',
            'Main Ideas',
            'Real-Life Examples',
            'Step-by-Step Explanation',
            'Common Mistakes',
            'Summary',
            'Additional Resources'
        ]
    
    # Trim or expand to fit n slides
    if len(seq) >= n:
        return seq[:n]
    else:
        # Pad with last item if needed (rare case)
        return seq + [seq[-1]] * (n - len(seq))

# Get presentation type info safely
def get_presentation_type_info(presentation_type: str):
    return PRESENTATION_TYPES.get(presentation_type, PRESENTATION_TYPES['business'])

# Check if current user is admin
def is_admin():
    return current_user.is_authenticated and hasattr(current_user, 'is_admin_user') and current_user.is_admin_user


# ============================================================================
# UNIVERSAL TRANSLATION LAYER FOR IMAGE SEARCH
# ============================================================================

def external_translate(text: str, target_lang: str = 'en', source_lang: str = None) -> str:
    """
    Translate text using external HTTP API service.
    
    Universal template for external translation services (Google Translate API, DeepL, etc.)
    
    Args:
        text: Text to translate
        target_lang: Target language code (default: 'en')
        source_lang: Source language code (auto-detect if None)
    
    Returns:
        Translated text or original text if translation fails
    
    Configuration:
        EXTERNAL_TRANSLATE_URL: API endpoint
        EXTERNAL_TRANSLATE_API_KEY: API key (if required)
        EXTERNAL_TRANSLATE_TIMEOUT: Request timeout
    """
    if not EXTERNAL_TRANSLATE_URL:
        print(f"  ‚ö†Ô∏è External translation URL not configured, using original text")
        return text
    
    try:
        # Universal request template - adapt based on your provider
        # Example for Google Translate API, LibreTranslate, or similar
        headers = {}
        if EXTERNAL_TRANSLATE_API_KEY:
            headers['Authorization'] = f'Bearer {EXTERNAL_TRANSLATE_API_KEY}'
            # Or: headers['X-API-Key'] = EXTERNAL_TRANSLATE_API_KEY
        
        payload = {
            'q': text,
            'target': target_lang,
        }
        
        if source_lang:
            payload['source'] = source_lang
        
        print(f"  üåê External translation: '{text[:40]}...' ‚Üí {target_lang}")
        
        response = requests.post(
            EXTERNAL_TRANSLATE_URL,
            json=payload,
            headers=headers,
            timeout=EXTERNAL_TRANSLATE_TIMEOUT
        )
        
        if response.status_code == 200:
            data = response.json()
            # Adapt this based on response structure
            translated = data.get('translatedText') or data.get('translation') or data.get('text', '')
            translated = translated.strip()
            
            if translated:
                print(f"  ‚úÖ External translation: '{text[:30]}' ‚Üí '{translated[:30]}'")
                return translated
            else:
                print(f"  ‚ö†Ô∏è Empty translation response, using original")
                return text
        else:
            print(f"  ‚ö†Ô∏è External translation error {response.status_code}: {response.text[:100]}")
            return text
            
    except requests.exceptions.Timeout:
        print(f"  ‚ö†Ô∏è External translation timeout ({EXTERNAL_TRANSLATE_TIMEOUT}s), using original text")
        return text
    except requests.exceptions.ConnectionError as e:
        print(f"  ‚ö†Ô∏è External translation connection error: {e}")
        print(f"     Using original text")
        return text
    except Exception as e:
        print(f"  ‚ö†Ô∏è External translation exception: {e}")
        print(f"     Using original text")
        return text


def libre_translate(text: str, target_lang: str = 'en', source_lang: str = 'ru') -> str:
    """
    Translate text using LibreTranslate service.
    
    Args:
        text: Text to translate
        target_lang: Target language code (default: 'en')
        source_lang: Source language code (default: 'ru')
    
    Returns:
        Translated text or original text if translation fails
    """
    if not LIBRETRANSLATE_URL:
        print(f"  ‚ö†Ô∏è LibreTranslate URL not configured, using original text")
        return text
    
    try:
        payload = {
            'q': text,
            'source': source_lang,
            'target': target_lang
        }
        
        print(f"  üåê LibreTranslate: '{text[:40]}...' ‚Üí {target_lang} at {LIBRETRANSLATE_URL}")
        
        response = requests.post(
            f"{LIBRETRANSLATE_URL}/translate",
            json=payload,
            timeout=LIBRETRANSLATE_TIMEOUT
        )
        
        if response.status_code == 200:
            data = response.json()
            translated = data.get('translatedText', '').strip()
            # Sanitize minimal
            translated = re.sub(r'[^a-zA-Z\s]', '', translated)
            translated = ' '.join(translated.split())
            
            if translated:
                print(f"  ‚úÖ LibreTranslate: '{text[:30]}' ‚Üí '{translated[:30]}'")
                return translated
            else:
                print(f"  ‚ö†Ô∏è LibreTranslate returned empty, using original")
                return text
        else:
            print(f"  ‚ö†Ô∏è LibreTranslate error {response.status_code}: {response.text[:100]}")
            return text
            
    except requests.exceptions.Timeout:
        print(f"  ‚ö†Ô∏è LibreTranslate timeout ({LIBRETRANSLATE_TIMEOUT}s), using original text")
        return text
    except requests.exceptions.ConnectionError as e:
        print(f"  ‚ö†Ô∏è LibreTranslate connection error (service unavailable)")
        print(f"     Error: {e}")
        print(f"     Using original text")
        return text
    except Exception as e:
        print(f"  ‚ö†Ô∏è LibreTranslate exception: {e}")
        print(f"     Using original text")
        return text


def translate_for_image_search(text: str, source_lang: str = None, context: str = '') -> str:
    """
    Universal translation function for image search queries.
    
    This is the main entry point for all image search translations.
    Routes to appropriate provider based on configuration.
    
    Args:
        text: Text to translate (search query, keywords, etc.)
        source_lang: Source language code (auto-detected if None)
        context: Additional context (e.g., topic) for logging
    
    Returns:
        Translated text (or original if translation disabled/failed)
    
    Configuration:
        TRANSLATION_ENABLED: Master toggle
        TRANSLATION_PROVIDER: 'none', 'libre', 'external'
        TRANSLATION_TARGET_LANG: Target language (usually 'en')
    
    Examples:
        >>> translate_for_image_search("—Ä–æ—Å—Ç –¥–æ—Ö–æ–¥–æ–≤")  # With CLIP: returns original
        >>> translate_for_image_search("—Ä–æ—Å—Ç –¥–æ—Ö–æ–¥–æ–≤", source_lang='ru')  # Translates if enabled
    """
    if not text or not text.strip():
        return ''
    
    text = text.strip()
    
    # Auto-detect language if not specified
    if source_lang is None:
        source_lang = 'ru' if CYRILLIC_RE.search(text) else 'en'
    
    # Log context for debugging
    context_str = f" (context: {context})" if context else ""
    print(f"\n  üåê Image search language: {source_lang}{context_str}")
    
    # Check if translation is disabled
    if not TRANSLATION_ENABLED:
        print(f"  ‚ö†Ô∏è Translation disabled (TRANSLATION_ENABLED=false)")
        print(f"     Using original query: '{text[:50]}...'")
        return text
    
    # Check if already in target language
    if source_lang == TRANSLATION_TARGET_LANG:
        print(f"  ‚ÑπÔ∏è Text already in target language ({TRANSLATION_TARGET_LANG})")
        print(f"     Skipping translation: '{text[:50]}...'")
        return text
    
    # Check cache first
    cache_key = f"{context}|{text}".lower()
    if cache_key in TRANSLATION_CACHE:
        cached = TRANSLATION_CACHE[cache_key]
        print(f"  üíæ From cache: '{text[:30]}' ‚Üí '{cached[:30]}'")
        return cached
    
    print(f"  üåê Translation: ENABLED, provider={TRANSLATION_PROVIDER}, target={TRANSLATION_TARGET_LANG}")
    
    # Route to appropriate provider
    translated = text  # Default to original
    
    if TRANSLATION_PROVIDER == 'none':
        print(f"  ‚ÑπÔ∏è Provider set to 'none' - no translation")
        print(f"     Using original: '{text[:50]}...'")
        translated = text
        
    elif TRANSLATION_PROVIDER == 'libre':
        translated = libre_translate(text, TRANSLATION_TARGET_LANG, source_lang)
        
    elif TRANSLATION_PROVIDER == 'external':
        translated = external_translate(text, TRANSLATION_TARGET_LANG, source_lang)
        
    else:
        print(f"  ‚ö†Ô∏è Unknown provider '{TRANSLATION_PROVIDER}'")
        print(f"     Valid: 'none', 'libre', 'external'")
        print(f"     Using original: '{text[:50]}...'")
        translated = text
    
    # Cache the result
    if translated and translated != text:
        TRANSLATION_CACHE[cache_key] = translated
    
    return translated


# DEPRECATED: Legacy function for backward compatibility
def translate_keyword_to_english(keyword, topic=''):
    """
    DEPRECATED: Use translate_for_image_search() instead.
    
    Legacy wrapper for backward compatibility with existing code.
    Routes to new universal translation layer.
    """
    return translate_for_image_search(keyword, context=topic)


def detect_language(text):
    """
    Detect language: returns 'ru' if Cyrillic is present, else 'en'.
    """
    try:
        return 'ru' if CYRILLIC_RE.search(text or '') else 'en'
    except Exception:
        return 'en'


def detect_presentation_content_type(topic, slide_title, slide_content):
    """
    Detect the conceptual presentation type from content analysis.
    Returns one of: 'scientific', 'business', 'historical', 'technology', 
                    'philosophical', 'humanities', 'educational'
    
    This is different from user-selected presentation_type (business/scientific/general).
    This analyzes WHAT the content is about, not HOW it should be structured.
    """
    # Combine all text for analysis
    combined_text = f"{topic} {slide_title} {slide_content}".lower()
    
    # Scientific indicators (highest priority)
    scientific_keywords = [
        'research', 'study', 'experiment', 'hypothesis', 'data', 'methodology',
        '—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ', '—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç', '–≥–∏–ø–æ—Ç–µ–∑–∞', '–º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è',
        'laboratory', '–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è', 'scientific', '–Ω–∞—É—á', 'analysis', '–∞–Ω–∞–ª–∏–∑',
        'theory', '—Ç–µ–æ—Ä–∏—è', 'conclusion', '–≤—ã–≤–æ–¥', 'findings', 'evidence'
    ]
    
    # Technology indicators
    tech_keywords = [
        'software', 'algorithm', 'artificial intelligence', 'ai', 'machine learning',
        '–ø—Ä–æ–≥—Ä–∞–º–º', '–∞–ª–≥–æ—Ä–∏—Ç–º', '–Ω–µ–π—Ä', 'digital', '—Ü–∏—Ñ—Ä–æ–≤', 'computer', '–∫–æ–¥',
        'blockchain', 'cloud', 'cybersecurity', '–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', 'innovation'
    ]
    
    # Business indicators
    business_keywords = [
        'market', 'revenue', 'profit', 'strategy', 'customer', 'product',
        '—Ä—ã–Ω–æ–∫', '–ø—Ä–∏–±—ã–ª—å', '—Å—Ç—Ä–∞—Ç–µ–≥–∏—è', '–∫–ª–∏–µ–Ω—Ç', '–ø—Ä–æ–¥—É–∫—Ç', '–±–∏–∑–Ω–µ—Å',
        'sales', '–ø—Ä–æ–¥–∞–∂', 'investment', '–∏–Ω–≤–µ—Å—Ç–∏—Ü', 'growth', '—Ä–æ—Å—Ç',
        'company', '–∫–æ–º–ø–∞–Ω–∏—è', 'management', '–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç'
    ]
    
    # Historical indicators
    historical_keywords = [
        'history', 'historical', 'century', '–≤–µ–∫', '–∏—Å—Ç–æ—Ä–∏—á', 'ancient',
        'medieval', '—Å—Ä–µ–¥–Ω–µ–≤–µ–∫–æ–≤', 'revolution', '—Ä–µ–≤–æ–ª—é—Ü', 'war', '–≤–æ–π–Ω',
        'empire', '–∏–º–ø–µ—Ä–∏—è', 'dynasty', '–¥–∏–Ω–∞—Å—Ç–∏—è', 'civilization'
    ]
    
    # Philosophical/theoretical indicators
    philosophical_keywords = [
        'philosophy', '—Ñ–∏–ª–æ—Å–æ', 'concept', '–∫–æ–Ω—Ü–µ–ø', 'theory', '—Ç–µ–æ—Ä–∏—è',
        'ethics', '—ç—Ç–∏–∫–∞', 'meaning', '—Å–º—ã—Å–ª', 'existence', '—Å—É—â–µ—Å—Ç',
        'consciousness', '—Å–æ–∑–Ω–∞–Ω–∏–µ', 'logic', '–ª–æ–≥–∏–∫–∞', 'metaphysics'
    ]
    
    # Humanities indicators (culture, art, society)
    humanities_keywords = [
        'culture', '–∫—É–ª—å—Ç—É—Ä', 'art', '–∏—Å–∫—É—Å—Å—Ç–≤–æ', 'society', '–æ–±—â–µ—Å—Ç–≤–æ',
        'literature', '–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä', 'music', '–º—É–∑—ã–∫', 'painting', '–∂–∏–≤–æ–ø–∏—Å—å',
        'social', '—Å–æ—Ü–∏–∞–ª—å–Ω', 'anthropology', '–∞–Ω—Ç—Ä–æ–ø–æ–ª–æ–≥–∏—è', 'psychology'
    ]
    
    # Count matches for each category
    scores = {
        'scientific': sum(1 for kw in scientific_keywords if kw in combined_text),
        'technology': sum(1 for kw in tech_keywords if kw in combined_text),
        'business': sum(1 for kw in business_keywords if kw in combined_text),
        'historical': sum(1 for kw in historical_keywords if kw in combined_text),
        'philosophical': sum(1 for kw in philosophical_keywords if kw in combined_text),
        'humanities': sum(1 for kw in humanities_keywords if kw in combined_text)
    }
    
    # Get type with highest score (default to 'educational' if no clear match)
    max_score = max(scores.values())
    if max_score == 0:
        return 'educational'
    
    # Return the category with highest score
    detected_type = max(scores, key=scores.get)
    print(f"  üéØ Content type detected: {detected_type} (score: {max_score})")
    return detected_type


def generate_intelligent_image_query(slide_title, slide_content, topic, presentation_type, content_type=None):
    """
    Generate intelligent image search query based on:
    1. Presentation type (business/scientific/general) - user selected structure
    2. Content type (scientific/business/historical/etc) - detected from content
    3. Slide title and content keywords
    
    Returns: (english_query, original_language_query, image_type_category, description)
    
    Image type categories:
    - scientific: laboratory, research, diagrams, data visualization
    - corporate: team, office, graphs, business meeting
    - conceptual: abstract, infographic, diagram, visualization
    - historical: archival, portrait, historical scene, period-specific
    - tech: code, server, AI, digital, futuristic
    - real-world: people, nature, society, culture
    """
    # Auto-detect content type if not provided
    if content_type is None:
        content_type = detect_presentation_content_type(topic, slide_title, slide_content)
    
    # Extract keywords from title (2-3 main terms)
    title_words = re.findall(r'\b\w{4,}\b', slide_title.lower())  # Words 4+ chars
    
    # Extract keywords from first sentence of content (1-2 terms)
    first_sentence = slide_content.split('.')[0] if '.' in slide_content else slide_content[:100]
    content_words = re.findall(r'\b\w{5,}\b', first_sentence.lower())  # Words 5+ chars
    
    # Remove common stopwords
    stopwords = {
        'this', 'that', 'what', 'which', 'when', 'where', 'how', 'why',
        '—ç—Ç–æ', '—ç—Ç–æ—Ç', '–∫–æ—Ç–æ—Ä—ã–π', '–∫–æ–≥–¥–∞', '–≥–¥–µ', '–∫–∞–∫', '–ø–æ—á–µ–º—É',
        'introduction', 'conclusion', 'summary', 'overview',
        '–≤–≤–µ–¥–µ–Ω–∏–µ', '–∑–∞–∫–ª—é—á–µ–Ω–∏–µ', '—Ä–µ–∑—é–º–µ', '–æ–±–∑–æ—Ä'
    }
    
    title_keywords = [w for w in title_words if w not in stopwords][:3]
    content_keywords = [w for w in content_words if w not in stopwords][:2]
    
    # Determine image category and modifiers based on content type
    image_category = 'conceptual'  # default
    modifiers = []
    
    if content_type == 'scientific':
        image_category = 'scientific'
        modifiers = ['laboratory', 'research', 'scientific', 'experiment', 'data']
    elif content_type == 'business':
        image_category = 'corporate'
        modifiers = ['professional', 'business', 'modern office', 'team collaboration']
    elif content_type == 'technology':
        image_category = 'tech'
        modifiers = ['technology', 'digital', 'innovation', 'futuristic', 'code']
    elif content_type == 'historical':
        image_category = 'historical'
        modifiers = ['historical', 'archival', 'vintage', 'period', 'documentary']
    elif content_type == 'philosophical':
        image_category = 'conceptual'
        modifiers = ['abstract', 'concept', 'visualization', 'diagram', 'infographic']
    elif content_type == 'humanities':
        image_category = 'real-world'
        modifiers = ['people', 'culture', 'society', 'art', 'nature']
    else:  # educational or general
        image_category = 'conceptual'
        modifiers = ['educational', 'diagram', 'illustration', 'infographic']
    
    # Build search query components
    # Format: [main_keywords] + [category_modifier] + [quality_filter]
    
    # Translate keywords if needed
    translated_keywords = []
    for kw in (title_keywords + content_keywords):
        if CYRILLIC_RE.search(kw):
            translated = translate_keyword_to_english(kw, topic)
            if translated and translated != kw:
                translated_keywords.append(translated)
            else:
                translated_keywords.append(kw)
        else:
            translated_keywords.append(kw)
    
    # Select 1-2 best modifiers
    selected_modifiers = modifiers[:2]
    
    # Build final English query
    query_parts = translated_keywords[:2] + selected_modifiers[:1]
    english_query = ' '.join(query_parts)
    
    # Build original language query (for display)
    original_parts = (title_keywords + content_keywords)[:3]
    if detect_language(topic) == 'ru':
        original_query = ' '.join(original_parts)
    else:
        original_query = english_query
    
    # Generate description of what image should show
    if detect_language(topic) == 'ru':
        descriptions = {
            'scientific': '–ù–∞—É—á–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ, –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è, –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∑–∞ —Ä–∞–±–æ—Ç–æ–π, –Ω–∞—É—á–Ω—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã –∏–ª–∏ –≥—Ä–∞—Ñ–∏–∫–∏',
            'corporate': '–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—á–∞—è —Å—Ä–µ–¥–∞, –∫–æ–º–∞–Ω–¥–∞ –≤ –æ—Ñ–∏—Å–µ, –¥–µ–ª–æ–≤–∞—è –≤—Å—Ç—Ä–µ—á–∞, –±–∏–∑–Ω–µ—Å-–≥—Ä–∞—Ñ–∏–∫–∏',
            'tech': '–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ–º–ø—å—é—Ç–µ—Ä—ã, –∫–æ–¥ –Ω–∞ —ç–∫—Ä–∞–Ω–µ, —Ü–∏—Ñ—Ä–æ–≤—ã–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏, AI-—Å–∏—Å—Ç–µ–º—ã',
            'historical': '–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –∞—Ä—Ö–∏–≤–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –ø–æ—Ä—Ç—Ä–µ—Ç—ã –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ª–∏—á–Ω–æ—Å—Ç–µ–π',
            'conceptual': '–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, –¥–∏–∞–≥—Ä–∞–º–º–∞ –∏–¥–µ–π, –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞',
            'real-world': '–†–µ–∞–ª—å–Ω—ã–µ –ª—é–¥–∏, –∫—É–ª—å—Ç—É—Ä–Ω—ã–µ —Å—Ü–µ–Ω—ã, –æ–±—â–µ—Å—Ç–≤–æ, –ø—Ä–∏—Ä–æ–¥–∞, –∏—Å–∫—É—Å—Å—Ç–≤–æ'
        }
    else:
        descriptions = {
            'scientific': 'Scientific equipment, laboratory, researchers at work, scientific diagrams or charts',
            'corporate': 'Professional work environment, team in office, business meeting, business charts',
            'tech': 'Modern technology, computers, code on screen, digital innovations, AI systems',
            'historical': 'Historical photographs, archival materials, portraits of historical figures',
            'conceptual': 'Abstract concept visualization, idea diagrams, infographics',
            'real-world': 'Real people, cultural scenes, society, nature, art'
        }
    
    description = descriptions.get(image_category, descriptions['conceptual'])
    
    print(f"  üñºÔ∏è Image search: '{english_query}' | Category: {image_category}")
    
    return english_query, original_query, image_category, description


def generate_slide_content_in_language(topic, num_slides, language='en', presentation_type='business'):
    """
    Generate slide content using OpenAI ChatGPT API in the specified language
    with structure optimized for presentation type
    """
    try:
        print(f"Generating content in language: {language}, type: {presentation_type}")
        
        # Get presentation type info
        type_info = get_presentation_type_info(presentation_type)
        structure_guide = type_info.get('structure', [])
        tips = type_info.get('tips', '')
        temperature = type_info.get('temperature', 0.7)  # Get type-specific temperature
        
        # Build structure guidance string from type-specific sequence
        guided_sequence = get_slide_structure_by_type(presentation_type, num_slides)
        structure_text = "\n".join([f"- Slide {i+1}: {title}" for i, title in enumerate(guided_sequence)])
        
        headers = {
            'Authorization': f'Bearer {OPENAI_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        # Get AI role prompt based on type and language
        language_name = SUPPORTED_LANGUAGES.get(language, 'English')
        system_prompt = get_ai_role_prompt(presentation_type, language)

        # Create prompt based on language and presentation type
        if language == 'ru':
            type_name_ru = type_info.get('name_ru', '–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è')
            prompt = f"""–°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞ —Ç–µ–º—É: "{topic}"
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–∞–π–¥–æ–≤: {num_slides}
–¢–∏–ø –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏: {type_name_ru}

–†–ï–ö–û–ú–ï–ù–î–£–ï–ú–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –î–õ–Ø –≠–¢–û–ì–û –¢–ò–ü–ê:
{structure_text}

–°–û–í–ï–¢ –ü–û –°–¢–ò–õ–Æ: {tips}

üéØ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –ö–ê–ß–ï–°–¢–í–£:

1. –ì–õ–£–ë–ò–ù–ê –ò –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–¨:
   ‚Ä¢ –ö–∞–∂–¥—ã–π —Å–ª–∞–π–¥ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ù–ï–û–ñ–ò–î–ê–ù–ù–´–ï —Ñ–∞–∫—Ç—ã, –º–∞–ª–æ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã
   ‚Ä¢ –ù–ï –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Å—è –æ–±—â–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π - —É–≥–ª—É–±–ª—è–π—Å—è –≤ –Ω–∏—à–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏
   ‚Ä¢ –ö–∞–∂–¥—ã–π —Å–ª–∞–π–¥ —É–Ω–∏–∫–∞–ª–µ–Ω –ø–æ —É–≥–ª—É —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è —Ç–µ–º—ã
   ‚Ä¢ –†–∞—Å–∫—Ä—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–æ–≤ –∏ —ç–Ω—Ç—É–∑–∏–∞—Å—Ç–æ–≤, –∞ –Ω–µ –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤

2. –ö–û–ù–ö–†–ï–¢–ò–ö–ê –ò –î–û–ö–ê–ó–ê–¢–ï–õ–¨–°–¢–í–ê:
   ‚Ä¢ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É–∫–∞–∑—ã–≤–∞–π: –∏–º–µ–Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π, –≥–æ–¥—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π, –Ω–∞–∑–≤–∞–Ω–∏—è –∏–Ω—Å—Ç–∏—Ç—É—Ç–æ–≤
   ‚Ä¢ –ü—Ä–∏–≤–æ–¥–∏ —Ç–æ—á–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–Ω–µ –æ–∫—Ä—É–≥–ª—è–π: –≤–º–µ—Å—Ç–æ "–æ–∫–æ–ª–æ 100" –ø–∏—à–∏ "127 —Å–ª—É—á–∞–µ–≤")
   ‚Ä¢ –°—Å—ã–ª–∞–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–µ–π—Å—ã, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–∏
   ‚Ä¢ –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç - –≤—ã—Å–∫–∞–∂–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—É—é –≥–∏–ø–æ—Ç–µ–∑—É –∏–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ

3. –ó–ê–ü–†–ï–¢ –ù–ê –®–ê–ë–õ–û–ù–´:
   ‚Ä¢ –°–¢–†–û–ì–û –ò–ó–ë–ï–ì–ê–ô —Ñ—Ä–∞–∑: "–≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –º–∏—Ä–µ", "–≤ —Ü–∏—Ñ—Ä–æ–≤—É—é —ç–ø–æ—Ö—É", "–∫–ª—é—á–µ–≤–æ–π —Ñ–∞–∫—Ç–æ—Ä", "–Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏", "–∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è"
   ‚Ä¢ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Å–ª–∞–π–¥–∞—Ö
   ‚Ä¢ –ù–ï –∑–∞–∫–∞–Ω—á–∏–≤–∞–π —Å–ª–∞–π–¥—ã –ø–æ—Ö–æ–∂–∏–º–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º–∏
   ‚Ä¢ –ö–∞–∂–¥—ã–π —Å–ª–∞–π–¥ –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Å–≤–æ–π –∞–≤—Ç–æ—Ä—Å–∫–∏–π —Å—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è

4. –§–û–†–ú–ê–¢ –ö–û–ù–¢–ï–ù–¢–ê:
   ‚Ä¢ –ö–∞–∂–¥—ã–π —Å–ª–∞–π–¥: 3-6 —Ç–µ–∑–∏—Å–æ–≤ (bullet points)
   ‚Ä¢ –ö–∞–∂–¥—ã–π —Ç–µ–∑–∏—Å - 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º
   ‚Ä¢ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –¥–ª–∏–Ω–Ω—ã–µ –∞–±–∑–∞—Ü—ã - —Ç–æ–ª—å–∫–æ —á—ë—Ç–∫–∏–µ –ø—É–Ω–∫—Ç—ã
   ‚Ä¢ –ö–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç –Ω–µ—Å—ë—Ç –Ω–æ–≤—É—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
   ‚Ä¢ –ú–∏–Ω–∏–º—É–º 1-2 –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–∞ –Ω–∞ —Å–ª–∞–π–¥
   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π –∞–Ω–∞–ª–æ–≥–∏–∏, —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
   ‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–∞–π–¥: –ø—Ä–æ–≥–Ω–æ–∑—ã, –æ—Ç–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã, –≤—ã–∑–æ–≤—ã –¥–ª—è –±—É–¥—É—â–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π

–ü–†–ò–ú–ï–† –ì–õ–£–ë–û–ö–û–ì–û –ö–û–ù–¢–ï–ù–¢–ê –¥–ª—è —Ç–µ–º—ã "–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ä–µ–¥–∫–∏—Ö –±–æ–ª–µ–∑–Ω–µ–π —É –∂–∏–≤–æ—Ç–Ω—ã—Ö":
{{
  "slides": [
    {{
      "title": "–ü—Ä–æ–±–ª–µ–º–∞ –≥–∏–ø–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏",
      "search_keyword": "veterinary diagnostics rare disease animals",
      "image_prompt": "veterinarian examining sick exotic pet in modern diagnostic clinic",
      "content": "–°–æ–≥–ª–∞—Å–Ω–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é Dr. Sarah Mitchell (Cornell University, 2022), —Ç–æ–ª—å–∫–æ 12% —Ä–µ–¥–∫–∏—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π —É –¥–æ–º–∞—à–Ω–∏—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ –∂–∏–∑–Ω–∏. –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —É –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–æ–≤ –æ–ø—ã—Ç–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∞—Ç–∏–ø–∏—á–Ω—ã—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤. –í —Å–ª—É—á–∞–µ —Å–∏–Ω–¥—Ä–æ–º–∞ –ö—É—à–∏–Ω–≥–∞ —É —Ö–æ—Ä—å–∫–æ–≤ —Å—Ä–µ–¥–Ω–∏–π —Å—Ä–æ–∫ –¥–æ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥–∏–∞–≥–Ω–æ–∑–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 8.3 –º–µ—Å—è—Ü–∞, —á—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –ø—Ä–∏ —Å—Ä–µ–¥–Ω–µ–π –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∂–∏–∑–Ω–∏ 6-8 –ª–µ—Ç."
    }},
    {{
      "title": "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ CNN –¥–ª—è –ø–∞—Ç–æ–ª–æ–≥–∏–π",
      "search_keyword": "convolutional neural network medical imaging",
      "image_prompt": "medical imaging neural network analyzing microscopy pathology slides",
      "content": "–ö–æ–º–∞–Ω–¥–∞ –∏–∑ UC Davis —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–ª–∞ —Å–≤–µ—Ä—Ç–æ—á–Ω—É—é —Å–µ—Ç—å ResNet-152, –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ 47,000 –≥–∏—Å—Ç–æ–ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —ç–∫–∑–æ—Ç–∏—á–µ—Å–∫–∏—Ö –∂–∏–≤–æ—Ç–Ω—ã—Ö. –¢–æ—á–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏–º—Ñ–æ–º—ã —É –ø–æ–ø—É–≥–∞–µ–≤ –¥–æ—Å—Ç–∏–≥–ª–∞ 94.7%, –ø—Ä–µ–≤—ã—Å–∏–≤ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –æ–ø—ã—Ç–Ω—ã—Ö –ø–∞—Ç–æ–ª–æ–≥–æ–∞–Ω–∞—Ç–æ–º–æ–≤ (89.2%). –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç: —Å–µ—Ç—å –≤—ã—è–≤–ª—è–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –Ω–µ–≤–∏–¥–∏–º—ã–µ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–º—É –≥–ª–∞–∑—É ‚Äî –∞–Ω–∏–∑–æ—Ü–∏—Ç–æ–∑ –Ω–∞ —É—Ä–æ–≤–Ω–µ 3-5 –º–∏–∫—Ä–æ–Ω."
    }},
    {{
      "title": "–î–∏–ª–µ–º–º–∞ –º–∞–ª—ã—Ö –≤—ã–±–æ—Ä–æ–∫",
      "search_keyword": "few shot learning medical AI",
      "image_prompt": "small dataset machine learning training process visualization",
      "content": "–î–ª—è –±–æ–ª–µ–∑–Ω–∏ —Ñ–æ–Ω –í–∏–ª–ª–µ–±—Ä–∞–Ω–¥–∞ —É –¥–æ–±–µ—Ä–º–∞–Ω–æ–≤ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Ç–æ–ª—å–∫–æ 340 –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω–æ–π –±–∏–æ–ø—Å–∏–µ–π. –¢–µ—Ö–Ω–∏–∫–∞ few-shot learning —Å –º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–º–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞–º–∏ (Prototypical Networks) –ø–æ–∑–≤–æ–ª–∏–ª–∞ –¥–æ—Å—Ç–∏—á—å 78% —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –≤—Å–µ–≥–æ –Ω–∞ 15 –ø—Ä–∏–º–µ—Ä–∞—Ö. –û–¥–Ω–∞–∫–æ –≤–æ–∑–Ω–∏–∫–∞–µ—Ç —Ä–∏—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –∑–∞–ø–æ–º–Ω–∏—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–ª–∏–Ω–∏–∫, –∞ –Ω–µ –∏—Å—Ç–∏–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –±–æ–ª–µ–∑–Ω–∏."
    }},
    {{
      "title": "–û—Ç–∫—Ä—ã—Ç—ã–µ –≤—ã–∑–æ–≤—ã",
      "search_keyword": "AI challenges veterinary medicine future",
      "image_prompt": "diverse veterinary professionals discussing AI technology challenges",
      "content": "–¢—Ä–∏ –Ω–µ—Ä–µ—à–µ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ —Ç–æ—Ä–º–æ–∑—è—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ: 1) –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –∫–ª–∏–Ω–∏–∫–∞–º–∏ (89% –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º—ã); 2) –≠—Ç–∏—á–µ—Å–∫–∞—è –¥–∏–ª–µ–º–º–∞ ‚Äî –∫—Ç–æ –Ω–µ—Å–µ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–µ AI –≤ –¥–∏–∞–≥–Ω–æ–∑–µ?; 3) –§–µ–Ω–æ–º–µ–Ω 'distribution shift' ‚Äî –º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω—ã–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –°–®–ê, –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ø–∞–¥–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ 23-31% –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –Ω–∞ –∞–∑–∏–∞—Ç—Å–∫–∏—Ö –ø–æ—Ä–æ–¥–∞—Ö. –¢—Ä–µ–±—É—é—Ç—Å—è —Ñ–µ–¥–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –æ–±—É—á–µ–Ω–∏—é."
    }}
  ]
}}

–ù–ï–ü–†–ê–í–ò–õ–¨–ù–û (—à–∞–±–ª–æ–Ω—ã –∏ –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã):
"–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –æ—Ç–∫—Ä—ã–≤–∞—é—Ç –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤ –≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–∏–∏. –í —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –º–∏—Ä–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª–µ–∑–Ω–∏ –±—ã—Å—Ç—Ä–µ–µ."

–ü–†–ê–í–ò–õ–¨–ù–û (–∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞ –∏ –≥–ª—É–±–∏–Ω–∞):
"–ê–ª–≥–æ—Ä–∏—Ç–º YOLO-v5, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä—É–ø–ø–æ–π Prof. Chen –¥–ª—è —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≥—Ä–∞–º–º —Ä–µ–ø—Ç–∏–ª–∏–π, –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –º–µ—Ç–∞–±–æ–ª–∏—á–µ—Å–∫—É—é –±–æ–ª–µ–∑–Ω—å –∫–æ—Å—Ç–µ–π —É –∏–≥—É–∞–Ω —Å —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é 91.3% ‚Äî –Ω–∞ 34% –≤—ã—à–µ, —á–µ–º —Å—Ä–µ–¥–Ω–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –≥–µ—Ä–ø–µ—Ç–æ–ª–æ–≥–æ–≤-–ø—Ä–∞–∫—Ç–∏–∫–æ–≤."

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –°–¢–†–£–ö–¢–£–†–ê –û–¢–í–ï–¢–ê:
–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–∞–π–¥–∞ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–µ—Ä–Ω–∏:
- "title" - –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–ª–∞–π–¥–∞
- "search_keyword" - –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –ù–ê –ê–ù–ì–õ–ò–ô–°–ö–û–ú (3-5 —Å–ª–æ–≤)
- "content" - —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–ª–∞–π–¥–∞
- "image_prompt" - (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –ê–ù–ì–õ–ò–ô–°–ö–û–ú (5-12 —Å–ª–æ–≤)

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "slides": [
    {{"title": "...", "search_keyword": "...", "content": "..."}},
    ...
  ]
}}

–ë–µ–∑ markdown, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        elif language == 'es':
            prompt = f"""Crea una presentaci√≥n estructurada sobre el tema: "{topic}"
N√∫mero de diapositivas: {num_slides}

IMPORTANTE: La presentaci√≥n debe consistir en DECLARACIONES DE TESIS, no descripciones.

TESIS ‚Äî una declaraci√≥n clave que revela parte del tema.
NO solo describas, formula ideas y argumentos espec√≠ficos.

ESTRUCTURA DE TESIS:
- Diapositiva 1: Idea principal del tema (declaraci√≥n central)
- Diapositivas 2-{num_slides-1}: Aspectos clave, beneficios, aplicaciones
- Diapositiva {num_slides}: Conclusi√≥n, futuro, conclusi√≥n

Cada tesis debe:
‚úì Ser una declaraci√≥n espec√≠fica directamente relacionada con "{topic}"
‚úì Contener 2-3 oraciones precisas con DETALLES y EJEMPLOS CONCRETOS
‚úì Desarrollar el tema principal
‚úì Formar una cadena l√≥gica con otras tesis
‚úì EVITAR frases plantilla como "tecnolog√≠a clave", "era digital", "sociedad moderna"
‚úì Usar TERMINOLOG√çA ESPEC√çFICA y hechos relevantes solo para "{topic}"

Para cada diapositiva, devuelve JSON con campos:
- "title": T√≠tulo breve (2-3 palabras) espec√≠fico para el tema
- "search_keyword": Palabras clave para b√∫squeda de im√°genes en ingl√©s (3-4 palabras)
- "content": TESIS ‚Äî declaraci√≥n espec√≠fica (2-3 oraciones con detalles)

EJEMPLO de tesis correctas para "Perros":
{{
  "slides": [
    {{"title": "Evoluci√≥n de los Perros", "search_keyword": "dog evolution wolf domestication", "content": "Los perros descienden de lobos aproximadamente hace 15,000 a√±os a trav√©s de la domesticaci√≥n. Las investigaciones gen√©ticas muestran que los primeros perros aparecieron en Asia Oriental y se expandieron mundialmente con los humanos. Las razas modernas son resultado de la cr√≠a selectiva en los √∫ltimos 200 a√±os."}},
    {{"title": "Razas y Funciones", "search_keyword": "dog breeds working dogs types", "content": "Existen m√°s de 400 razas de perros reconocidas, cada una criada para tareas espec√≠ficas. Las razas pastoriles (Border Collies, Pastores) manejan reba√±os, las de caza (Retrievers, Spaniels) asisten en la caza, mientras que las razas guardianas (Dobermans, Rottweilers) protegen propiedades. Las razas de compa√±√≠a (Chihuahuas, Terriers) se cr√≠an exclusivamente para compa√±√≠a."}},
    {{"title": "Inteligencia Canina", "search_keyword": "dog intelligence training cognition", "content": "Los perros pueden memorizar hasta 165 palabras y gestos, comparable a las habilidades cognitivas de un ni√±o de dos a√±os. Los Border Collies se consideran la raza m√°s inteligente, comprendiendo nuevos comandos tras solo 5 repeticiones. Las investigaciones muestran que los perros distinguen emociones humanas a trav√©s de expresiones faciales y tono de voz."}}
  ]
}}

INCORRECTO (frases plantilla):
"Los perros se est√°n convirtiendo en un factor clave en la sociedad moderna. La adopci√≥n de estas tecnolog√≠as desbloquea nuevas posibilidades."

CORRECTO (hechos concretos):
"Los perros poseen un sentido del olfato 10,000 veces m√°s agudo que los humanos debido a 300 millones de receptores olfativos. Esto les permite detectar drogas, explosivos e incluso diagnosticar c√°ncer en etapas tempranas."

Devuelve SOLO JSON v√°lido sin texto adicional.

CR√çTICO: 
- Cada tesis debe contener HECHOS, N√öMEROS, EJEMPLOS relacionados con "{topic}"
- NO uses frases gen√©ricas sobre "tecnolog√≠a", "innovaci√≥n", "futuro" sin especificaciones
- El t√≠tulo y contenido de cada diapositiva deben estar L√ìGICAMENTE conectados
- Cada search_keyword debe ser DIFERENTE y espec√≠fico"""
        elif language == 'zh':
            prompt = f"""ÂàõÂª∫ÂÖ≥‰∫é‰∏ªÈ¢ò "{topic}" ÁöÑÁªìÊûÑÂåñÊºîÁ§∫ÊñáÁ®ø
ÂπªÁÅØÁâáÊï∞Èáè: {num_slides}

ÈáçË¶ÅÔºöÊºîÁ§∫ÊñáÁ®øÂøÖÈ°ªÁî±ËÆ∫ÁÇπÈôàËø∞ÁªÑÊàêÔºåËÄå‰∏çÊòØÊèèËø∞ÔºÅ

ËÆ∫ÁÇπ ‚Äî Êè≠Á§∫‰∏ªÈ¢òÈÉ®ÂàÜÂÜÖÂÆπÁöÑÂÖ≥ÈîÆÈôàËø∞„ÄÇ
‰∏çË¶ÅÂè™ÊòØÊèèËø∞ÔºåË¶ÅÊèêÂá∫ÂÖ∑‰ΩìÁöÑÊÉ≥Ê≥ïÂíåËÆ∫ÊçÆ„ÄÇ

ËÆ∫ÁÇπÁªìÊûÑÔºö
- ÂπªÁÅØÁâá 1: ‰∏ªÈ¢òÁöÑ‰∏ªË¶ÅËßÇÁÇπÔºàÊ†∏ÂøÉÈôàËø∞Ôºâ
- ÂπªÁÅØÁâá 2-{num_slides-1}: ÂÖ≥ÈîÆÊñπÈù¢„ÄÅ‰ºòÂäø„ÄÅÂ∫îÁî®
- ÂπªÁÅØÁâá {num_slides}: ÁªìËÆ∫„ÄÅÊú™Êù•„ÄÅË¶ÅÁÇπ

ÊØè‰∏™ËÆ∫ÁÇπÂøÖÈ°ªÔºö
‚úì ÊòØ‰∏é "{topic}" Áõ¥Êé•Áõ∏ÂÖ≥ÁöÑÂÖ∑‰ΩìÈôàËø∞
‚úì ÂåÖÂê´ 2-3 ‰∏™Â∏¶ÊúâÂÖ∑‰ΩìÁªÜËäÇÂíåÁ§∫‰æãÁöÑÁ≤æÁ°ÆÂè•Â≠ê
‚úì ÂèëÂ±ï‰∏ªË¶Å‰∏ªÈ¢ò
‚úì ‰∏éÂÖ∂‰ªñËÆ∫ÁÇπÂΩ¢ÊàêÈÄªËæëÈìæ
‚úì ÈÅøÂÖç‰ΩøÁî® "ÂÖ≥ÈîÆÊäÄÊúØ"„ÄÅ"Êï∞Â≠óÊó∂‰ª£"„ÄÅ"Áé∞‰ª£Á§æ‰ºö" Á≠âÊ®°ÊùøÁü≠ËØ≠
‚úì ‰ΩøÁî®‰ªÖ‰∏é "{topic}" Áõ∏ÂÖ≥ÁöÑÁâπÂÆöÊúØËØ≠Âíå‰∫ãÂÆû

ÂØπ‰∫éÊØèÂº†ÂπªÁÅØÁâáÔºåËøîÂõûÂåÖÂê´‰ª•‰∏ãÂ≠óÊÆµÁöÑ JSONÔºö
- "title": ÁÆÄÁü≠Ê†áÈ¢òÔºà2-3 ‰∏™ËØçÔºâÔºåÈíàÂØπ‰∏ªÈ¢ò
- "search_keyword": Ëã±ÊñáÂõæÂÉèÊêúÁ¥¢ÂÖ≥ÈîÆËØçÔºà3-4 ‰∏™ËØçÔºâ
- "content": ËÆ∫ÁÇπ ‚Äî ÂÖ∑‰ΩìÈôàËø∞Ôºà2-3 ‰∏™Â∏¶ÁªÜËäÇÁöÑÂè•Â≠êÔºâ

"Áãó" ÁöÑÊ≠£Á°ÆËÆ∫ÁÇπÁ§∫‰æãÔºö
{{
  "slides": [
    {{"title": "ÁãóÁöÑËøõÂåñ", "search_keyword": "dog evolution wolf domestication", "content": "ÁãóÂ§ßÁ∫¶Âú® 15,000 Âπ¥ÂâçÈÄöËøáÈ©ØÂåñ‰ªéÁãºËøõÂåñËÄåÊù•„ÄÇÂü∫Âõ†Á†îÁ©∂Ë°®ÊòéÔºåÁ¨¨‰∏ÄÊâπÁãóÂá∫Áé∞Âú®‰∏ú‰∫öÔºåÂπ∂ÈöèÁùÄ‰∫∫Á±ª‰º†Êí≠Âà∞‰∏ñÁïåÂêÑÂú∞„ÄÇÁé∞‰ª£ÂìÅÁßçÊòØËøáÂéª 200 Âπ¥ÈÄâÊã©ÊÄßÁπÅÊÆñÁöÑÁªìÊûú„ÄÇ"}},
    {{"title": "ÂìÅÁßçÂíåÂäüËÉΩ", "search_keyword": "dog breeds working dogs types", "content": "ÊúâË∂ÖËøá 400 ÁßçË¢´ËÆ§ÂèØÁöÑÁãóÂìÅÁßçÔºåÊØèÁßçÈÉΩ‰∏∫ÁâπÂÆö‰ªªÂä°ËÄåÂüπËÇ≤„ÄÇÁâßÁæäÁä¨ÔºàËæπÂ¢ÉÁâßÁæäÁä¨„ÄÅÂæ∑ÂõΩÁâßÁæäÁä¨ÔºâÁÆ°ÁêÜÁâ≤ÁïúÔºåÁåéÁä¨ÔºàÂØªÂõûÁä¨„ÄÅË•øÁè≠ÁâôÁåéÁä¨ÔºâÂçèÂä©Áã©ÁåéÔºåËÄåÊä§Âç´Áä¨ÔºàÊùúÂÆæÁä¨„ÄÅÁΩóÂ®ÅÁ∫≥Áä¨Ôºâ‰øùÊä§Ë¥¢‰∫ß„ÄÇÁé©ÂÖ∑Áä¨ÔºàÂêâÂ®ÉÂ®É„ÄÅÊ¢óÁä¨Ôºâ‰∏ìÈó®Áî®‰∫é‰º¥‰æ£„ÄÇ"}},
    {{"title": "Áä¨Á±ªÊô∫Âäõ", "search_keyword": "dog intelligence training cognition", "content": "ÁãóËÉΩËÆ∞‰ΩèÂ§öËææ 165 ‰∏™ÂçïËØçÂíåÊâãÂäøÔºåÁõ∏ÂΩì‰∫é‰∏§Â≤ÅÂÑøÁ´•ÁöÑËÆ§Áü•ËÉΩÂäõ„ÄÇËæπÂ¢ÉÁâßÁæäÁä¨Ë¢´ËÆ§‰∏∫ÊòØÊúÄËÅ™ÊòéÁöÑÂìÅÁßçÔºåÂè™ÈúÄ 5 Ê¨°ÈáçÂ§çÂ∞±ËÉΩÁêÜËß£Êñ∞ÂëΩ‰ª§„ÄÇÁ†îÁ©∂Ë°®ÊòéÁãóËÉΩÈÄöËøáÈù¢ÈÉ®Ë°®ÊÉÖÂíåËØ≠Ë∞ÉÂå∫ÂàÜ‰∫∫Á±ªÊÉÖÊÑü„ÄÇ"}}
  ]
}}

ÈîôËØØÔºàÊ®°ÊùøÁü≠ËØ≠ÔºâÔºö
"ÁãóÊ≠£Âú®Êàê‰∏∫Áé∞‰ª£Á§æ‰ºöÂèëÂ±ïÁöÑÂÖ≥ÈîÆÂõ†Á¥†„ÄÇÈááÁî®Ëøô‰∫õÊäÄÊúØÂºÄÂêØ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇ"

Ê≠£Á°ÆÔºàÂÖ∑‰Ωì‰∫ãÂÆûÔºâÔºö
"ÁãóÁöÑÂóÖËßâÊØî‰∫∫Á±ªÊïèÈîê 10,000 ÂÄçÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Êã•Êúâ 3 ‰∫ø‰∏™ÂóÖËßâÂèó‰Ωì„ÄÇËøô‰ΩøÂÆÉ‰ª¨ËÉΩÂ§üÊ£ÄÊµãÊØíÂìÅ„ÄÅÁàÜÁÇ∏Áâ©ÔºåÁîöËá≥Âú®Êó©ÊúüËØäÊñ≠ÁôåÁóá„ÄÇ"

‰ªÖËøîÂõûÊúâÊïàÁöÑ JSONÔºå‰∏çÂåÖÂê´È¢ùÂ§ñÊñáÊú¨„ÄÇ

ÂÖ≥ÈîÆÔºö
- ÊØè‰∏™ËÆ∫ÁÇπÂøÖÈ°ªÂåÖÂê´‰∏é "{topic}" Áõ∏ÂÖ≥ÁöÑÂÖ∑‰Ωì‰∫ãÂÆû„ÄÅÊï∞Â≠ó„ÄÅÁ§∫‰æã
- ‰∏çË¶Å‰ΩøÁî®Ê≤°ÊúâÂÖ∑‰ΩìËØ¥ÊòéÁöÑ "ÊäÄÊúØ"„ÄÅ"ÂàõÊñ∞"„ÄÅ"Êú™Êù•" Á≠âÈÄöÁî®Áü≠ËØ≠
- ÊØèÂº†ÂπªÁÅØÁâáÁöÑÊ†áÈ¢òÂíåÂÜÖÂÆπÂøÖÈ°ªÂú®ÈÄªËæë‰∏äÁõ∏ÂÖ≥ËÅî
- ÊØè‰∏™ search_keyword ÂøÖÈ°ªÊòØ‰∏çÂêåÁöÑ‰∏îÂÖ∑‰ΩìÁöÑ"""
        elif language == 'fr':
            prompt = f"""Cr√©ez une pr√©sentation structur√©e sur le sujet : "{topic}"
Nombre de diapositives : {num_slides}

IMPORTANT : La pr√©sentation doit consister en des D√âCLARATIONS DE TH√àSE, pas des descriptions.

TH√àSE ‚Äî une d√©claration cl√© qui r√©v√®le une partie du sujet.
Ne d√©crivez pas seulement, formulez des id√©es et arguments sp√©cifiques.

STRUCTURE DES TH√àSES :
- Diapositive 1 : Id√©e principale du sujet (d√©claration centrale)
- Diapositives 2-{num_slides-1} : Aspects cl√©s, avantages, applications
- Diapositive {num_slides} : Conclusion, avenir, point de vue

Chaque th√®se doit :
‚úì √ätre une d√©claration sp√©cifique directement li√©e √† "{topic}"
‚úì Contenir 2-3 phrases pr√©cises avec des D√âTAILS et EXEMPLES CONCR√âTS
‚úì D√©velopper le sujet principal
‚úì Former une cha√Æne logique avec les autres th√®ses
‚úì √âVITER les phrases mod√®les comme "technologie cl√©", "√®re num√©rique", "soci√©t√© moderne"
‚úì Utiliser une TERMINOLOGIE SP√âCIFIQUE et des faits pertinents uniquement pour "{topic}"

Pour chaque diapositive, retournez JSON avec les champs :
- "title" : Titre bref (2-3 mots) sp√©cifique au sujet
- "search_keyword" : Mots-cl√©s pour recherche d'images en anglais (3-4 mots)
- "content" : TH√àSE ‚Äî d√©claration sp√©cifique (2-3 phrases avec d√©tails)

EXEMPLE de th√®ses correctes pour "Chiens" :
{{
  "slides": [
    {{"title": "√âvolution des Chiens", "search_keyword": "dog evolution wolf domestication", "content": "Les chiens descendent des loups il y a environ 15 000 ans par domestication. Les recherches g√©n√©tiques montrent que les premiers chiens sont apparus en Asie de l'Est et se sont r√©pandus dans le monde avec les humains. Les races modernes sont le r√©sultat de l'√©levage s√©lectif au cours des 200 derni√®res ann√©es."}},
    {{"title": "Races et Fonctions", "search_keyword": "dog breeds working dogs types", "content": "Plus de 400 races de chiens reconnues existent, chacune √©lev√©e pour des t√¢ches sp√©cifiques. Les races de berger (Border Collies, Bergers) g√®rent les troupeaux, les races de chasse (Retrievers, √âpagneuls) aident √† la chasse, tandis que les races de garde (Dobermans, Rottweilers) prot√®gent les propri√©t√©s. Les races de compagnie (Chihuahuas, Terriers) sont √©lev√©es exclusivement pour la compagnie."}},
    {{"title": "Intelligence Canine", "search_keyword": "dog intelligence training cognition", "content": "Les chiens peuvent m√©moriser jusqu'√† 165 mots et gestes, comparable aux capacit√©s cognitives d'un enfant de deux ans. Les Border Collies sont consid√©r√©s comme la race la plus intelligente, comprenant de nouvelles commandes apr√®s seulement 5 r√©p√©titions. Les recherches montrent que les chiens distinguent les √©motions humaines par les expressions faciales et le ton de la voix."}}
  ]
}}

INCORRECT (phrases mod√®les) :
"Les chiens deviennent un facteur cl√© dans la soci√©t√© moderne. L'adoption de ces technologies d√©bloque de nouvelles possibilit√©s."

CORRECT (faits concrets) :
"Les chiens poss√®dent un sens de l'odorat 10 000 fois plus aigu que les humains gr√¢ce √† 300 millions de r√©cepteurs olfactifs. Cela leur permet de d√©tecter des drogues, des explosifs et m√™me de diagnostiquer le cancer √† un stade pr√©coce."

Retournez SEULEMENT du JSON valide sans texte suppl√©mentaire.

CRITIQUE : 
- Chaque th√®se doit contenir des FAITS CONCR√âTS, des NOMBRES, des EXEMPLES li√©s √† "{topic}"
- N'utilisez PAS de phrases g√©n√©riques sur "technologie", "innovation", "avenir" sans pr√©cisions
- Le titre et le contenu de chaque diapositive doivent √™tre LI√âS LOGIQUEMENT
- Chaque search_keyword doit √™tre DIFF√âRENT et sp√©cifique"""
        else:  # Default to English
            type_name_en = type_info.get('name_en', 'Presentation')
            prompt = f"""Create a structured presentation on topic: "{topic}"
Number of slides: {num_slides}
Presentation type: {type_name_en}

RECOMMENDED STRUCTURE FOR THIS TYPE:
{structure_text}

STYLE ADVICE: {tips}

üéØ CRITICAL QUALITY REQUIREMENTS:

1. DEPTH AND UNIQUENESS:
   ‚Ä¢ Each slide must contain UNEXPECTED facts, little-known data, or original insights
   ‚Ä¢ DO NOT limit to common knowledge - dive into niche details
   ‚Ä¢ Each slide is unique in its angle of topic exploration
   ‚Ä¢ Target professionals and enthusiasts, not beginners

2. SPECIFICITY AND EVIDENCE:
   ‚Ä¢ MUST include: researcher names, study years, institution names
   ‚Ä¢ Provide exact numbers and statistics (don't round: instead of "about 100" write "127 cases")
   ‚Ä¢ Reference specific cases, practical examples from real practice
   ‚Ä¢ If no data available - state well-founded hypothesis or critical analysis

3. TEMPLATE BAN:
   ‚Ä¢ STRICTLY AVOID phrases: "in modern world", "in digital era", "key factor", "new opportunities", "innovative solutions"
   ‚Ä¢ DO NOT use identical sentence structures across slides
   ‚Ä¢ DO NOT end slides with similar formulations
   ‚Ä¢ Each slide must have its own authorial writing style

4. CONTENT FORMAT:
   ‚Ä¢ Each slide: 3-4 sentences with SPECIFIC details
   ‚Ä¢ Minimum 1-2 unexpected facts per slide
   ‚Ä¢ Use analogies, comparisons, critical analysis
   ‚Ä¢ Final slide: forecasts, open questions, challenges for future research

EXAMPLE OF DEEP CONTENT for "Neural networks for diagnosing rare animal diseases":
{{
  "slides": [
    {{
      "title": "Underdiagnosis Problem",
      "search_keyword": "veterinary diagnostics rare disease animals",
      "image_prompt": "veterinarian examining sick exotic pet in modern diagnostic clinic",
      "content": "According to Dr. Sarah Mitchell's study (Cornell University, 2022), only 12% of rare diseases in domestic animals are diagnosed during lifetime. Primary cause: veterinarians lack experience recognizing atypical symptoms. For Cushing's syndrome in ferrets, average time to diagnosis is 8.3 months, critical given 6-8 year lifespan."
    }},
    {{
      "title": "CNN Architecture for Pathology",
      "search_keyword": "convolutional neural network medical imaging",
      "image_prompt": "medical imaging neural network analyzing microscopy pathology slides",
      "content": "UC Davis team developed ResNet-152 convolutional network trained on 47,000 histopathological images of exotic animals. Lymphoma detection accuracy in parrots reached 94.7%, exceeding experienced pathologists (89.2%). Critical: network detects patterns invisible to human eye ‚Äî anisocytosis at 3-5 micron level."
    }},
    {{
      "title": "Few-Shot Learning Dilemma",
      "search_keyword": "few shot learning medical AI",
      "image_prompt": "small dataset machine learning training process visualization",
      "content": "Only 340 documented biopsy-confirmed cases exist for von Willebrand disease in Dobermans. Few-shot learning with metric spaces (Prototypical Networks) achieved 78% accuracy training on just 15 examples. However, overfitting risk emerges: model may memorize artifacts of specific clinics rather than true disease patterns."
    }},
    {{
      "title": "Open Challenges",
      "search_keyword": "AI challenges veterinary medicine future",
      "image_prompt": "diverse veterinary professionals discussing AI technology challenges",
      "content": "Three unsolved issues hamper adoption: 1) Lack of standardized data collection protocols between clinics (89% databases incompatible); 2) Ethical dilemma ‚Äî who bears responsibility for AI diagnostic errors?; 3) Distribution shift phenomenon ‚Äî models trained on US data show 23-31% accuracy drop when tested on Asian breeds. Federated learning approaches required."
    }}
  ]
}}

INCORRECT (templates and generic phrases):
"Neural networks unlock new opportunities in veterinary medicine. Modern world technologies enable faster disease diagnosis."

CORRECT (specificity and depth):
"YOLO-v5 algorithm adapted by Prof. Chen's group for reptile X-rays detects metabolic bone disease in iguanas with 91.3% sensitivity ‚Äî 34% higher than average herpetologist practitioners."

CRITICAL - RESPONSE STRUCTURE:
For each slide you MUST return:
- "title" - slide title
- "search_keyword" - keywords for image search IN ENGLISH (3-5 words)
- "content" - slide content
- "image_prompt" - (OPTIONAL) detailed description of ideal image in ENGLISH (5-12 words)

RESPONSE FORMAT:
Return ONLY valid JSON in format:
{{
  "slides": [
    {{"title": "...", "search_keyword": "...", "content": "..."}},
    ...
  ]
}}

No markdown, no additional text."""


        data = {
            'model': 'gpt-3.5-turbo',
            'messages': [
                {'role': 'system', 'content': f"{system_prompt}\n\nAlways respond with valid JSON only. Generate content in {language_name}."},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': temperature,  # Use type-specific temperature (0.2 for scientific, 0.6 for business, 0.7 for general)
            'max_tokens': 2500  # Increased for detailed, in-depth responses
        }
        
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"OpenAI API error: {response.status_code} - {response.text}")
        
        result = response.json()
        content = result['choices'][0]['message']['content'].strip()
        
        # Try to parse JSON from response
        # Remove markdown code blocks if present
        if content.startswith('```'):
            content = content.split('```')[1]
            if content.startswith('json'):
                content = content[4:]
            content = content.strip()
        
        slides_data = json.loads(content)
        return slides_data.get('slides', [])
        
    except json.JSONDecodeError as e:
        print(f"JSON parsing error: {e}")
        print(f"Response content: {content}")
        # Fail instead of generating low-quality fallback
        return None
    except Exception as e:
        print(f"Error generating content: {e}")
        # Fail instead of generating low-quality fallback
        return None


def create_fallback_slides(topic, num_slides, language='en'):
    """
    Create fallback slides if API fails with language support
    """
    slides = []
    
    # Language-specific fallback content
    if language == 'ru':
        slides.append({
            'title': f'{topic} –∏–∑–º–µ–Ω—è–µ—Ç –º–∏—Ä',
            'search_keyword': f'{topic} innovation future technology',
            'content': f'{topic} —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º —Ñ–∞–∫—Ç–æ—Ä–æ–º —Ä–∞–∑–≤–∏—Ç–∏—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–±—â–µ—Å—Ç–≤–∞. –í–Ω–µ–¥—Ä–µ–Ω–∏–µ —ç—Ç–∏—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ –∏ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏. –ü–æ–Ω–∏–º–∞–Ω–∏–µ {topic} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è —É—Å–ø–µ—Ö–∞ –≤ —Ü–∏—Ñ—Ä–æ–≤—É—é —ç–ø–æ—Ö—É.'
        })
        
        thesis_templates = [
            ('–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞', 'key benefits advantages', lambda t: f'{t} –ø–æ–≤—ã—à–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã –∏ —Å–Ω–∏–∂–∞–µ—Ç –∏–∑–¥–µ—Ä–∂–∫–∏. –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á–∞—Ö. –ö–æ–º–ø–∞–Ω–∏–∏, –≤–Ω–µ–¥—Ä–∏–≤—à–∏–µ {t}, –ø–æ–ª—É—á–∞—é—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –Ω–∞ —Ä—ã–Ω–∫–µ.'),
            ('–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ', 'real world practical use', lambda t: f'–†–µ–∞–ª—å–Ω—ã–µ –∫–µ–π—Å—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å {t} –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ—Ç—Ä–∞—Å–ª—è—Ö. –û—Ç –º–µ–¥–∏—Ü–∏–Ω—ã –¥–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è —Ä–µ—à–∞–µ—Ç —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏. –£—Å–ø–µ—à–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—Ç –Ω–∞ –¥–∞–ª—å–Ω–µ–π—à–µ–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏–µ.'),
            ('–í—ã–∑–æ–≤—ã –∏ —Ä–µ—à–µ–Ω–∏—è', 'challenges solutions problems', lambda t: f'–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏—è –ø—Ä–∏ –≤–Ω–µ–¥—Ä–µ–Ω–∏–∏ {t} –≤–∫–ª—é—á–∞—é—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –±–∞—Ä—å–µ—Ä—ã. –û–¥–Ω–∞–∫–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –ø–æ–∑–≤–æ–ª—è—é—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞—Ç—å —ç—Ç–∏ —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç —Ä–∏—Å–∫–∏ –∏ —É—Å–∫–æ—Ä—è–µ—Ç –∞–¥–∞–ø—Ç–∞—Ü–∏—é.'),
            ('–ë—É–¥—É—â–µ–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', 'future innovation development', lambda t: f'{t} –±—É–¥–µ—Ç –∏–≥—Ä–∞—Ç—å –≤—Å—ë –±–æ–ª–µ–µ –≤–∞–∂–Ω—É—é —Ä–æ–ª—å –≤ –±–ª–∏–∂–∞–π—à–∏–µ –≥–æ–¥—ã. –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏ —Ä–∞—Å—Ç—É—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ. –¢–µ, –∫—Ç–æ –æ—Å–≤–æ–∏—Ç {t} —Å–µ–≥–æ–¥–Ω—è, —Å—Ç–∞–Ω—É—Ç –ª–∏–¥–µ—Ä–∞–º–∏ –∑–∞–≤—Ç—Ä–∞—à–Ω–µ–≥–æ –¥–Ω—è.')
        ]
        
        for i in range(1, min(num_slides, len(thesis_templates) + 1)):
            title, keywords, content_func = thesis_templates[i - 1]
            slides.append({
                'title': title,
                'search_keyword': f'{topic} {keywords}',
                'content': content_func(topic)
            })
            
    elif language == 'es':
        slides.append({
            'title': f'{topic} Revoluciona',
            'search_keyword': f'{topic} innovacion futuro tecnologia',
            'content': f'{topic} est√° redefiniendo c√≥mo abordamos los desaf√≠os y oportunidades modernos. La adopci√≥n de estas tecnolog√≠as desbloquea nuevo potencial para negocios y vida diaria. Dominar {topic} es fundamental para el √©xito en la era digital.'
        })
        
        thesis_templates = [
            ('Ventajas Clave', 'ventajas beneficios clave', lambda t: f'{t} mejora dr√°sticamente la eficiencia mientras reduce costos operativos. La automatizaci√≥n permite a los equipos enfocarse en iniciativas estrat√©gicas en lugar de tareas rutinarias. Las organizaciones que implementan {t} obtienen ventajas competitivas significativas en sus mercados.'),
            ('Impacto en el Mundo Real', 'impacto aplicaciones practicas', lambda t: f'Las historias de √©xito demuestran la efectividad de {t} en diversas industrias. Desde la salud hasta las finanzas, la tecnolog√≠a resuelve problemas anteriormente intratables. Estos ejemplos probados inspiran mayor adopci√≥n e innovaci√≥n.'),
            ('Superando Desaf√≠os', 'desafios soluciones problemas', lambda t: f'Los obst√°culos principales para la adopci√≥n de {t} incluyen complejidad t√©cnica y resistencia organizacional. Los marcos y metodolog√≠as modernos abordan efectivamente estas barreras. La planificaci√≥n estrat√©gica minimiza riesgos y acelera la implementaci√≥n exitosa.'),
            ('Perspectiva Futura', 'futuro innovacion desarrollo', lambda t: f'{t} jugar√° un papel cada vez m√°s vital en dar forma al ma√±ana. La inversi√≥n en este campo crece exponencialmente a√±o tras a√±o. Los primeros adoptantes de {t} se posicionan como l√≠deres del futuro.')
        ]
        
        for i in range(1, min(num_slides, len(thesis_templates) + 1)):
            title, keywords, content_func = thesis_templates[i - 1]
            slides.append({
                'title': title,
                'search_keyword': f'{topic} {keywords}',
                'content': content_func(topic)
            })
            
    elif language == 'zh':
        slides.append({
            'title': f'{topic} Èù©ÂëΩ',
            'search_keyword': f'{topic} innovation future technology',
            'content': f'{topic} Ê≠£Âú®ÈáçÂ°ëÊàë‰ª¨Â∫îÂØπÁé∞‰ª£ÊåëÊàòÂíåÊú∫ÈÅáÁöÑÊñπÂºè„ÄÇÈááÁî®Ëøô‰∫õÊäÄÊúØ‰∏∫‰∏öÂä°ÂíåÊó•Â∏∏ÁîüÊ¥ªÂºÄÂêØ‰∫ÜÊñ∞ÁöÑÂèØËÉΩÊÄß„ÄÇÊéåÊè° {topic} ÂØπ‰∫éÊï∞Â≠óÊó∂‰ª£ÁöÑÊàêÂäüËá≥ÂÖ≥ÈáçË¶Å„ÄÇ'
        })
        
        thesis_templates = [
            ('ÂÖ≥ÈîÆ‰ºòÂäø', 'key benefits advantages', lambda t: f'{t} ÊòæËëóÊèêÈ´òÊïàÁéáÂêåÊó∂Èôç‰ΩéËøêËê•ÊàêÊú¨„ÄÇËá™Âä®Âåñ‰ΩøÂõ¢ÈòüËÉΩÂ§ü‰∏ìÊ≥®‰∫éÊàòÁï•‰∏æÊé™ËÄåÈùûÊó•Â∏∏‰ªªÂä°„ÄÇÂÆûÊñΩ {t} ÁöÑÁªÑÁªáÂú®ÂÖ∂Â∏ÇÂú∫‰∏≠Ëé∑ÂæóÊòæËëóÁöÑÁ´û‰∫â‰ºòÂäø„ÄÇ'),
            ('Áé∞ÂÆû‰∏ñÁïåÂΩ±Âìç', 'real world practical applications', lambda t: f'ÊàêÂäüÊ°à‰æãËØÅÊòé‰∫Ü {t} Âú®‰∏çÂêåË°å‰∏öÁöÑÊúâÊïàÊÄß„ÄÇ‰ªéÂåªÁñó‰øùÂÅ•Âà∞ÈáëËûçÔºåËØ•ÊäÄÊúØËß£ÂÜ≥‰∫Ü‰ª•ÂâçÈöæ‰ª•Ëß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇËøô‰∫õÁªèËøáÈ™åËØÅÁöÑ‰æãÂ≠êÊøÄÂä±ÁùÄËøõ‰∏ÄÊ≠•ÁöÑÈááÁî®ÂíåÂàõÊñ∞„ÄÇ'),
            ('ÂÖãÊúçÊåëÊàò', 'challenges solutions problems', lambda t: f'{t} ÈááÁî®ÁöÑ‰∏ªË¶ÅÈöúÁ¢çÂåÖÊã¨ÊäÄÊúØÂ§çÊùÇÊÄßÂíåÁªÑÁªáÈòªÂäõ„ÄÇÁé∞‰ª£Ê°ÜÊû∂ÂíåÊñπÊ≥ïÊúâÊïàÂú∞Ëß£ÂÜ≥‰∫ÜËøô‰∫õÈöúÁ¢ç„ÄÇÊàòÁï•ËßÑÂàíÂ∞ÜÈ£éÈô©ÈôçËá≥ÊúÄ‰ΩéÂπ∂Âä†ÈÄüÊàêÂäüÂÆûÊñΩ„ÄÇ'),
            ('Êú™Êù•Â±ïÊúõ', 'future innovation development', lambda t: f'{t} Â∞ÜÂú®Â°ëÈÄ†Êú™Êù•‰∏≠ÂèëÊå•Ë∂äÊù•Ë∂äÈáçË¶ÅÁöÑ‰ΩúÁî®„ÄÇËØ•È¢ÜÂüüÁöÑÊäïËµÑÊ≠£Âú®ÈÄêÂπ¥ÊåáÊï∞Á∫ßÂ¢ûÈïø„ÄÇÊó©ÊúüÈááÁî® {t} ÁöÑ‰∫∫Â∞ÜËá™Â∑±ÂÆö‰Ωç‰∏∫Êú™Êù•ÁöÑÈ¢ÜÂØºËÄÖ„ÄÇ')
        ]
        
        for i in range(1, min(num_slides, len(thesis_templates) + 1)):
            title, keywords, content_func = thesis_templates[i - 1]
            slides.append({
                'title': title,
                'search_keyword': f'{topic} {keywords}',
                'content': content_func(topic)
            })
            
    elif language == 'fr':
        slides.append({
            'title': f'{topic} R√©volution',
            'search_keyword': f'{topic} innovation future technologie',
            'content': f'{topic} red√©finit comment nous abordons les d√©fis et opportunit√©s modernes. L\'adoption de ces technologies d√©bloque de nouvelles possibilit√©s pour les entreprises et la vie quotidienne. Ma√Ætriser {topic} est essentiel pour r√©ussir √† l\'√®re num√©rique.'
        })
        
        thesis_templates = [
            ('Avantages Cl√©s', 'avantages b√©n√©fices cl√©s', lambda t: f'{t} am√©liore drastiquement l\'efficacit√© tout en r√©duisant les co√ªts op√©rationnels. L\'automatisation permet aux √©quipes de se concentrer sur des initiatives strat√©giques au lieu de t√¢ches routini√®res. Les organisations impl√©mentant {t} gagnent des avantages comp√©titifs significatifs sur leurs march√©s.'),
            ('Impact R√©el', 'impact applications pratiques', lambda t: f'Les histoires de r√©ussite d√©montrent l\'efficacit√© de {t} dans diverses industries. De la sant√© aux finances, la technologie r√©sout des probl√®mes auparavant intractables. Ces exemples √©prouv√©s inspirent une adoption et une innovation suppl√©mentaires.'),
            ('Surmonter les D√©fis', 'd√©fis solutions probl√®mes', lambda t: f'Les obstacles principaux √† l\'adoption de {t} incluent la complexit√© technique et la r√©sistance organisationnelle. Les cadres et m√©thodologies modernes traitent efficacement ces barri√®res. La planification strat√©gique minimise les risques et acc√©l√®re l\'impl√©mentation r√©ussie.'),
            ('Aper√ßu Futur', 'futur innovation d√©veloppement', lambda t: f'{t} jouera un r√¥le de plus en plus vital dans fa√ßonner demain. L\'investissement dans ce domaine cro√Æt exponentiellement ann√©e apr√®s ann√©e. Les premiers adoptants de {t} se positionnent comme les leaders de l\'avenir.')
        ]
        
        for i in range(1, min(num_slides, len(thesis_templates) + 1)):
            title, keywords, content_func = thesis_templates[i - 1]
            slides.append({
                'title': title,
                'search_keyword': f'{topic} {keywords}',
                'content': content_func(topic)
            })
    else:  # Default to English
        slides.append({
            'title': f'{topic} Revolution',
            'search_keyword': f'{topic} innovation future technology',
            'content': f'{topic} is reshaping how we approach modern challenges and opportunities. The adoption of these technologies unlocks new potential for businesses and daily life. Mastering {topic} is critical for success in the digital age.'
        })
        
        thesis_templates = [
            ('Key Advantages', 'key benefits advantages', lambda t: f'{t} dramatically improves efficiency while reducing operational costs. Automation enables teams to focus on strategic initiatives instead of routine tasks. Organizations implementing {t} gain significant competitive advantages in their markets.'),
            ('Real-World Impact', 'real world practical applications', lambda t: f'Success stories demonstrate the effectiveness of {t} across diverse industries. From healthcare to finance, the technology solves previously intractable problems. These proven examples inspire further adoption and innovation.'),
            ('Overcoming Challenges', 'challenges solutions problems', lambda t: f'Primary obstacles to {t} adoption include technical complexity and organizational resistance. Modern frameworks and methodologies effectively address these barriers. Strategic planning minimizes risks and accelerates successful implementation.'),
            ('Future Outlook', 'future innovation development', lambda t: f'{t} will play an increasingly vital role in shaping tomorrow. Investment in this field is growing exponentially year over year. Early adopters of {t} position themselves as leaders of the future.')
        ]
        
        for i in range(1, min(num_slides, len(thesis_templates) + 1)):
            title, keywords, content_func = thesis_templates[i - 1]
            slides.append({
                'title': title,
                'search_keyword': f'{topic} {keywords}',
                'content': content_func(topic)
            })
    
    return slides


def get_cached_image_path(keywords):
    """
    Get cached image path based on keyword hash
    """
    cache_key = hashlib.md5(keywords.encode('utf-8')).hexdigest()
    cache_file = os.path.join(IMAGE_CACHE_DIR, f"{cache_key}.jpg")
    
    if os.path.exists(cache_file):
        print(f"  ‚ö° Using cached image for '{keywords}'")
        return cache_file
    
    return None


def save_image_to_cache(image_data, keywords):
    """
    Save downloaded image to cache
    """
    try:
        cache_key = hashlib.md5(keywords.encode('utf-8')).hexdigest()
        cache_file = os.path.join(IMAGE_CACHE_DIR, f"{cache_key}.jpg")
        
        with open(cache_file, 'wb') as f:
            f.write(image_data.getvalue())
        
        return cache_file
    except Exception as e:
        print(f"  ‚ö† Error caching image: {e}")
        return None


# ============================================================================
# Image Search API - Multi-source with fallback and rate limiting
# ============================================================================

# Rate limiting state
API_CALL_TIMES = {'pexels': [], 'unsplash': []}
MAX_CALLS_PER_MINUTE = {'pexels': 50, 'unsplash': 50}  # API limits

def can_make_api_call(service):
    """
    Check if we can make API call based on rate limits
    Returns True if allowed, False if rate limit exceeded
    """
    import time
    current_time = time.time()
    
    # Clean old calls (older than 60 seconds)
    API_CALL_TIMES[service] = [
        t for t in API_CALL_TIMES[service] 
        if current_time - t < 60
    ]
    
    # Check limit
    if len(API_CALL_TIMES[service]) >= MAX_CALLS_PER_MINUTE[service]:
        print(f"  ‚ö† Rate limit reached for {service}")
        return False
    
    # Record this call
    API_CALL_TIMES[service].append(current_time)
    return True


# ============================================================================
# IMAGE PROVIDER LAYER - Multi-source image fetching
# ============================================================================
# This layer provides a unified interface for fetching images from multiple
# sources (Pexels, Unsplash) with automatic fallback and error handling

# ============================================================================
# USED IMAGES TRACKING SYSTEM
# ============================================================================
# Prevents duplicate images within presentations and across recent generations

def get_used_images_for_user(user_id, limit=100):
    """
    Get list of recently used image URLs for a user
    
    Args:
        user_id: User ID to fetch images for
        limit: Maximum number of recent images to return (default: 100)
    
    Returns:
        List of image URLs (strings)
    """
    if not user_id:
        return []
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute(
            '''SELECT image_url FROM used_images 
               WHERE user_id = ? 
               ORDER BY used_date DESC 
               LIMIT ?''',
            (user_id, limit)
        )
        rows = cursor.fetchall()
        conn.close()
        return [row[0] for row in rows]
    except Exception as e:
        print(f"‚ö†Ô∏è Error fetching used images: {e}")
        return []


def add_used_image(user_id, image_url, query=''):
    """
    Add an image to the used images tracking table
    
    Args:
        user_id: User ID who used the image
        image_url: URL of the image
        query: Search query used to find the image (optional)
    """
    if not user_id or not image_url:
        return
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute(
            '''INSERT INTO used_images (user_id, image_url, image_query)
               VALUES (?, ?, ?)''',
            (user_id, image_url, query)
        )
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"‚ö†Ô∏è Error adding used image: {e}")


def cleanup_old_used_images(user_id, keep_count=100):
    """
    Remove old used images beyond the keep_count limit
    Keeps the database from growing indefinitely
    
    Args:
        user_id: User ID to cleanup
        keep_count: Number of most recent images to keep (default: 100)
    """
    if not user_id:
        return
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Delete all but the most recent keep_count images
        cursor.execute(
            '''DELETE FROM used_images 
               WHERE user_id = ? 
               AND id NOT IN (
                   SELECT id FROM used_images 
                   WHERE user_id = ? 
                   ORDER BY used_date DESC 
                   LIMIT ?
               )''',
            (user_id, user_id, keep_count)
        )
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        if deleted_count > 0:
            print(f"üßπ Cleaned up {deleted_count} old image entries for user {user_id}")
    except Exception as e:
        print(f"‚ö†Ô∏è Error cleaning up used images: {e}")

def fetch_images_from_pexels(query, count=1, retries=2):
    """
    Fetch images from Pexels API
    
    Args:
        query: Search query string
        count: Number of images to fetch (default: 1)
        retries: Number of retry attempts (default: 2)
    
    Returns:
        List of dicts with unified format:
        [
            {
                'url': 'https://...',
                'author': 'Photographer Name',
                'source': 'Pexels',
                'source_link': 'https://pexels.com/photo/...', 
                'attribution': 'Photo by Name on Pexels'
            }
        ]
        Returns empty list if no results or error
    """
    if not PEXELS_API_KEY:
        print("  ‚ö† Pexels API key not configured")
        return []
    
    if not can_make_api_call('pexels'):
        return []
    
    for attempt in range(retries):
        try:
            query_clean = query.strip().lower()
            
            headers = {
                'Authorization': PEXELS_API_KEY
            }
            
            params = {
                'query': query_clean,
                'per_page': count,
                'orientation': 'landscape'
            }
            
            if attempt == 0:
                print(f"  ‚Üí Pexels search: '{query_clean}'")
            
            response = requests.get(
                'https://api.pexels.com/v1/search',
                headers=headers,
                params=params,
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get('photos') and len(data['photos']) > 0:
                    results = []
                    for photo in data['photos'][:count]:
                        results.append({
                            'url': photo['src']['large'],
                            'author': photo['photographer'],
                            'source': 'Pexels',
                            'source_link': photo.get('url', 'https://www.pexels.com'),
                            'attribution': f"Photo by {photo['photographer']} on Pexels"
                        })
                    print(f"  ‚úì Pexels: Found {len(results)} image(s)")
                    return results
                else:
                    print(f"  ‚úó No Pexels results for '{query_clean}'")
                    return []
            
            elif response.status_code == 429:  # Rate limit
                print(f"  ‚ö† Pexels rate limit hit (attempt {attempt + 1}/{retries})")
                if attempt < retries - 1:
                    import time
                    time.sleep(1)  # Wait before retry
                    continue
                return []
            
            else:
                print(f"  ‚úó Pexels API error: {response.status_code}")
                return []
        
        except requests.exceptions.Timeout:
            print(f"  ‚ö† Pexels timeout (attempt {attempt + 1}/{retries})")
            if attempt < retries - 1:
                continue
            return []
        
        except Exception as e:
            print(f"  ‚úó Pexels error: {e}")
            return []
    
    return []


def fetch_images_from_unsplash(query, count=1, retries=2):
    """
    Fetch images from Unsplash API
    
    Args:
        query: Search query string
        count: Number of images to fetch (default: 1)
        retries: Number of retry attempts (default: 2)
    
    Returns:
        List of dicts with unified format (same as fetch_images_from_pexels)
        Returns empty list if no results or error
    """
    if not UNSPLASH_ACCESS_KEY:
        return []  # Silent fail if not configured
    
    if not can_make_api_call('unsplash'):
        return []
    
    for attempt in range(retries):
        try:
            query_clean = query.strip().lower()
            
            headers = {
                'Authorization': f'Client-ID {UNSPLASH_ACCESS_KEY}'
            }
            
            params = {
                'query': query_clean,
                'per_page': count,
                'orientation': 'landscape'
            }
            
            if attempt == 0:
                print(f"  ‚Üí Unsplash search: '{query_clean}'")
            
            response = requests.get(
                'https://api.unsplash.com/search/photos',
                headers=headers,
                params=params,
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if data.get('results') and len(data['results']) > 0:
                    results = []
                    for photo in data['results'][:count]:
                        results.append({
                            'url': photo['urls']['regular'],
                            'author': photo['user']['name'],
                            'source': 'Unsplash',
                            'source_link': photo['links']['html'],
                            'attribution': f"Photo by {photo['user']['name']} on Unsplash"
                        })
                    print(f"  ‚úì Unsplash: Found {len(results)} image(s)")
                    return results
                else:
                    print(f"  ‚úó No Unsplash results for '{query_clean}'")
                    return []
            
            elif response.status_code == 429:  # Rate limit
                print(f"  ‚ö† Unsplash rate limit hit (attempt {attempt + 1}/{retries})")
                if attempt < retries - 1:
                    import time
                    time.sleep(1)
                    continue
                return []
            
            else:
                print(f"  ‚úó Unsplash API error: {response.status_code}")
                return []
        
        except requests.exceptions.Timeout:
            print(f"  ‚ö† Unsplash timeout (attempt {attempt + 1}/{retries})")
            if attempt < retries - 1:
                continue
            return []
        
        except Exception as e:
            print(f"  ‚úó Unsplash error: {e}")
            return []
    
    return []


def get_images(query, count=1, mode=None):
    """
    Unified image fetching function with multi-source support
    
    This is the main function used by the presentation generator.
    It handles provider selection, fallback logic, and error handling.
    
    Args:
        query: Search query string
        count: Number of images to fetch (default: 1)
        mode: Override provider mode ('pexels', 'unsplash', 'mixed')
              If None, uses IMAGE_PROVIDER_MODE from config
    
    Returns:
        List of image dicts with unified format (url, author, source, etc.)
        Returns empty list if no images found
    
    Strategy:
        - 'pexels': Only try Pexels
        - 'unsplash': Only try Unsplash
        - 'mixed': Try Pexels first, fallback to Unsplash if needed
    """
    if mode is None:
        mode = IMAGE_PROVIDER_MODE
    
    results = []
    
    if mode == 'unsplash':
        # Unsplash only
        results = fetch_images_from_unsplash(query, count)
    
    elif mode == 'pexels':
        # Pexels only
        results = fetch_images_from_pexels(query, count)
    
    else:  # 'mixed' or default
        # Try Pexels first (primary source)
        results = fetch_images_from_pexels(query, count)
        
        if not results:
            # Fallback to Unsplash if Pexels failed or returned nothing
            print(f"  ‚Üí Trying Unsplash as fallback...")
            results = fetch_images_from_unsplash(query, count)
    
    return results


def search_image(query):
    """
    Legacy wrapper for backward compatibility
    Searches for a single image and returns URL or None
    
    This function maintains compatibility with existing code that uses
    the old search_image() interface.
    """
    results = get_images(query, count=1)
    if results and len(results) > 0:
        return results[0]['url']
    return None


def search_pexels_image(query, retries=2):
    """
    Legacy wrapper for backward compatibility
    Returns: (image_url, attribution) or (None, None)
    """
    results = fetch_images_from_pexels(query, count=1, retries=retries)
    if results and len(results) > 0:
        img = results[0]
        return img['url'], img['attribution']
    return None, None


def search_unsplash_image(query, retries=2):
    """
    Legacy wrapper for backward compatibility  
    Returns: (image_url, attribution) or (None, None)
    """
    results = fetch_images_from_unsplash(query, count=1, retries=retries)
    if results and len(results) > 0:
        img = results[0]
        return img['url'], img['attribution']
    return None, None


def search_image_with_fallback(search_keyword, slide_title, main_topic, used_images, presentation_type='business', slide_content=''):
    """
    Search for image with intelligent query generation and multiple fallback attempts.
    Now uses AI-driven content analysis to select appropriate image types.
    
    Returns: (image_data, image_url, image_metadata) or (None, None, None)
    image_metadata: dict with 'query', 'category', 'description'
    """
    # Generate intelligent image search query
    english_query, original_query, image_category, description = generate_intelligent_image_query(
        slide_title=slide_title,
        slide_content=slide_content or '',
        topic=main_topic,
        presentation_type=presentation_type
    )
    
    attempts = []
    
    # Primary attempt: Intelligent query
    if english_query:
        attempts.append((english_query, f"Intelligent ({image_category})"))
    
    # Fallback 1: Original search keyword (if provided)
    if search_keyword and search_keyword.strip():
        if CYRILLIC_RE.search(search_keyword):
            translated = translate_keyword_to_english(search_keyword, main_topic)
            if translated and translated != english_query:
                attempts.append((translated, "Translated keyword"))
        elif search_keyword != english_query:
            attempts.append((search_keyword, "Original keyword"))
    
    # Fallback 2: Slide title
    if slide_title and slide_title != english_query:
        attempts.append((slide_title, "Slide title"))
    
    # Fallback 3: Main topic
    if main_topic and main_topic not in [a[0] for a in attempts[:3]]:
        attempts.append((main_topic, "Main topic"))
    
    metadata = {
        'query': english_query,
        'original_query': original_query,
        'category': image_category,
        'description': description
    }
    
    for query, attempt_name in attempts:
        if not query or query.strip() == "":
            continue
            
        print(f"  ‚Üí Attempt: {attempt_name} - '{query}'")
        
        # Check cache first
        cached_path = get_cached_image_path(query)
        if cached_path and cached_path not in used_images:
            try:
                with open(cached_path, 'rb') as f:
                    image_data = io.BytesIO(f.read())
                return image_data, cached_path, metadata
            except:
                pass
        
        # Search on Pexels/Unsplash
        image_url = search_image(query)
        
        if image_url and image_url not in used_images:
            image_data = download_image(image_url)
            
            if image_data:
                # Save to cache
                cached_path = save_image_to_cache(image_data, query)
                return image_data, image_url, metadata
    
    print(f"  ‚úó No unique image found after all attempts")
    return None, None, metadata


def search_image_for_slide(slide_title, slide_content, main_topic, exclude_images=None, presentation_type='business'):
    """
    MAIN ROUTING FUNCTION FOR IMAGE SEARCH
    
    Routes to either LEGACY or ADVANCED mode based on USE_IMAGE_PROMPT flag.
    This maintains backward compatibility while allowing opt-in to new features.
    
    - LEGACY mode (USE_IMAGE_PROMPT=false, default): Stable, simple keyword search
    - ADVANCED mode (USE_IMAGE_PROMPT=true): Uses image_prompt and enhanced pipeline
    
    Args:
        slide_title: Title of the slide
        slide_content: Main content/text of the slide
        main_topic: Overall presentation topic
        exclude_images: List of image URLs to exclude (previously used)
        presentation_type: Type of presentation (business/scientific/general)
    
    Returns:
        (image_data, image_url, query_used) or (None, None, None)
    """
    # Route based on USE_IMAGE_PROMPT flag
    if not USE_IMAGE_PROMPT:
        # LEGACY MODE: Ignore image_prompt, use search_keyword/title/content
        print(f"\nüè∑Ô∏è  MODE: LEGACY (USE_IMAGE_PROMPT=false)")
        return search_image_legacy_mode(
            slide_title=slide_title,
            slide_content=slide_content,
            main_topic=main_topic,
            exclude_images=exclude_images,
            presentation_type=presentation_type,
            search_keyword=None,  # Will be extracted from content
            language=None         # Will be auto-detected
        )
    else:
        # ADVANCED MODE: Use image_prompt if available
        print(f"\nüè∑Ô∏è  MODE: ADVANCED (USE_IMAGE_PROMPT=true)")
        return search_image_advanced_mode(
            slide_title=slide_title,
            slide_content=slide_content,
            main_topic=main_topic,
            exclude_images=exclude_images,
            presentation_type=presentation_type,
            image_prompt=None,  # Not available in this old signature
            language=None       # Will be auto-detected
        )


def search_image_in_curated_pool(clip_context_embedding, top_k: int = 5):
    """
    Search for images in curated pool using CLIP embeddings.
    
    STUB: Future implementation will use FAISS/vector database with pre-indexed curated images.
    
    Args:
        clip_context_embedding: CLIP embedding of slide context (numpy array)
        top_k: Number of top results to return
    
    Returns:
        List of image candidates (empty for now - stub implementation)
    
    Future:
        - Will maintain a curated pool of high-quality stock photos
        - Pre-computed CLIP embeddings stored in FAISS index
        - Fast vector similarity search
        - Metadata: tags, categories, license info
    """
    # STUB: Return empty list until curated pool is implemented
    return []


def search_image_legacy_mode(
    slide_title: str,
    slide_content: str,
    main_topic: str,
    exclude_images: list | None = None,
    presentation_type: str = 'business',
    search_keyword: str | None = None,
    language: str | None = None
):
    """
    LEGACY IMAGE SEARCH MODE - Maximum stability, minimal complexity
    
    This is the original, stable search behavior that works reliably across
    Russian and English presentations. It uses simple keyword-based search
    with optional CLIP ranking (soft mode - no threshold blocking).
    
    Key characteristics:
    - Uses search_keyword from LLM (or extracts from title/content)
    - Ignores image_prompt completely
    - CLIP only ranks candidates, never blocks images
    - Simple translation logic (if enabled)
    - Maximum compatibility and stability
    
    Args:
        slide_title: Title of the slide
        slide_content: Main content/text of the slide  
        main_topic: Overall presentation topic
        exclude_images: List of image URLs to exclude (previously used)
        presentation_type: Type of presentation (business/scientific/general)
        search_keyword: LLM-provided search keyword (preferred)
        language: Language of the slide content (auto-detected if None)
    
    Returns:
        (image_data, image_url, query_used) or (None, None, None)
    """
    if exclude_images is None:
        exclude_images = []
    
    print(f"\nüîç [LEGACY] Searching image for slide: '{slide_title}'")
    
    # ========================================================================
    # STEP 1: Build search query from search_keyword or title/content
    # ========================================================================
    if search_keyword and search_keyword.strip():
        query = search_keyword.strip()
        print(f"  üéØ [LEGACY] Using search_keyword: '{query}'")
    else:
        # Extract keywords from title and content (old behavior)
        print(f"  ‚ö†Ô∏è [LEGACY] No search_keyword, extracting from title/content")
        
        text_for_query = f"{slide_title} {slide_content[:100]}"
        
        # Simple keyword extraction
        stopwords = {
            'the', 'is', 'at', 'which', 'on', 'a', 'an', 'as', 'are', 'was', 'were',
            'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did',
            'will', 'would', 'should', 'could', 'may', 'might', 'must',
            'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',
            '—ç—Ç–æ', '—ç—Ç–æ—Ç', '—ç—Ç–∞', '—ç—Ç–∏', '—Ç–æ—Ç', '—Ç–∞', '—Ç–µ', '–∏', '–≤', '–Ω–∞', '–ø–æ', '—Å', '—É',
            '–±—ã–ª', '–±—ã–ª–∞', '–±—ã–ª–∏', '–±—É–¥–µ—Ç', '–±—É–¥—É—Ç', '–º–æ–∂–µ—Ç', '–º–æ–∂–Ω–æ'
        }
        
        words = re.findall(r'\b\w{4,}\b', text_for_query.lower())
        keywords = [w for w in words if w not in stopwords][:5]
        
        if keywords:
            query = ' '.join(keywords[:3])  # Top 3 keywords
            print(f"  üéØ [LEGACY] Extracted keywords: {keywords[:3]}")
        else:
            query = slide_title
            print(f"  ‚ö†Ô∏è [LEGACY] No keywords, using title")
    
    # Auto-detect language if needed
    if language is None:
        language = detect_language(f"{slide_title} {slide_content[:50]}")
    
    print(f"  üåç [LEGACY] Detected language: {language}")
    
    # ========================================================================
    # STEP 2: Apply translation if enabled
    # ========================================================================
    # Use universal translation layer
    query = translate_for_image_search(
        text=query,
        source_lang=language,
        context=f"legacy_search:{slide_title}"
    )
    
    print(f"  üîç [LEGACY] Final search query: '{query}'")
    
    # ========================================================================
    # STEP 3: CLIP-enhanced search (SOFT MODE - no threshold blocking)
    # ========================================================================
    if CLIP_AVAILABLE:
        print(f"  ü§ñ [LEGACY] CLIP ranking: STRICT_FILTER={USE_STRICT_CLIP_FILTER}")
        
        # Fetch candidates (max 6 for speed optimization)
        candidate_count = 6
        candidates = get_images(query, count=candidate_count)
        
        if not candidates:
            print(f"  ‚ö†Ô∏è [LEGACY] No candidates for '{query}', trying title")
            candidates = get_images(slide_title, count=candidate_count)
        
        # Check minimum candidates threshold
        if candidates and len(candidates) < CLIP_MIN_CANDIDATES:
            print(f"  ‚ö†Ô∏è [LEGACY] Only {len(candidates)} candidates (< {CLIP_MIN_CANDIDATES} minimum)")
            print(f"     Skipping CLIP, using keyword search")
            candidates = []
        
        if candidates:
            print(f"  üìä [LEGACY] Found {len(candidates)} candidates, starting CLIP ranking...")
            print(f"     ‚Üí CLIP Mode: {'STRICT (can reject)' if USE_STRICT_CLIP_FILTER else 'SOFT (ranks only)'}")
            print(f"     ‚Üí Threshold: {CLIP_SIMILARITY_THRESHOLD if USE_STRICT_CLIP_FILTER else 0.0}")
            
            clip_start = time.perf_counter()
            
            # Build CLIP context (simple - no image_prompt)
            clip_context_text = f"{slide_title}. {slide_content[:60]}"
            print(f"  üìã [LEGACY] CLIP context: '{clip_context_text}...'")
            
            # Add description field if missing
            for candidate in candidates:
                if 'description' not in candidate:
                    candidate['description'] = (
                        candidate.get('attribution', '') or 
                        candidate.get('author', '') or 
                        slide_title
                    )
            
            # Use CLIP to rank images
            try:
                best_image = clip_pick_best_image(
                    slide_title=slide_title,
                    slide_content=slide_content,
                    image_candidates=candidates,
                    exclude_images=exclude_images,
                    similarity_threshold=CLIP_SIMILARITY_THRESHOLD if USE_STRICT_CLIP_FILTER else 0.0
                )
                
                clip_time = time.perf_counter() - clip_start
                print(f"  ‚è±Ô∏è  [LEGACY] CLIP processing completed in {clip_time:.2f}s")
                
                if best_image:
                    similarity = best_image.get('_clip_similarity', 'N/A')
                    source = best_image.get('source', 'Unknown')
                    
                    # In legacy mode, check if strict filter rejected image
                    if USE_STRICT_CLIP_FILTER and similarity != 'N/A' and similarity < CLIP_SIMILARITY_THRESHOLD:
                        print(f"  ‚ùå [LEGACY] CLIP rejected (similarity {similarity} < {CLIP_SIMILARITY_THRESHOLD})")
                        best_image = None
                    else:
                        image_url = best_image['url']
                        image_data = download_image(image_url)
                        
                        if image_data:
                            print(f"  ‚úÖ [LEGACY] CLIP selected: {image_url[:50]}... (similarity={similarity}, source={source})")
                            return image_data, image_url, query
                        else:
                            print(f"  ‚ö†Ô∏è [LEGACY] Failed to download CLIP-selected image")
                else:
                    if USE_STRICT_CLIP_FILTER:
                        print(f"  ‚ùå [LEGACY] No image passed CLIP threshold ({CLIP_SIMILARITY_THRESHOLD})")
                    else:
                        print(f"  ‚ö†Ô∏è [LEGACY] CLIP ranking returned no result")
            except Exception as e:
                print(f"  ‚ö†Ô∏è [LEGACY] CLIP ranking failed: {e}")
        else:
            print(f"  ‚ö†Ô∏è [LEGACY] No candidates for CLIP ranking")
    else:
        # CLIP not available
        print(f"  ‚ÑπÔ∏è [LEGACY] CLIP not available, using keyword search")
    
    # ========================================================================
    # STEP 4: Fallback to traditional keyword search
    # ========================================================================
    print(f"  üîç [LEGACY] Fallback to keyword search")
    
    image_data, image_url, metadata = search_image_with_fallback(
        search_keyword=query,
        slide_title=slide_title,
        main_topic=main_topic,
        used_images=exclude_images,
        presentation_type=presentation_type,
        slide_content=slide_content
    )
    
    if image_url:
        print(f"  ‚úÖ [LEGACY] Found image: {image_url[:60]}...")
        return image_data, image_url, query
    else:
        print(f"  ‚ùå [LEGACY] No suitable image found")
        return None, None, None


def build_image_search_query(
    slide_title: str,
    slide_content: str,
    image_prompt: str | None = None,
    language: str | None = None
) -> str:
    """
    Build optimal search query for image search based on available information.
    
    Priority:
    1. Use image_prompt if available (already in English, optimized for stock photos)
    2. Fall back to slide_title + content keywords
    3. Apply translation if needed (based on TRANSLATION_ENABLED/PROVIDER)
    
    Args:
        slide_title: Title of the slide
        slide_content: Content of the slide
        image_prompt: LLM-generated image description in English (preferred)
        language: Language of the slide (auto-detected if None)
    
    Returns:
        Search query string optimized for Pexels/Unsplash
    
    Examples:
        >>> build_image_search_query(
        ...     "Market Analysis",
        ...     "Our revenue grew...",
        ...     "business team analyzing financial charts in modern office"
        ... )
        "business team analyzing financial charts in modern office"
        
        >>> build_image_search_query(
        ...     "–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞",
        ...     "–ù–∞—à–∏ –¥–æ—Ö–æ–¥—ã –≤—ã—Ä–æ—Å–ª–∏...",
        ...     None,
        ...     language='ru'
        ... )
        # Returns translated query or original based on TRANSLATION_ENABLED
    """
    # ========================================================================
    # PRIORITY 1: Use image_prompt if available (best option)
    # ========================================================================
    if image_prompt and image_prompt.strip():
        query = image_prompt.strip()
        print(f"  üñºÔ∏è Image prompt: '{query}'")
        # image_prompt should already be in English, optimized for stock photos
        # No translation needed
        return query
    
    # ========================================================================
    # PRIORITY 2: Build query from title + content
    # ========================================================================
    print(f"  ‚ö†Ô∏è No image_prompt provided, building from title/content")
    
    # Combine title and short content snippet
    text_for_query = f"{slide_title} {slide_content[:100]}"
    
    # Auto-detect language if not specified
    if language is None:
        language = detect_language(text_for_query)
    
    print(f"  üåê Detected language: {language}")
    
    # Extract keywords (simplified - reuse existing logic)
    stopwords = {
        'the', 'is', 'at', 'which', 'on', 'a', 'an', 'as', 'are', 'was', 'were',
        'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did',
        'will', 'would', 'should', 'could', 'may', 'might', 'must',
        'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',
        '—ç—Ç–æ', '—ç—Ç–æ—Ç', '—ç—Ç–∞', '—ç—Ç–∏', '—Ç–æ—Ç', '—Ç–∞', '—Ç–µ', '–∏', '–≤', '–Ω–∞', '–ø–æ', '—Å', '—É',
        '–±—ã–ª', '–±—ã–ª–∞', '–±—ã–ª–∏', '–±—É–¥–µ—Ç', '–±—É–¥—É—Ç', '–º–æ–∂–µ—Ç', '–º–æ–∂–Ω–æ'
    }
    
    words = re.findall(r'\b\w{4,}\b', text_for_query.lower())
    keywords = [w for w in words if w not in stopwords][:5]
    
    if keywords:
        query = ' '.join(keywords[:3])  # Top 3 keywords
        print(f"  üéØ Extracted keywords: {keywords[:3]}")
    else:
        query = slide_title
        print(f"  ‚ö†Ô∏è No keywords extracted, using title")
    
    # ========================================================================
    # TRANSLATION: Use universal translation layer
    # ========================================================================
    # Translate query if:
    # - TRANSLATION_ENABLED=true
    # - TRANSLATION_PROVIDER != 'none'
    # - language is not already target language
    
    query = translate_for_image_search(
        text=query,
        source_lang=language,
        context=f"image_search:{slide_title}"
    )
    
    print(f"  üîç Final search query: '{query}'")
    return query


def search_image_advanced_mode(
    slide_title: str,
    slide_content: str,
    main_topic: str,
    exclude_images: list | None = None,
    presentation_type: str = 'business',
    image_prompt: str | None = None,
    language: str | None = None
):
    """
    ADVANCED IMAGE SEARCH MODE - Uses image_prompt and enhanced pipeline
    
    This mode uses the newer, more sophisticated search pipeline with:
    - image_prompt from LLM for better search queries
    - Universal translation layer
    - CLIP semantic matching with configurable threshold filtering
    - Curated pool support (stub for future)
    
    Behavior depends on USE_STRICT_CLIP_FILTER:
    - false: CLIP ranks but never blocks (soft mode)
    - true: CLIP can reject images below threshold (strict mode)
    
    Args:
        slide_title: Title of the slide
        slide_content: Main content/text of the slide
        main_topic: Overall presentation topic
        exclude_images: List of image URLs to exclude (previously used)
        presentation_type: Type of presentation (business/scientific/general)
        image_prompt: LLM-generated image description in English (NEW)
        language: Language of the slide content (auto-detected if None)
    
    Returns:
        (image_data, image_url, query_used) or (None, None, None)
    """
    if exclude_images is None:
        exclude_images = []
    
    print(f"\nüîç [ADVANCED] Searching image for slide: '{slide_title}'")
    print(f"  üîß [ADVANCED] STRICT_FILTER={USE_STRICT_CLIP_FILTER}")
    
    # ========================================================================
    # NEW: Build search query using image_prompt or fallback
    # ========================================================================
    search_query = build_image_search_query(
        slide_title=slide_title,
        slide_content=slide_content,
        image_prompt=image_prompt,
        language=language
    )
    
    # ========================================================================
    # FUTURE: Try curated pool first (stub for now)
    # ========================================================================
    if CLIP_AVAILABLE and image_prompt:
        # Get CLIP embedding for slide context
        try:
            from services.clip_client import get_text_embedding
            clip_context = f"{slide_title}. {slide_content[:100]}. {image_prompt or ''}"
            context_embedding = get_text_embedding(clip_context)
            
            # Try curated pool (returns empty list for now - stub)
            curated_candidates = search_image_in_curated_pool(context_embedding, top_k=5)
            
            if curated_candidates:
                print(f"  üåü [ADVANCED] Found {len(curated_candidates)} images in curated pool")
                # TODO: Implement curated pool ranking and selection
                # For now, falls through to regular search
        except Exception as e:
            print(f"  ‚ö†Ô∏è [ADVANCED] Curated pool search failed: {e}")
    
    # ========================================================================
    # CLIP-ENHANCED IMAGE SEARCH (from Pexels/Unsplash)
    # ========================================================================
    if CLIP_AVAILABLE:
        print(f"  ü§ñ [ADVANCED] Using CLIP semantic matching")
        print(f"     Threshold: {CLIP_SIMILARITY_THRESHOLD}, Min candidates: {CLIP_MIN_CANDIDATES}")
        
        # Determine candidate count (max 6 for speed optimization)
        candidate_count = 6
        
        # Fetch candidates using the built search query
        candidates = get_images(search_query, count=candidate_count)
        
        if not candidates:
            print(f"  ‚ö†Ô∏è [ADVANCED] No candidates for '{search_query}', trying title")
            # Try with slide title as fallback
            candidates = get_images(slide_title, count=candidate_count)
        
        # Check if we have minimum required candidates
        if candidates and len(candidates) < CLIP_MIN_CANDIDATES:
            print(f"  ‚ö†Ô∏è [ADVANCED] Only {len(candidates)} candidates (< {CLIP_MIN_CANDIDATES} minimum)")
            print(f"     Skipping CLIP, falling back to keyword search")
            candidates = []  # Force fallback
        
        if candidates:
            print(f"  üìä [ADVANCED] Found {len(candidates)} candidates, applying CLIP ranking...")
            
            # Enhanced CLIP context with image_prompt
            if image_prompt:
                clip_context_text = f"{slide_title}. {slide_content[:60]}. Target: {image_prompt}"
            else:
                clip_context_text = f"{slide_title}. {slide_content[:60]}"
            
            print(f"  üìù CLIP context: '{clip_context_text}...'")
            
            # Add description field if missing
            for candidate in candidates:
                if 'description' not in candidate:
                    candidate['description'] = (
                        candidate.get('attribution', '') or 
                        candidate.get('author', '') or 
                        slide_title
                    )
            
            # Use CLIP to pick best matching image
            # In soft mode (USE_STRICT_CLIP_FILTER=false), pass threshold=0.0 to never block
            # In strict mode (USE_STRICT_CLIP_FILTER=true), use actual threshold
            effective_threshold = CLIP_SIMILARITY_THRESHOLD if USE_STRICT_CLIP_FILTER else 0.0
            
            try:
                best_image = clip_pick_best_image(
                    slide_title=slide_title,
                    slide_content=slide_content + (f" Image target: {image_prompt}" if image_prompt else ""),
                    image_candidates=candidates,
                    exclude_images=exclude_images,
                    similarity_threshold=effective_threshold
                )
                
                if best_image:
                    similarity = best_image.get('_clip_similarity', 'N/A')
                    source = best_image.get('source', 'Unknown')
                    
                    # Check if strict mode rejected the image
                    if USE_STRICT_CLIP_FILTER and similarity != 'N/A' and similarity < CLIP_SIMILARITY_THRESHOLD:
                        print(f"  ‚ùå [ADVANCED] CLIP rejected (similarity {similarity} < {CLIP_SIMILARITY_THRESHOLD})")
                        print(f"     Reason: Strict filter enabled, threshold not met")
                    else:
                        image_url = best_image['url']
                        image_data = download_image(image_url)
                        
                        if image_data:
                            mode_suffix = "(strict)" if USE_STRICT_CLIP_FILTER else "(soft)"
                            print(f"  ‚úÖ [ADVANCED] CLIP selected {mode_suffix}: {image_url[:50]}...")
                            print(f"     similarity={similarity}, source={source}")
                            return image_data, image_url, search_query
                        else:
                            print(f"  ‚ö†Ô∏è [ADVANCED] Failed to download CLIP-selected image")
                else:
                    if USE_STRICT_CLIP_FILTER:
                        print(f"  ‚ùå [ADVANCED] No image passed CLIP threshold ({CLIP_SIMILARITY_THRESHOLD})")
                    else:
                        print(f"  ‚ö†Ô∏è [ADVANCED] CLIP ranking returned no result")
            except Exception as e:
                print(f"  ‚ö†Ô∏è [ADVANCED] CLIP ranking failed: {e}")
        else:
            print(f"  ‚ö†Ô∏è [ADVANCED] No candidates for CLIP ranking")
    else:
        # CLIP not available
        if CLIP_ENABLED:
            print(f"  ‚ö†Ô∏è [ADVANCED] CLIP enabled but not available (initialization failed)")
        else:
            print(f"  ‚ÑπÔ∏è [ADVANCED] CLIP disabled (CLIP_ENABLED=false)")
        print(f"     Using keyword search only")
    
    # ========================================================================
    # FALLBACK: Traditional keyword-based search
    # ========================================================================
    print(f"  üîç [ADVANCED] Fallback to keyword search")
    
    # Use existing intelligent search with duplicate prevention
    image_data, image_url, metadata = search_image_with_fallback(
        search_keyword=search_query,
        slide_title=slide_title,
        main_topic=main_topic,
        used_images=exclude_images,
        presentation_type=presentation_type,
        slide_content=slide_content
    )
    
    if image_url:
        print(f"  ‚úÖ [ADVANCED] Found image: {image_url[:60]}...")
        return image_data, image_url, search_query
    else:
        print(f"  ‚ùå [ADVANCED] No suitable image found")
        return None, None, None


# Backward compatibility alias
search_image_for_slide_enhanced = search_image_advanced_mode


def is_libretranslate_available():
    """
    Check if LibreTranslate service is available.
    Returns False immediately if translation is disabled or provider is not 'libre'.
    """
    try:
        if not TRANSLATION_ENABLED:
            return False
        if TRANSLATION_PROVIDER != 'libre':
            return False
        if not LIBRETRANSLATE_URL:
            return False
        resp = requests.get(f"{LIBRETRANSLATE_URL}/languages", timeout=LIBRETRANSLATE_TIMEOUT)
        return resp.status_code == 200
    except Exception:
        return False


def download_image(url):
    """
    Download image from URL and return as bytes
    Security: Limit image size to prevent memory issues
    """
    MAX_IMAGE_SIZE = 10 * 1024 * 1024  # 10 MB limit
    
    try:
        response = requests.get(url, timeout=10, stream=True)
        if response.status_code == 200:
            # Check content length if available
            content_length = response.headers.get('content-length')
            if content_length and int(content_length) > MAX_IMAGE_SIZE:
                print(f"  ‚ö† Image too large: {content_length} bytes")
                return None
            
            # Download with size limit
            content = b''
            for chunk in response.iter_content(chunk_size=8192):
                content += chunk
                if len(content) > MAX_IMAGE_SIZE:
                    print(f"  ‚ö† Image exceeds size limit")
                    return None
            
            return io.BytesIO(content)
        return None
    except Exception as e:
        print(f"Error downloading image: {e}")
        return None


def calculate_title_font_size(text, max_width_inches=8.5, bold=True):
    """
    Calculate optimal font size for title to fit in one line.
    Tries sizes from 40pt down to 24pt.
    Returns the largest font size that fits the text in one line.
    
    Approximate calculation: 1 character ‚âà 0.6 * font_size_pt / 72 inches (for bold text)
    """
    # Font sizes to try in descending order
    font_sizes = [40, 36, 32, 28, 24]
    
    # Approximate character width factor for bold fonts (empirical)
    # For bold fonts: ~0.55-0.65 of font size in points
    char_width_factor = 0.6 if bold else 0.5
    
    for font_size in font_sizes:
        # Estimate text width in inches
        # char_width_in_points = font_size * char_width_factor
        # char_width_in_inches = char_width_in_points / 72
        estimated_width = len(text) * (font_size * char_width_factor / 72)
        
        if estimated_width <= max_width_inches:
            print(f"  üìè Title font size: {font_size}pt (estimated width: {estimated_width:.2f}in vs max {max_width_inches}in)")
            return font_size
    
    # If even 24pt doesn't fit, return 24pt anyway (minimum)
    print(f"  ‚ö† Title very long, using minimum font size: 24pt")
    return 24


# Theme color configurations for presentations
PRESENTATION_THEMES = {
    'light': {
        'background': RGBColor(245, 245, 250),
        'title_slide_bg': RGBColor(15, 25, 45),
        'content_slide_bg': RGBColor(245, 245, 250),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(30, 60, 120),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(40, 40, 40),
        'accent_color': RGBColor(30, 60, 180)
    },
    'dark': {
        'background': RGBColor(30, 30, 30),
        'title_slide_bg': RGBColor(15, 15, 25),
        'content_slide_bg': RGBColor(30, 30, 30),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(187, 134, 252),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(224, 224, 224),
        'accent_color': RGBColor(3, 218, 198)
    },
    'modern': {
        'background': RGBColor(250, 250, 250),
        'title_slide_bg': RGBColor(30, 30, 50),
        'content_slide_bg': RGBColor(250, 250, 250),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(79, 70, 229),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(15, 23, 42),
        'accent_color': RGBColor(124, 58, 237)
    },
    'casual': {
        'background': RGBColor(255, 245, 247),
        'title_slide_bg': RGBColor(76, 69, 105),
        'content_slide_bg': RGBColor(255, 245, 247),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(255, 107, 157),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(51, 51, 51),
        'accent_color': RGBColor(255, 160, 122)
    },
    'classic': {
        'background': RGBColor(236, 240, 241),
        'title_slide_bg': RGBColor(28, 38, 50),
        'content_slide_bg': RGBColor(236, 240, 241),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(44, 62, 80),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(44, 62, 80),
        'accent_color': RGBColor(52, 73, 94)
    },
    'futuristic': {
        'background': RGBColor(10, 14, 39),
        'title_slide_bg': RGBColor(10, 14, 39),
        'content_slide_bg': RGBColor(10, 14, 39),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(0, 212, 255),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(255, 255, 255),
        'accent_color': RGBColor(255, 0, 255)
    },
    'gradient': {
        'background': RGBColor(254, 249, 255),
        'title_slide_bg': RGBColor(79, 30, 85),
        'content_slide_bg': RGBColor(254, 249, 255),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(240, 147, 251),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(51, 51, 51),
        'accent_color': RGBColor(79, 172, 254)
    },
    'glassmorphism': {
        'background': RGBColor(102, 126, 234),
        'title_slide_bg': RGBColor(26, 30, 74),
        'content_slide_bg': RGBColor(102, 126, 234),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(255, 255, 255),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(255, 255, 255),
        'accent_color': RGBColor(255, 255, 255)
    },
    'nature': {
        'background': RGBColor(241, 250, 238),
        'title_slide_bg': RGBColor(29, 67, 50),
        'content_slide_bg': RGBColor(241, 250, 238),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(45, 106, 79),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(27, 67, 50),
        'accent_color': RGBColor(82, 183, 136)
    },
    'vivid': {
        'background': RGBColor(255, 252, 242),
        'title_slide_bg': RGBColor(33, 5, 17),
        'content_slide_bg': RGBColor(255, 252, 242),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(255, 0, 110),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(33, 37, 41),
        'accent_color': RGBColor(251, 86, 7)
    },
    'business': {
        'background': RGBColor(248, 250, 252),
        'title_slide_bg': RGBColor(15, 25, 50),
        'content_slide_bg': RGBColor(248, 250, 252),
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(30, 58, 138),
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(15, 23, 42),
        'accent_color': RGBColor(14, 165, 233)
    },
    'heroic': {
        # HEROIC_MINIMAL: Clean minimalist design with strategic metaphors
        'background': RGBColor(255, 255, 255),  # Pure white
        'title_slide_bg': RGBColor(45, 55, 72),  # #2D3748 - Dark slate for title
        'content_slide_bg': RGBColor(255, 255, 255),  # White for content
        'title_color_first_last': RGBColor(255, 255, 255),  # White on dark
        'title_color_content': RGBColor(26, 32, 44),  # #1A202C - Almost black
        'content_color_first_last': RGBColor(255, 255, 255),  # White
        'content_color_content': RGBColor(26, 32, 44),  # #1A202C
        'accent_color': RGBColor(66, 153, 225),  # #4299E1 - Blue accent
        'icon_color': RGBColor(74, 85, 104),  # #4A5568 - Gray for icons
        'metaphor_overlay_color': RGBColor(45, 55, 72),  # #2D3748
        'style': 'heroic_minimal',  # Special flag
        'metaphor_percentage': 40  # 40% slides get metaphorical images
    },
    'minimal': {
        # Updated MINIMAL: Even cleaner with more air
        'background': RGBColor(248, 250, 252),  # #F8FAFC - Soft white
        'title_slide_bg': RGBColor(0, 0, 0),  # Pure black
        'content_slide_bg': RGBColor(248, 250, 252),  # Soft white
        'title_color_first_last': RGBColor(255, 255, 255),
        'title_color_content': RGBColor(26, 32, 44),  # #1A202C
        'content_color_first_last': RGBColor(255, 255, 255),
        'content_color_content': RGBColor(26, 32, 44),
        'accent_color': RGBColor(74, 85, 104),  # #4A5568 - Subtle gray
        'icon_color': RGBColor(74, 85, 104),
        'style': 'minimal_clean',
        'metaphor_percentage': 10  # Only 10% metaphorical images
    }
}

def filter_quiz_and_assessment_slides(slides_data):
    """
    Filter out quiz, self-assessment, and review question slides.
    These are not suitable for academic/professional presentations.
    
    Returns: (filtered_slides, removed_slides_info)
    """
    quiz_keywords = [
        'quiz', 'test', 'self-check', 'self-assessment', 'questions for review',
        '–∫–≤–∏–∑', '—Ç–µ—Å—Ç', '—Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∞', '–≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏', '–ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–Ω–∞–Ω–∏–π',
        'check your knowledge', 'knowledge check', '–ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–µ–±—è',
        'review questions', '–ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ', 'practice questions'
    ]
    
    filtered = []
    removed = []
    
    for idx, slide in enumerate(slides_data):
        title = slide.get('title', '').lower()
        content = slide.get('content', '').lower()
        
        # Check if slide contains quiz/assessment keywords
        is_quiz_slide = any(kw in title or kw in content for kw in quiz_keywords)
        
        # Additional check: slides with many question marks (likely quiz)
        question_count = content.count('?')
        has_many_questions = question_count >= 3
        
        if is_quiz_slide or has_many_questions:
            removed.append({
                'index': idx,
                'title': slide.get('title', ''),
                'reason': 'quiz/self-assessment content' if is_quiz_slide else 'multiple questions detected'
            })
            print(f"  ‚ùå Removed slide {idx + 1}: '{slide.get('title', '')}' ({removed[-1]['reason']})")
        else:
            filtered.append(slide)
    
    return filtered, removed


def get_icon_unicode_for_slide(slide_title: str, slide_content: str) -> str:
    """
    Select appropriate line-style icon (Unicode) based on slide content.
    Returns Unicode character for thin line icons (Heroicons/Feather style).
    
    Icon Categories:
    - Idea/Goal: üí° (lightbulb), üß≠ (compass)
    - Process: ‚öôÔ∏è (gear), ‚û°Ô∏è (arrow)
    - Comparison: ‚öñÔ∏è (scales), üìä (chart)
    - Success: üèÜ (trophy), üìà (growth)
    - Warning: ‚ö†Ô∏è (warning)
    - Information: ‚ÑπÔ∏è (info), üìù (document)
    - Target: üéØ (target)
    - Time: ‚è±Ô∏è (stopwatch), üìÖ (calendar)
    - People: üë• (users), ü§ù (handshake)
    - Tools: üîß (wrench), üõ†Ô∏è (tools)
    - Security: üîí (lock), üõ°Ô∏è (shield)
    - Communication: üí¨ (speech), üìß (email)
    """
    combined_text = (slide_title + " " + slide_content).lower()
    
    # Idea/Innovation/Goal/Vision
    if any(word in combined_text for word in ['idea', 'innovation', 'vision', '–∏–¥–µ—è', '–∏–Ω–Ω–æ–≤–∞—Ü–∏—è', '–≤–∏–∑–∏—è', 'creative', '—Ç–≤–æ—Ä—á–µ—Å–∫–∏–π']):
        return "üí°"  # Lightbulb
    
    # Direction/Strategy/Goal/Compass
    if any(word in combined_text for word in ['direction', 'strategy', 'goal', 'compass', 'navigate', '–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '—Å—Ç—Ä–∞—Ç–µ–≥–∏—è', '—Ü–µ–ª—å', '–Ω–∞–≤–∏–≥–∞—Ü–∏—è']):
        return "üß≠"  # Compass
    
    # Target/Focus/Objective
    if any(word in combined_text for word in ['target', 'focus', 'objective', 'aim', '—Ü–µ–ª—å', '—Ñ–æ–∫—É—Å', '–∑–∞–¥–∞—á–∞']):
        return "üéØ"  # Target
    
    # Process/System/Mechanism/Work
    if any(word in combined_text for word in ['process', 'system', 'mechanism', 'workflow', 'operation', '–ø—Ä–æ—Ü–µ—Å—Å', '—Å–∏—Å—Ç–µ–º–∞', '–º–µ—Ö–∞–Ω–∏–∑–º', '—Ä–∞–±–æ—Ç–∞']):
        return "‚öôÔ∏è"  # Gear
    
    # Growth/Success/Achievement/Increase
    if any(word in combined_text for word in ['growth', 'increase', 'success', 'achievement', 'improve', '—Ä–æ—Å—Ç', '—É—Å–ø–µ—Ö', '–¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ', '—É–≤–µ–ª–∏—á–µ–Ω–∏–µ']):
        return "üìà"  # Growth chart
    
    # Award/Trophy/Win/Victory
    if any(word in combined_text for word in ['award', 'trophy', 'win', 'victory', 'champion', '–Ω–∞–≥—Ä–∞–¥–∞', '–ø–æ–±–µ–¥–∞', '—á–µ–º–ø–∏–æ–Ω']):
        return "üèÜ"  # Trophy
    
    # Comparison/Analysis/Balance
    if any(word in combined_text for word in ['compare', 'comparison', 'balance', 'versus', 'analysis', '—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ', '–∞–Ω–∞–ª–∏–∑', '–±–∞–ª–∞–Ω—Å']):
        return "‚öñÔ∏è"  # Scales
    
    # Data/Chart/Statistics/Metrics
    if any(word in combined_text for word in ['data', 'chart', 'statistics', 'metrics', 'analytics', '–¥–∞–Ω–Ω—ã–µ', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', '–º–µ—Ç—Ä–∏–∫–∏']):
        return "üìä"  # Bar chart
    
    # Warning/Risk/Alert/Danger
    if any(word in combined_text for word in ['warning', 'risk', 'alert', 'danger', 'caution', '–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ', '—Ä–∏—Å–∫', '–æ–ø–∞—Å–Ω–æ—Å—Ç—å']):
        return "‚ö†Ô∏è"  # Warning
    
    # Time/Schedule/Deadline
    if any(word in combined_text for word in ['time', 'schedule', 'deadline', 'timeline', '–≤—Ä–µ–º—è', '–≥—Ä–∞—Ñ–∏–∫', '—Å—Ä–æ–∫']):
        return "‚è±Ô∏è"  # Stopwatch
    
    # Calendar/Date/Event/Plan
    if any(word in combined_text for word in ['calendar', 'date', 'event', 'plan', 'schedule', '–∫–∞–ª–µ–Ω–¥–∞—Ä—å', '–¥–∞—Ç–∞', '—Å–æ–±—ã—Ç–∏–µ', '–ø–ª–∞–Ω']):
        return "üìÖ"  # Calendar
    
    # Team/People/Collaboration/Users
    if any(word in combined_text for word in ['team', 'people', 'collaboration', 'users', 'group', '–∫–æ–º–∞–Ω–¥–∞', '–ª—é–¥–∏', '—Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ']):
        return "üë•"  # Users
    
    # Partnership/Agreement/Handshake
    if any(word in combined_text for word in ['partnership', 'agreement', 'cooperation', 'alliance', '–ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–æ', '—Å–æ–≥–ª–∞—à–µ–Ω–∏–µ', '—Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ']):
        return "ü§ù"  # Handshake
    
    # Tools/Build/Development
    if any(word in combined_text for word in ['tool', 'build', 'development', 'construct', '–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç', '—Å–æ–∑–¥–∞–Ω–∏–µ', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞']):
        return "üîß"  # Wrench
    
    # Security/Protection/Safe
    if any(word in combined_text for word in ['security', 'protection', 'safe', 'secure', 'protect', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '–∑–∞—â–∏—Ç–∞']):
        return "üîí"  # Lock
    
    # Communication/Message/Discussion
    if any(word in combined_text for word in ['communication', 'message', 'discussion', 'talk', '–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è', '—Å–æ–æ–±—â–µ–Ω–∏–µ', '–æ–±—Å—É–∂–¥–µ–Ω–∏–µ']):
        return "üí¨"  # Speech bubble
    
    # Document/File/Report
    if any(word in combined_text for word in ['document', 'file', 'report', 'paper', '–¥–æ–∫—É–º–µ–Ω—Ç', '—Ñ–∞–π–ª', '–æ—Ç—á–µ—Ç']):
        return "üìù"  # Document
    
    # Default: Info icon
    return "‚ÑπÔ∏è"  # Info


def should_use_metaphorical_image(slide_index: int, total_slides: int, slide_title: str, slide_content: str, metaphor_percentage: int) -> tuple[bool, str | None]:
    """
    Determine if a slide should use metaphorical image instead of icon.
    Returns: (use_metaphor, metaphor_keyword)
    
    Metaphorical images for key moments:
    - Compass: direction, strategy, navigation
    - Phoenix: rebirth, transformation, renewal
    - Door: opportunity, opening, entrance, beginning
    - Road: journey, path, progress
    - Fire: passion, energy, transformation
    - Mountain: challenge, achievement, peak
    - Bridge: connection, transition, crossing
    - Lighthouse: guidance, vision, clarity
    - Sunrise: beginning, hope, new start
    - Keys: solution, access, unlock
    """
    combined_text = (slide_title + " " + slide_content).lower()
    
    # Calculate if this slide should get a metaphor based on percentage
    # Key slides (first, last, middle) have higher priority
    is_key_slide = (slide_index == 0 or slide_index == total_slides - 1 or slide_index == total_slides // 2)
    
    # Threshold calculation: key slides more likely to get metaphors
    if is_key_slide:
        should_get_metaphor = (slide_index % max(1, int(100 / (metaphor_percentage * 1.5)))) == 0
    else:
        should_get_metaphor = (slide_index % max(1, int(100 / metaphor_percentage))) == 0
    
    if not should_get_metaphor:
        return False, None
    
    # Check for metaphorical keywords
    metaphor_map = {
        'compass': ['direction', 'strategy', 'navigate', 'path', 'way', 'course', '–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '—Å—Ç—Ä–∞—Ç–µ–≥–∏—è', '–Ω–∞–≤–∏–≥–∞—Ü–∏—è', '–ø—É—Ç—å'],
        'phoenix fire': ['rebirth', 'transformation', 'renewal', 'rise', 'resurrect', '–≤–æ–∑—Ä–æ–∂–¥–µ–Ω–∏–µ', '—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è', '–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ'],
        'open door opportunity': ['opportunity', 'opening', 'entrance', 'beginning', 'start', 'door', '–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å', '–Ω–∞—á–∞–ª–æ', '–≤—Ö–æ–¥'],
        'road journey path': ['journey', 'road', 'progress', 'ahead', 'forward', '–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ', '–¥–æ—Ä–æ–≥–∞', '–ø—Ä–æ–≥—Ä–µ—Å—Å', '–≤–ø–µ—Ä–µ–¥'],
        'bonfire flames': ['passion', 'energy', 'fire', 'burn', 'ignite', '—Å—Ç—Ä–∞—Å—Ç—å', '—ç–Ω–µ—Ä–≥–∏—è', '–æ–≥–æ–Ω—å'],
        'mountain peak summit': ['challenge', 'achievement', 'peak', 'summit', 'climb', 'overcome', '–≤—ã–∑–æ–≤', '–¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ', '–≤–µ—Ä—à–∏–Ω–∞'],
        'bridge connection': ['connection', 'bridge', 'link', 'connect', 'transition', '—Å–≤—è–∑—å', '–º–æ—Å—Ç', '–ø–µ—Ä–µ—Ö–æ–¥'],
        'lighthouse guidance': ['guidance', 'vision', 'clarity', 'light', 'beacon', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ', '–≤–∏–∑–∏—è', '—è—Å–Ω–æ—Å—Ç—å'],
        'sunrise dawn': ['beginning', 'hope', 'new', 'dawn', 'start', 'morning', '–Ω–∞—á–∞–ª–æ', '–Ω–∞–¥–µ–∂–¥–∞', '—Ä–∞—Å—Å–≤–µ—Ç'],
        'golden key solution': ['solution', 'key', 'unlock', 'access', 'answer', '—Ä–µ—à–µ–Ω–∏–µ', '–∫–ª—é—á', '–æ—Ç–≤–µ—Ç']
    }
    
    # Find matching metaphor
    for metaphor_query, keywords in metaphor_map.items():
        if any(keyword in combined_text for keyword in keywords):
            return True, metaphor_query
    
    # No specific metaphor match, but slide was selected - use generic inspiring image
    return False, None


def create_presentation(topic, slides_data, theme='light', presentation_type='business', user_id=None):
    """
    Create PowerPoint presentation with text and images.
    Now includes:
    - Quiz/self-assessment slide filtering
    - Intelligent image search based on SLIDE CONTENT (not just topic)
    - Duplicate image prevention (within presentation + user history)
    - Dynamic font sizing to prevent text overflow
    
    Args:
        topic: Presentation topic
        slides_data: List of slide dicts with 'title' and 'content'
        theme: Visual theme (light/dark)
        presentation_type: Type (business/scientific/general)
        user_id: User ID for tracking image usage (optional)
    """
    print(f"\n{'#'*60}")
    print(f"# Creating presentation: {topic}")
    print(f"# Total slides (before filtering): {len(slides_data)}")
    print(f"# Theme: {theme}")
    print(f"# Type: {presentation_type}")
    if user_id:
        print(f"# User ID: {user_id}")
    print(f"{'#'*60}\n")
    
    # Filter out quiz/self-assessment slides
    print(f"\nüì¶ FILTERING QUIZ/ASSESSMENT SLIDES...")
    slides_data, removed_slides = filter_quiz_and_assessment_slides(slides_data)
    
    if removed_slides:
        print(f"\n‚ö†Ô∏è Removed {len(removed_slides)} quiz/assessment slide(s):")
        for r in removed_slides:
            print(f"  - Slide {r['index'] + 1}: '{r['title']}' ({r['reason']})")
    
    print(f"\n‚úÖ Final slide count: {len(slides_data)} slides")
    print(f"{'='*60}\n")
    
    # Get theme configuration
    theme_config = PRESENTATION_THEMES.get(theme, PRESENTATION_THEMES['light'])
    
    # Create presentation object
    prs = Presentation()
    prs.slide_width = Inches(10)
    prs.slide_height = Inches(5.625)
    
    # ============================================================================
    # DUPLICATE IMAGE PREVENTION SYSTEM
    # ============================================================================
    # Track used images in TWO ways:
    # 1. Within this presentation (used_images set)
    # 2. Across user's history (exclude_images from database)
    
    used_images = set()  # Images used in this presentation
    exclude_images = []  # Images to exclude (from user history)
    
    if user_id:
        # Get user's recently used images to avoid duplicates
        exclude_images = get_used_images_for_user(user_id, limit=100)
        if exclude_images:
            print(f"üìä Loaded {len(exclude_images)} previously used images for user {user_id}")
            print(f"   ‚Üí Will avoid these in image search to prevent duplicates\n")
    
    for idx, slide_data in enumerate(slides_data):
        # Add a blank slide
        blank_layout = prs.slide_layouts[6]  # Blank layout
        slide = prs.slides.add_slide(blank_layout)
        
        # Set background color based on theme
        background = slide.background
        fill = background.fill
        fill.solid()
        
        is_title_slide = (idx == 0)
        is_last_slide = (idx == len(slides_data) - 1)
        
        if is_title_slide or is_last_slide:
            fill.fore_color.rgb = theme_config['title_slide_bg']
        else:
            fill.fore_color.rgb = theme_config['content_slide_bg']
        
        # Add title
        title_box = slide.shapes.add_textbox(
            Inches(0.5), Inches(0.3),
            Inches(8.5), Inches(0.8)
        )
        # Title style
        title_frame = title_box.text_frame
        title_frame.word_wrap = False  # NO line breaks - single line only
        title_frame.text = slide_data['title']
        title_para = title_frame.paragraphs[0]
        title_para.alignment = PP_ALIGN.CENTER
        title_para.font.name = 'Roboto'
        
        # Calculate optimal font size to fit title in one line
        optimal_font_size = calculate_title_font_size(
            text=slide_data['title'],
            max_width_inches=8.5,
            bold=True
        )
        
        if is_title_slide or is_last_slide:
            title_para.font.size = Pt(optimal_font_size)
            title_para.font.bold = True
            title_para.font.color.rgb = theme_config['title_color_first_last']
        else:
            title_para.font.size = Pt(optimal_font_size)
            title_para.font.bold = True
            title_para.font.color.rgb = theme_config['title_color_content']
        
        # Add accent element for content slides based on theme
        if not (is_title_slide or is_last_slide):
            try:
                slide.shapes.add_shape(
                    MSO_AUTO_SHAPE_TYPE.RECTANGLE,
                    Inches(0.3), Inches(0.3), Inches(0.1), Inches(5.0)
                ).fill.fore_color.rgb = theme_config['accent_color']
            except Exception as e:
                print(f"  ‚ö† Failed to add left bar: {e}")
        
        # ============================================================================
        # SMART IMAGE SEARCH PER SLIDE
        # ============================================================================
        # Uses slide-specific content analysis for better image matching
        # Prevents duplicates within presentation AND across user history
        
        print(f"\n[Slide {idx + 1}/{len(slides_data)}] {slide_data['title']}")
        print(f"  Content: {slide_data['content'][:60]}...")
        
        # Combine within-presentation used images + user history
        all_exclude_images = list(used_images) + exclude_images
        
        # Extract search_keyword and image_prompt from slide_data (supports both modes)
        search_keyword = slide_data.get('search_keyword', None)
        image_prompt = slide_data.get('image_prompt', None)
        
        # Route based on USE_IMAGE_PROMPT flag
        if not USE_IMAGE_PROMPT:
            # LEGACY MODE: Use search_keyword
            image_data, image_url, query_used = search_image_legacy_mode(
                slide_title=slide_data['title'],
                slide_content=slide_data.get('content', ''),
                main_topic=topic,
                exclude_images=all_exclude_images,
                presentation_type=presentation_type,
                search_keyword=search_keyword,  # LLM-generated in English
                language=None  # Auto-detect
            )
        else:
            # ADVANCED MODE: Use image_prompt
            image_data, image_url, query_used = search_image_advanced_mode(
                slide_title=slide_data['title'],
                slide_content=slide_data.get('content', ''),
                main_topic=topic,
                exclude_images=all_exclude_images,
                presentation_type=presentation_type,
                image_prompt=image_prompt,  # LLM-generated description
                language=None  # Auto-detect
            )
        
        if image_data and image_url:
            # Mark image as used in this presentation
            used_images.add(image_url)
            
            # Track in database for future duplicate prevention
            if user_id:
                add_used_image(user_id, image_url, query_used or slide_data['title'])
            
            try:
                # Add image on the right side
                slide.shapes.add_picture(
                    image_data,
                    Inches(5.5), Inches(1.3),
                    width=Inches(4),
                    height=Inches(3.5)
                )
                print(f"  ‚úÖ Image added successfully (unique, query: '{query_used}')")
            except Exception as e:
                print(f"  ‚úó Error adding image to slide: {e}")
        else:
            print(f"  ‚ö†Ô∏è Continuing without image (no suitable unique image found)")
        
        # Add content text with improved overflow handling
        content_text = slide_data['content']
        
        # For first/last slides: more aggressive length limiting to prevent overflow
        if is_title_slide or is_last_slide:
            max_chars = 350  # Shorter limit for title/conclusion slides
            if len(content_text) > max_chars:
                content_text = content_text[:max_chars] + "..."
                print(f"  ‚úÇÔ∏è Content trimmed: {len(slide_data['content'])} ‚Üí {len(content_text)} chars (title/last slide)")
        else:
            # Content slides can have more text
            if len(content_text) > 500:
                content_text = content_text[:500] + "..."
                print(f"  ‚úÇÔ∏è Content trimmed: {len(slide_data['content'])} ‚Üí {len(content_text)} chars")
        content_box = slide.shapes.add_textbox(
            Inches(0.5), Inches(1.4),
            Inches(4.8), Inches(3.6)
        )
        content_frame = content_box.text_frame
        content_frame.word_wrap = True
        content_frame.text = content_text
        
        # Format content text based on theme and slide position
        # Dynamic font size based on content length and slide type
        content_length = len(content_text)
        
        # First/last slides need smaller fonts to prevent overflow
        if is_title_slide or is_last_slide:
            if content_length > 280:
                base_font_size = 16
            elif content_length > 220:
                base_font_size = 17
            elif content_length > 160:
                base_font_size = 18
            else:
                base_font_size = 20
            print(f"  üî§ Title/Last slide font: {base_font_size}pt (length: {content_length})")
        else:
            # Content slides
            if content_length > 250:
                base_font_size = 14
            elif content_length > 180:
                base_font_size = 15
            else:
                base_font_size = 16
        
        for paragraph in content_frame.paragraphs:
            paragraph.font.name = 'Roboto'
            paragraph.font.size = Pt(base_font_size if not (is_title_slide or is_last_slide) else 20)
            if is_title_slide or is_last_slide:
                paragraph.font.color.rgb = theme_config['content_color_first_last']
            else:
                paragraph.font.color.rgb = theme_config['content_color_content']
            paragraph.space_after = Pt(10)
            paragraph.line_spacing = 1.2
        
        print(f"\n{'='*60}")
        print(f"‚úì Slide {idx + 1} created successfully")
        print(f"  Title: {slide_data['title']}")
        print(f"  Content length: {len(slide_data['content'])} characters")
        print(f"{'='*60}")
    
    # Save presentation
    filename = f"presentation_{uuid.uuid4().hex[:8]}.pptx"
    filepath = os.path.join(OUTPUT_DIR, filename)
    prs.save(filepath)
    
    # Cleanup old used images for this user (keep last 100)
    if user_id:
        cleanup_old_used_images(user_id, keep_count=100)
    
    print(f"\n{'#'*60}")
    print(f"# ‚úì Presentation created successfully!")
    print(f"# File: {filename}")
    print(f"# Location: {filepath}")
    print(f"# Unique images used: {len(used_images)}")
    if user_id:
        print(f"# Total images tracked for user: {len(exclude_images) + len(used_images)}")
    print(f"{'#'*60}\n")
    
    return filepath


@app.route('/')
def index():
    """
    Render main page
    """
    return render_template('index.html')


@app.route('/pricing')
def pricing():
    """
    Render pricing page with Stripe payment options
    """
    return render_template('pricing.html')


# ============================================================================
# STRIPE PAYMENT ROUTES
# ============================================================================

@app.route('/api/create-checkout-session', methods=['POST'])
@login_required
def create_checkout_session():
    """
    Create Stripe Checkout Session for payment
    Accepts: plan_type (one_time, subscription, pro, premium)
    Returns: sessionId and checkout URL
    """
    try:
        # Check if Stripe is configured
        if not STRIPE_SECRET_KEY:
            return jsonify({
                'error': 'Payment system not configured',
                'message': 'Stripe is not configured on the server'
            }), 500
        
        data = request.json
        plan_type = data.get('plan_type', 'one_time')
        
        # Get user email for Stripe customer
        user_email = current_user.email if hasattr(current_user, 'email') else None
        
        if not user_email:
            return jsonify({'error': 'User email not found'}), 400
        
        # Define pricing based on plan type
        # NOTE: You need to create these prices in your Stripe Dashboard
        # and replace with actual price IDs
        price_configs = {
            'one_time': {
                'mode': 'payment',
                'price_data': {
                    'currency': 'usd',
                    'unit_amount': 999,  # $9.99
                    'product_data': {
                        'name': 'AI SlideRush - Single Purchase',
                        'description': 'One-time access to create presentations',
                    },
                },
                'quantity': 1,
                'plan_name': 'one_time'
            },
            'subscription': {
                'mode': 'subscription',
                'price_data': {
                    'currency': 'usd',
                    'unit_amount': 1999,  # $19.99/month
                    'recurring': {'interval': 'month'},
                    'product_data': {
                        'name': 'AI SlideRush - Monthly Subscription',
                        'description': 'Unlimited presentations per month',
                    },
                },
                'quantity': 1,
                'plan_name': 'subscription'
            },
            'pro': {
                'mode': 'payment',
                'price_data': {
                    'currency': 'usd',
                    'unit_amount': 1999,  # $19.99
                    'product_data': {
                        'name': 'AI SlideRush - Pro Plan',
                        'description': 'Pro features with advanced customization',
                    },
                },
                'quantity': 1,
                'plan_name': 'pro'
            },
            'premium': {
                'mode': 'subscription',
                'price_data': {
                    'currency': 'usd',
                    'unit_amount': 4999,  # $49.99/month
                    'recurring': {'interval': 'month'},
                    'product_data': {
                        'name': 'AI SlideRush - Premium Subscription',
                        'description': 'Unlimited presentations with priority support',
                    },
                },
                'quantity': 1,
                'plan_name': 'premium'
            }
        }
        
        if plan_type not in price_configs:
            return jsonify({'error': f'Invalid plan type: {plan_type}'}), 400
        
        config = price_configs[plan_type]
        
        # Create Stripe Checkout Session
        try:
            checkout_session = stripe.checkout.Session.create(
                payment_method_types=['card'],
                line_items=[{
                    'price_data': config['price_data'],
                    'quantity': config['quantity'],
                }],
                mode=config['mode'],
                success_url=request.host_url + 'dashboard?payment=success',
                cancel_url=request.host_url + 'dashboard?payment=cancelled',
                customer_email=user_email,
                client_reference_id=str(current_user.id),  # Store user ID for webhook
                metadata={
                    'user_id': str(current_user.id),
                    'user_email': user_email,
                    'plan_type': config['plan_name']
                }
            )
            
            print(f"‚úÖ Stripe Checkout Session created: {checkout_session.id}")
            print(f"   ‚Üí User: {user_email} (ID: {current_user.id})")
            print(f"   ‚Üí Plan: {plan_type}")
            print(f"   ‚Üí Amount: ${config['price_data']['unit_amount'] / 100:.2f}")
            
            return jsonify({
                'success': True,
                'sessionId': checkout_session.id,
                'url': checkout_session.url,
                'plan_type': plan_type
            })
            
        except stripe.error.StripeError as e:
            print(f"‚ùå Stripe error: {e}")
            return jsonify({
                'error': 'Payment session creation failed',
                'message': str(e)
            }), 500
            
    except Exception as e:
        print(f"‚ùå Error creating checkout session: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/stripe/webhook', methods=['POST'])
def stripe_webhook():
    """
    Stripe webhook handler for payment events
    Verifies webhook signature and processes checkout.session.completed
    """
    payload = request.data
    sig_header = request.headers.get('Stripe-Signature')
    
    # Verify webhook signature (if secret is configured)
    if STRIPE_WEBHOOK_SECRET:
        try:
            event = stripe.Webhook.construct_event(
                payload, sig_header, STRIPE_WEBHOOK_SECRET
            )
            print(f"‚úÖ Webhook signature verified: {event['type']}")
        except ValueError as e:
            # Invalid payload
            print(f"‚ùå Webhook error: Invalid payload - {e}")
            return jsonify({'error': 'Invalid payload'}), 400
        except stripe.error.SignatureVerificationError as e:
            # Invalid signature
            print(f"‚ùå Webhook error: Invalid signature - {e}")
            return jsonify({'error': 'Invalid signature'}), 400
    else:
        # No signature verification (INSECURE - only for development)
        print("‚ö†Ô∏è Webhook signature verification SKIPPED (no STRIPE_WEBHOOK_SECRET)")
        try:
            event = json.loads(payload)
        except json.JSONDecodeError as e:
            print(f"‚ùå Webhook error: Invalid JSON - {e}")
            return jsonify({'error': 'Invalid JSON'}), 400
    
    # Handle the event
    event_type = event['type']
    print(f"\n{'='*60}")
    print(f"üì• Stripe Webhook Event: {event_type}")
    print(f"{'='*60}")
    
    if event_type == 'checkout.session.completed':
        session = event['data']['object']
        
        # Extract customer information
        customer_email = session.get('customer_details', {}).get('email')
        client_reference_id = session.get('client_reference_id')  # User ID
        metadata = session.get('metadata', {})
        plan_type = metadata.get('plan_type', 'one_time')
        stripe_customer_id = session.get('customer')
        
        print(f"Payment completed:")
        print(f"  ‚Üí Email: {customer_email}")
        print(f"  ‚Üí User ID: {client_reference_id}")
        print(f"  ‚Üí Plan: {plan_type}")
        print(f"  ‚Üí Customer ID: {stripe_customer_id}")
        
        # Find user in database
        user_id = None
        if client_reference_id:
            user_id = client_reference_id
        elif customer_email:
            # Fallback: find user by email
            try:
                conn = sqlite3.connect(DB_PATH)
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute('SELECT id FROM users WHERE email = ?', (customer_email,))
                user_row = cursor.fetchone()
                conn.close()
                if user_row:
                    user_id = user_row['id']
                    print(f"  ‚Üí Found user by email: ID {user_id}")
            except Exception as e:
                print(f"‚ùå Error finding user by email: {e}")
        
        if not user_id:
            print(f"‚ùå Cannot find user for payment (email: {customer_email})")
            return jsonify({'error': 'User not found'}), 400
        
        # Update user in database
        try:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            
            # Determine subscription status based on plan type
            is_subscription = plan_type in ['subscription', 'premium']
            subscription_status = 'active' if is_subscription else 'active'
            
            cursor.execute('''
                UPDATE users 
                SET status = 'active',
                    stripe_customer_id = ?,
                    subscription_plan = ?,
                    subscription_status = ?
                WHERE id = ?
            ''', (stripe_customer_id, plan_type, subscription_status, user_id))
            
            conn.commit()
            affected_rows = cursor.rowcount
            conn.close()
            
            if affected_rows > 0:
                print(f"‚úÖ User {user_id} updated successfully:")
                print(f"   ‚Üí Status: active")
                print(f"   ‚Üí Plan: {plan_type}")
                print(f"   ‚Üí Subscription status: {subscription_status}")
                print(f"   ‚Üí Stripe customer: {stripe_customer_id}")
            else:
                print(f"‚ö†Ô∏è No user updated (user_id={user_id} not found)")
                
        except Exception as e:
            print(f"‚ùå Error updating user after payment: {e}")
            return jsonify({'error': 'Database update failed'}), 500
    
    elif event_type == 'customer.subscription.deleted':
        # Handle subscription cancellation
        subscription = event['data']['object']
        stripe_customer_id = subscription.get('customer')
        
        print(f"Subscription cancelled for customer: {stripe_customer_id}")
        
        try:
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            cursor.execute('''
                UPDATE users 
                SET subscription_status = 'cancelled',
                    subscription_plan = 'free'
                WHERE stripe_customer_id = ?
            ''', (stripe_customer_id,))
            conn.commit()
            conn.close()
            print(f"‚úÖ User subscription status updated to cancelled")
        except Exception as e:
            print(f"‚ùå Error updating subscription status: {e}")
    
    elif event_type == 'invoice.payment_failed':
        # Handle failed payment
        invoice = event['data']['object']
        stripe_customer_id = invoice.get('customer')
        
        print(f"‚ö†Ô∏è Payment failed for customer: {stripe_customer_id}")
        
        # Optionally update user status
        # (you might want to give them a grace period before blocking)
    
    else:
        print(f"‚ÑπÔ∏è Unhandled event type: {event_type}")
    
    print(f"{'='*60}\n")
    
    return jsonify({'success': True}), 200


@app.route('/api/create-presentation', methods=['POST'])
def create_presentation_api():
    """
    API endpoint to create presentation
    Now includes payment status verification
    """
    try:
        # ====================================================================
        # üß† MANDATORY CLIP STATUS CHECK BEFORE GENERATION
        # ====================================================================
        print("\n" + "="*70)
        print("üß† CLIP STATUS PRE-FLIGHT CHECK")
        print("="*70)
        
        if not CLIP_AVAILABLE:
            print("‚ùå CRITICAL: CLIP not available - cannot generate presentation")
            print("   This should never happen if server started correctly!")
            print("="*70 + "\n")
            return jsonify({
                'error': 'CLIP service unavailable',
                'message': 'Image matching service is not available. Please contact administrator.',
                'clip_status': 'unavailable'
            }), 500
        
        # Verify CLIP model is actually loaded
        from services import clip_client
        if clip_client._clip_model is None:
            print("‚ùå CRITICAL: CLIP model is None - system in invalid state")
            print("="*70 + "\n")
            return jsonify({
                'error': 'CLIP model not loaded',
                'message': 'Image matching service failed to initialize. Please restart server.',
                'clip_status': 'not_loaded'
            }), 500
        
        print("‚úÖ CLIP Status: READY")
        print(f"   ‚Üí Model: {clip_client._clip_model.__class__.__name__}")
        print(f"   ‚Üí Device: {clip_client._device}")
        print(f"   ‚Üí Cache size: {len(clip_client._image_embedding_cache)}")
        print("="*70 + "\n")
        
        # ====================================================================
        # Continue with normal request processing
        # ====================================================================
        data = request.json
        topic = data.get('topic', '').strip()
        num_slides = data.get('num_slides', 5)
        language = data.get('language', 'en')  # Get language from frontend
        theme = data.get('theme', 'light')  # Get theme from frontend
        presentation_type = data.get('presentation_type', 'business')  # Get presentation type
        
        # Validation
        if not topic:
            return jsonify({'error': 'Topic is required'}), 400
        
        # ============================================================================
        # FREE CREDITS & PAYMENT VERIFICATION
        # ============================================================================
        # Order of checks:
        # 1. Check if payments are enabled (dev mode bypass)
        # 2. Block if user is 'blocked'
        # 3. Allow if user has free_credits > 0 (no Stripe check needed)
        # 4. Only check Stripe if free_credits == 0
        
        # DEV MODE: Skip all payment checks if PAYMENTS_ENABLED=false
        if not PAYMENTS_ENABLED:
            print(f"[DEV] ‚ö†Ô∏è Payments disabled, skipping payment check for user {current_user.id if current_user.is_authenticated else 'anonymous'}")
            request.using_free_credit = False  # Not using credit in dev mode
        elif current_user.is_authenticated:
            try:
                conn = sqlite3.connect(DB_PATH)
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute(
                    'SELECT status, subscription_plan, subscription_status, free_credits FROM users WHERE id = ?',
                    (current_user.id,)
                )
                user_row = cursor.fetchone()
                conn.close()
                
                if user_row:
                    # ========================================
                    # STEP 1: Check if user is blocked
                    # ========================================
                    if user_row['status'] == 'blocked':
                        print(f"‚õî User {current_user.id} is BLOCKED - cannot create presentations")
                        return jsonify({
                            'error': 'Account blocked',
                            'message': 'Your account has been blocked. Please contact support.',
                            'requires_payment': False
                        }), 403
                    
                    # ========================================
                    # STEP 2: Handle free_credits (backward compatibility)
                    # ========================================
                    free_credits = user_row['free_credits']
                    
                    # Backward compatibility: if free_credits is NULL for existing users, initialize to 3
                    if free_credits is None:
                        print(f"üîÑ User {current_user.id} has NULL free_credits - initializing to 3")
                        try:
                            conn = sqlite3.connect(DB_PATH)
                            cursor = conn.cursor()
                            cursor.execute('UPDATE users SET free_credits = 3 WHERE id = ?', (current_user.id,))
                            conn.commit()
                            conn.close()
                            free_credits = 3
                            print(f"   ‚Üí Initialized free_credits = 3 for user {current_user.id}")
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error initializing free_credits: {e}")
                            free_credits = 0  # Fallback to 0 if update fails
                    
                    # ========================================
                    # STEP 3: Check free credits first (bypass Stripe)
                    # ========================================
                    if free_credits > 0:
                        print(f"üéÅ User {current_user.id} using FREE CREDIT ({free_credits} remaining)")
                        print(f"   ‚Üí Bypassing Stripe payment verification")
                        # Will decrement free_credits after successful presentation creation
                        # Store in session/variable to decrement later
                        request.using_free_credit = True
                    
                    # ========================================
                    # STEP 4: Only check Stripe if NO free credits
                    # ========================================
                    else:
                        print(f"üí≥ User {current_user.id} has 0 free credits - checking Stripe subscription")
                        subscription_status = user_row['subscription_status'] or 'inactive'
                        subscription_plan = user_row['subscription_plan'] or 'free'
                        
                        # Allow if: subscription_status='active' OR subscription_plan != 'free'
                        has_valid_subscription = (subscription_status == 'active') or (subscription_plan != 'free')
                        
                        if not has_valid_subscription:
                            print(f"‚õî User {current_user.id} requires payment:")
                            print(f"   ‚Üí Plan: {subscription_plan}")
                            print(f"   ‚Üí Status: {subscription_status}")
                            print(f"   ‚Üí Free credits: {free_credits}")
                            return jsonify({
                                'error': 'Payment required',
                                'message': 'You have used all 3 free presentations. Please upgrade your plan to continue.',
                                'requires_payment': True,
                                'current_plan': subscription_plan,
                                'free_credits_remaining': 0
                            }), 403
                        
                        print(f"‚úÖ User {current_user.id} has valid subscription - plan: {subscription_plan}, status: {subscription_status}")
                        request.using_free_credit = False
                        
            except Exception as e:
                print(f"‚ö†Ô∏è Error checking user payment status: {e}")
                # Continue anyway for backward compatibility
                request.using_free_credit = False
        
        # Normalize slides count to 5-10 range (enforced for 3 types)
        try:
            num_slides = int(num_slides)
        except (ValueError, TypeError):
            num_slides = 7  # Default to middle of range
        if num_slides < 5 or num_slides > 10:
            num_slides = max(5, min(10, num_slides))  # Clamp to 5-10
        
        # Check API keys
        if not OPENAI_API_KEY:
            return jsonify({'error': 'OpenAI API key not configured'}), 500
        
        if not PEXELS_API_KEY:
            return jsonify({'error': 'Pexels API key not configured'}), 500
        
        # Generate slide content in the selected language
        print(f"Generating content for topic: {topic}, slides: {num_slides}, language: {language}, type: {presentation_type}")
        slides_data = generate_slide_content_in_language(topic, num_slides, language, presentation_type)
        
        if not slides_data:
            # Use fallback slides in the selected language
            print("Using fallback slides in selected language")
            slides_data = create_fallback_slides(topic, num_slides, language)
            if not slides_data:
                return jsonify({'error': 'Failed to generate slide content'}), 502
        
        # Ensure we have the right number of slides
        slides_data = slides_data[:num_slides]
        
        # Create presentation with the selected theme and presentation type
        # Pass user_id for image duplicate tracking
        print("Creating presentation with theme:", theme, "type:", presentation_type)
        user_id_for_images = current_user.id if current_user.is_authenticated else None
        filepath = create_presentation(topic, slides_data, theme, presentation_type, user_id=user_id_for_images)
        filename = os.path.basename(filepath)
        
        # Save presentation to database if user is authenticated (already verified above)
        if current_user.is_authenticated:
            try:
                conn = sqlite3.connect(DB_PATH)
                cursor = conn.cursor()
                cursor.execute(
                    '''INSERT INTO presentations (user_id, topic, num_slides, filename, presentation_type) 
                       VALUES (?, ?, ?, ?, ?)''',
                    (current_user.id, topic, num_slides, filename, presentation_type)
                )
                conn.commit()
                print(f"‚úÖ Presentation saved to database for user {current_user.id}")
                
                # ========================================
                # DECREMENT FREE CREDITS if used
                # ========================================
                if hasattr(request, 'using_free_credit') and request.using_free_credit:
                    cursor.execute(
                        'UPDATE users SET free_credits = free_credits - 1 WHERE id = ?',
                        (current_user.id,)
                    )
                    conn.commit()
                    
                    # Get updated credits count
                    cursor.execute('SELECT free_credits FROM users WHERE id = ?', (current_user.id,))
                    updated_row = cursor.fetchone()
                    credits_remaining = updated_row[0] if updated_row else 0
                    
                    print(f"üéÅ FREE CREDIT USED - User {current_user.id} now has {credits_remaining} free presentations remaining")
                    if credits_remaining == 0:
                        print(f"   ‚ö†Ô∏è User has exhausted free credits - next presentation will require payment")
                
                conn.close()
            except Exception as e:
                print(f"‚ö†Ô∏è Error saving presentation to database: {e}")
        
        return jsonify({
            'success': True,
            'filename': filename,
            'slides': slides_data,
            'presentation_type': presentation_type
        })
        
    except Exception as e:
        print(f"Error in create_presentation_api: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/download/<filename>')
def download_presentation(filename):
    """
    Download generated presentation
    Security: Prevent path traversal attacks
    """
    try:
        # Security: Normalize path and prevent directory traversal
        filename = os.path.basename(filename)  # Remove any path components
        if '..' in filename or '/' in filename or '\\' in filename:
            return jsonify({'error': 'Invalid filename'}), 400
        
        filepath = os.path.join(OUTPUT_DIR, filename)
        
        # Security: Ensure file is within OUTPUT_DIR
        if not os.path.abspath(filepath).startswith(os.path.abspath(OUTPUT_DIR)):
            return jsonify({'error': 'Access denied'}), 403
        
        if not os.path.exists(filepath):
            return jsonify({'error': 'File not found'}), 404
        
        return send_file(
            filepath,
            as_attachment=True,
            download_name=filename,
            mimetype='application/vnd.openxmlformats-officedocument.presentationml.presentation'
        )
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/presentation-types', methods=['GET'])
def get_presentation_types():
    """
    API endpoint to get all available presentation types
    """
    return jsonify({
        'success': True,
        'types': PRESENTATION_TYPES
    })


@app.route('/health', methods=['GET'])
@app.route('/api/health', methods=['GET'])
def health_check():
    """
    Health check endpoint for Railway deployment monitoring.
    Returns service status and configuration info.
    """
    import sys
    
    health_data = {
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'environment': 'railway' if IS_RAILWAY else 'local',
        'python_version': f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
        'services': {
            'clip': 'enabled' if CLIP_AVAILABLE else 'disabled',
            'openai': 'configured' if OPENAI_API_KEY else 'missing',
            'pexels': 'configured' if PEXELS_API_KEY else 'missing',
            'firebase': 'configured' if os.getenv('FIREBASE_CREDENTIALS') else 'missing',
            'stripe': 'configured' if STRIPE_SECRET_KEY else 'missing'
        },
        'features': {
            'image_search': 'clip+keyword' if CLIP_AVAILABLE else 'keyword-only',
            'translation': TRANSLATION_ENABLED,
            'payments': PAYMENTS_ENABLED
        }
    }
    
    return jsonify(health_data), 200


@app.route('/api/test-clip', methods=['GET'])
def test_clip():
    """
    üß™ EMERGENCY DIAGNOSTIC: Test endpoint for CLIP performance.
    Tests image search with CLIP matching for a given text query.
    
    TARGET: <5 seconds response time for single query
    GOAL: <60 seconds for full presentation (10-15 slides)
    
    Query params:
        text: Search text (default: "banana plantain")
    
    Returns:
        JSON with comprehensive timing and diagnostic information
    """
    
    # Get query parameter
    text_query = request.args.get('text', 'banana plantain')
    
    print(f"\n{'='*70}")
    print(f"üß™ CLIP PERFORMANCE TEST - EMERGENCY DIAGNOSTIC")
    print(f"{'='*70}")
    print(f"üîç Query: '{text_query}'")
    print(f"üéØ Target: <5 seconds for single test")
    
    overall_start = time.perf_counter()
    
    try:
        # DIAGNOSTIC 1: Check CLIP status
        print(f"\nüîß STEP 1: CLIP Status Check")
        step1_start = time.perf_counter()
        
        print(f"   ‚Üí CLIP_ENABLED: {CLIP_ENABLED}")
        print(f"   ‚Üí CLIP_AVAILABLE: {CLIP_AVAILABLE}")
        print(f"   ‚Üí CLIP_IMPORT_SUCCESS: {CLIP_IMPORT_SUCCESS}")
        
        # Import clip_client for detailed checks
        from services import clip_client
        
        if not CLIP_AVAILABLE:
            error_msg = "CLIP NOT AVAILABLE - Server should have failed to start!"
            print(f"\n‚ùå {error_msg}")
            print(f"   This is a CRITICAL ERROR - server should not be running!")
            return jsonify({
                'success': False,
                'error': error_msg,
                'elapsed_ms': (time.perf_counter() - overall_start) * 1000,
                'diagnostics': {
                    'clip_enabled': CLIP_ENABLED,
                    'clip_available': CLIP_AVAILABLE,
                    'clip_import_success': CLIP_IMPORT_SUCCESS,
                    'clip_model_loaded': clip_client._clip_model is not None
                }
            }), 500
        
        # Verify model is actually loaded
        if clip_client._clip_model is None:
            error_msg = "CLIP model is None - system in invalid state"
            print(f"\n‚ùå {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg,
                'elapsed_ms': (time.perf_counter() - overall_start) * 1000,
                'diagnostics': {
                    'clip_available': CLIP_AVAILABLE,
                    'clip_model_loaded': False
                }
            }), 500
        
        step1_time = (time.perf_counter() - step1_start) * 1000
        print(f"   ‚úÖ CLIP is available and ready")
        print(f"   ‚è±Ô∏è  Time: {step1_time:.1f}ms")
        
        # DIAGNOSTIC 2: Fetch image candidates
        print(f"\nüì∏ STEP 2: Fetching Image Candidates (max 6)")
        step2_start = time.perf_counter()
        
        candidates = get_images(text_query, count=6)
        
        step2_time = (time.perf_counter() - step2_start) * 1000
        print(f"   ‚Üí Found: {len(candidates) if candidates else 0} images")
        print(f"   ‚è±Ô∏è  Time: {step2_time:.1f}ms")
        
        if not candidates:
            error_msg = f"No image candidates found for query: '{text_query}'"
            print(f"\n‚ùå {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg,
                'elapsed_ms': (time.perf_counter() - overall_start) * 1000,
                'timing': {
                    'clip_check_ms': step1_time,
                    'fetch_candidates_ms': step2_time
                }
            }), 404
        
        # DIAGNOSTIC 3: Prepare candidates for CLIP
        print(f"\nüõ†Ô∏è  STEP 3: Preparing Candidates")
        step3_start = time.perf_counter()
        
        for i, candidate in enumerate(candidates):
            if 'description' not in candidate:
                candidate['description'] = (
                    candidate.get('attribution', '') or 
                    candidate.get('author', '') or 
                    text_query
                )
            print(f"   [{i+1}] {candidate.get('description', 'No description')[:40]}")
        
        step3_time = (time.perf_counter() - step3_start) * 1000
        print(f"   ‚è±Ô∏è  Time: {step3_time:.1f}ms")
        
        # DIAGNOSTIC 4: Run CLIP matching (THE CRITICAL STEP)
        print(f"\nü§ñ STEP 4: CLIP SEMANTIC MATCHING (CRITICAL)")
        step4_start = time.perf_counter()
        
        best_image = clip_pick_best_image(
            slide_title=text_query,
            slide_content=f"Testing CLIP performance for query: {text_query}",
            image_candidates=candidates,
            exclude_images=[],
            similarity_threshold=0.0  # Soft mode for testing
        )
        
        step4_time = (time.perf_counter() - step4_start) * 1000
        print(f"\n   ‚è±Ô∏è  CLIP Time: {step4_time:.1f}ms ({step4_time/1000:.2f}s)")
        
        # Calculate total elapsed time
        total_elapsed = time.perf_counter() - overall_start
        total_ms = total_elapsed * 1000
        
        # Determine performance status
        if total_elapsed < 5.0:
            status = '‚úÖ EXCELLENT'
            performance_level = 'excellent'
            status_emoji = 'üéâ'
        elif total_elapsed < 10.0:
            status = '‚úì GOOD'
            performance_level = 'good'
            status_emoji = 'üëç'
        else:
            status = '‚ö†Ô∏è SLOW'
            performance_level = 'slow'
            status_emoji = 'üê¢'
        
        print(f"\n{'='*70}")
        print(f"{status_emoji} PERFORMANCE RESULTS: {status}")
        print(f"{'='*70}")
        print(f"‚è±Ô∏è  Total time: {total_ms:.1f}ms ({total_elapsed:.2f}s)")
        print(f"üéØ Target: <5000ms (5s)")
        print(f"{'‚úÖ MEETS TARGET' if total_elapsed < 5.0 else '‚ùå EXCEEDS TARGET'}")
        print(f"\nüìà Breakdown:")
        print(f"   1. CLIP status check:    {step1_time:7.1f}ms")
        print(f"   2. Fetch candidates:     {step2_time:7.1f}ms")
        print(f"   3. Prepare data:         {step3_time:7.1f}ms")
        print(f"   4. CLIP matching:        {step4_time:7.1f}ms  ‚≠ê CRITICAL")
        print(f"   {'‚îÄ'*40}")
        print(f"   TOTAL:                   {total_ms:7.1f}ms")
        print(f"\nüí° Estimated full presentation (15 slides):")
        estimated_full = (total_elapsed * 15)
        print(f"   {estimated_full:.1f}s ({estimated_full/60:.1f} min)")
        print(f"   {'‚úÖ Under 60s target' if estimated_full < 60 else '‚ùå Over 60s target'}")
        print(f"{'='*70}\n")
        
        # Return detailed results
        result = {
            'success': True,
            'query': text_query,
            'performance': performance_level,
            'status': status,
            'elapsed_ms': round(total_ms, 1),
            'elapsed_sec': round(total_elapsed, 2),
            'target_sec': 5.0,
            'meets_target': total_elapsed < 5.0,
            'estimated_full_presentation': {
                'slides': 15,
                'estimated_sec': round(estimated_full, 1),
                'estimated_min': round(estimated_full / 60, 2),
                'meets_60s_target': estimated_full < 60
            },
            'timing': {
                'step1_clip_check_ms': round(step1_time, 1),
                'step2_fetch_candidates_ms': round(step2_time, 1),
                'step3_prepare_data_ms': round(step3_time, 1),
                'step4_clip_matching_ms': round(step4_time, 1),
                'total_ms': round(total_ms, 1)
            },
            'candidates': {
                'count': len(candidates),
                'max_allowed': 6,
                'optimized': True
            },
            'diagnostics': {
                'clip_enabled': CLIP_ENABLED,
                'clip_available': CLIP_AVAILABLE,
                'clip_import_success': CLIP_IMPORT_SUCCESS,
                'use_strict_filter': USE_STRICT_CLIP_FILTER,
                'similarity_threshold': CLIP_SIMILARITY_THRESHOLD
            }
        }
        
        if best_image:
            result['best_match'] = {
                'url': best_image.get('url', '')[:100],
                'similarity': best_image.get('_clip_similarity', 'N/A'),
                'source': best_image.get('source', 'Unknown'),
                'description': best_image.get('description', '')[:60]
            }
            print(f"‚úÖ Best match found: {result['best_match']['description']}")
            print(f"   Similarity: {result['best_match']['similarity']}")
        else:
            print("‚ö†Ô∏è No best match returned (check CLIP logs above)")
        
        return jsonify(result)
        
    except Exception as e:
        total_elapsed = time.perf_counter() - overall_start
        error_type = type(e).__name__
        
        print(f"\n‚ùå TEST FAILED: {error_type}")
        print(f"{'='*70}")
        print(f"Error: {e}")
        import traceback
        print("\nüìã Full traceback:")
        traceback.print_exc()
        print(f"{'='*70}\n")
        
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': error_type,
            'elapsed_ms': total_elapsed * 1000,
            'diagnostics': {
                'clip_enabled': CLIP_ENABLED,
                'clip_available': CLIP_AVAILABLE
            }
        }), 500


# Admin routes
@app.route('/admin')
@login_required
def admin_dashboard():
    """Admin dashboard - only accessible to authenticated admins"""
    if not is_admin():
        flash('Access denied. Administrator privileges required.', 'error')
        return redirect(url_for('admin_login'))
    return render_template('admin/dashboard.html')

@app.route('/admin/users', methods=['GET', 'POST'])
@login_required
def admin_users():
    """Admin users management page - only accessible to authenticated admins"""
    if not is_admin():
        flash('Access denied. Administrator privileges required.', 'error')
        return redirect(url_for('admin_login'))
    
    # Handle POST requests for user actions
    if request.method == 'POST':
        action = request.form.get('action')
        user_id = request.form.get('user_id')
        
        if action == 'delete_user' and user_id:
            # Delete user
            if delete_user(user_id):
                flash('‚úÖ User deleted successfully.', 'success')
            else:
                flash('‚ùå Error: Failed to delete user. Please try again.', 'error')
        elif action == 'update_status' and user_id:
            # Update user status
            status = request.form.get('status')
            if status in ['active', 'blocked']:
                if update_user_status(user_id, status):
                    status_text = 'activated' if status == 'active' else 'blocked'
                    flash(f'‚úÖ User status updated: {status_text}.', 'success')
                else:
                    flash('‚ùå Error: Failed to update user status.', 'error')
            else:
                flash('‚ùå Invalid status value.', 'error')
        
        # Preserve search and pagination parameters
        search = request.args.get('search', '')
        page = request.args.get('page', 1, type=int)
        return redirect(url_for('admin_users', search=search, page=page))
    
    # GET request - display users with pagination and search
    search_query = request.args.get('search', '').strip()
    page = request.args.get('page', 1, type=int)
    per_page = 15  # Users per page
    
    # Get filtered users
    all_users = get_all_users()
    
    # Apply search filter
    if search_query:
        filtered_users = [
            user for user in all_users
            if search_query.lower() in user['email'].lower() or 
               search_query.lower() in user['status'].lower()
        ]
    else:
        filtered_users = all_users
    
    # Calculate pagination
    total_users = len(filtered_users)
    total_pages = max(1, (total_users + per_page - 1) // per_page)
    page = max(1, min(page, total_pages))  # Ensure page is in valid range
    
    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page
    paginated_users = filtered_users[start_idx:end_idx]
    
    return render_template(
        'admin/users.html',
        users=paginated_users,
        total_users=total_users,
        page=page,
        total_pages=total_pages,
        per_page=per_page,
        search_query=search_query
    )

# Firebase Authentication routes
@app.route('/auth/firebase/', methods=['POST'])
def firebase_auth_route():
    """Handle Firebase authentication"""
    try:
        data = request.get_json()
        id_token = data.get('token')
        
        if not id_token:
            return jsonify({'error': 'Token is required'}), 400
        
        # Verify Firebase ID token
        try:
            decoded_token = firebase_auth.verify_id_token(id_token)
        except Exception as e:
            print(f"Firebase token verification error: {e}")
            return jsonify({'error': 'Invalid token'}), 401
        
        firebase_uid = decoded_token['uid']
        email = decoded_token.get('email')
        name = decoded_token.get('name', '')
        picture = decoded_token.get('picture', '')
        
        if not email:
            return jsonify({'error': 'Email not found in token'}), 400
        
        # Get or create user
        user_data, error = get_or_create_firebase_user(firebase_uid, email, name, picture)
        if error:
            return jsonify({'error': error}), 500
        
        if user_data['status'] == 'blocked':
            return jsonify({'error': 'Your account has been blocked. Please contact support.'}), 403
        
        # Login user
        user = User(
            user_data['id'],
            email=user_data['email'],
            is_admin_user=False,
            name=user_data.get('name'),
            picture=user_data.get('picture')
        )
        login_user(user, remember=True)
        
        return jsonify({
            'success': True,
            'message': 'Logged in successfully',
            'redirect': url_for('user_dashboard')
        })
        
    except Exception as e:
        print(f"Firebase auth error: {e}")
        return jsonify({'error': 'Authentication failed'}), 500

# User authentication routes
@app.route('/signup', methods=['GET', 'POST'])
def signup():
    """User registration page"""
    if current_user.is_authenticated:
        # If already logged in, redirect to dashboard
        if hasattr(current_user, 'is_admin_user') and current_user.is_admin_user:
            return redirect(url_for('admin_dashboard'))
        return redirect(url_for('user_dashboard'))
    
    if request.method == 'POST':
        email = request.form.get('email', '').strip().lower()
        password = request.form.get('password', '')
        password_confirm = request.form.get('password_confirm', '')
        
        # Validate email
        is_valid_email, email_error = validate_email(email)
        if not is_valid_email:
            flash(f'‚ùå {email_error}', 'error')
            return render_template('signup.html')
        
        # Validate password
        is_valid_password, password_error = validate_password(password)
        if not is_valid_password:
            flash(f'‚ùå {password_error}', 'error')
            return render_template('signup.html')
        
        # Check password confirmation
        if password != password_confirm:
            flash('‚ùå Passwords do not match', 'error')
            return render_template('signup.html')
        
        # Create user
        user_id, error = create_user(email, password)
        if error:
            flash(f'‚ùå {error}', 'error')
            return render_template('signup.html')
        
        # Auto-login after registration
        user_data = get_user_by_id(user_id)
        if user_data:
            user = User(
                user_data['id'], 
                email=user_data['email'], 
                is_admin_user=False,
                name=user_data.get('name'),
                picture=user_data.get('picture')
            )
            login_user(user)
            flash('‚úÖ Account created successfully! Welcome to AI SlideRush!', 'success')
            return redirect(url_for('user_dashboard'))
    
    return render_template('signup.html')

@app.route('/login', methods=['GET', 'POST'])
def login():
    """User login page"""
    if current_user.is_authenticated:
        # If already logged in, redirect to appropriate dashboard
        if hasattr(current_user, 'is_admin_user') and current_user.is_admin_user:
            return redirect(url_for('admin_dashboard'))
        return redirect(url_for('user_dashboard'))
    
    if request.method == 'POST':
        email = request.form.get('email', '').strip().lower()
        password = request.form.get('password', '')
        
        if not email or not password:
            flash('‚ùå Please enter both email and password', 'error')
            return render_template('login.html')
        
        # Authenticate user
        user_data, error = authenticate_user(email, password)
        if error:
            flash(f'‚ùå {error}', 'error')
            return render_template('login.html')
        
        # Login user
        user = User(
            user_data['id'], 
            email=user_data['email'], 
            is_admin_user=False,
            name=user_data.get('name'),
            picture=user_data.get('picture')
        )
        login_user(user, remember=True)
        flash('‚úÖ Logged in successfully!', 'success')
        
        # Redirect to next page or dashboard
        next_page = request.args.get('next')
        if next_page:
            return redirect(next_page)
        return redirect(url_for('user_dashboard'))
    
    return render_template('login.html')

@app.route('/logout')
@login_required
def logout():
    """User logout"""
    logout_user()
    flash('‚úÖ You have been logged out successfully.', 'success')
    return redirect(url_for('index'))

@app.route('/dashboard')
@login_required
def user_dashboard():
    """User dashboard - personal cabinet"""
    # Redirect admins to admin dashboard
    if hasattr(current_user, 'is_admin_user') and current_user.is_admin_user:
        return redirect(url_for('admin_dashboard'))
    
    # Verify user status (prevent blocked users from accessing dashboard)
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute('SELECT status FROM users WHERE id = ?', (current_user.id,))
        user_row = cursor.fetchone()
        conn.close()
        
        if user_row and user_row['status'] == 'blocked':
            logout_user()
            flash('‚ùå Your account has been blocked. Please contact support.', 'error')
            return redirect(url_for('index'))
    except Exception as e:
        print(f"Error checking user status: {e}")
    
    # Get search, filter and pagination parameters
    search_query = request.args.get('search', '').strip()
    filter_type = request.args.get('type', '').strip()  # Filter by presentation type
    page = request.args.get('page', 1, type=int)
    per_page = 15
    
    # Get user's presentations
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # Get total count for stats
        cursor.execute(
            'SELECT COUNT(*) as count FROM presentations WHERE user_id = ?',
            (current_user.id,)
        )
        total_presentations = cursor.fetchone()['count']
        
        # Build query with search and type filter
        query = 'SELECT * FROM presentations WHERE user_id = ?'
        params = [current_user.id]
        
        if search_query:
            query += ' AND topic LIKE ?'
            params.append(f'%{search_query}%')
        
        if filter_type and filter_type in PRESENTATION_TYPES:
            query += ' AND presentation_type = ?'
            params.append(filter_type)
        
        query += ' ORDER BY creation_date DESC'
        
        cursor.execute(query, params)
        all_presentations = [dict(row) for row in cursor.fetchall()]
        
        # Add presentation type info to each presentation
        for pres in all_presentations:
            if not pres.get('presentation_type'):
                pres['presentation_type'] = 'business'  # Default for old presentations
            pres['type_info'] = get_presentation_type_info(pres['presentation_type'])
        
        # Get user data (fixed: was calling fetchone() twice, causing user_data to always be None)
        cursor.execute('SELECT * FROM users WHERE id = ?', (current_user.id,))
        user_row = cursor.fetchone()
        user_data = dict(user_row) if user_row else None
        
        conn.close()
    except Exception as e:
        print(f"Error fetching presentations: {e}")
        all_presentations = []
        total_presentations = 0
        user_data = None
    
    # Calculate pagination
    total_filtered = len(all_presentations)
    total_pages = max(1, (total_filtered + per_page - 1) // per_page)
    page = max(1, min(page, total_pages))
    
    start_idx = (page - 1) * per_page
    end_idx = start_idx + per_page
    paginated_presentations = all_presentations[start_idx:end_idx]
    
    return render_template(
        'dashboard.html',
        presentations=paginated_presentations,
        total_presentations=total_presentations,
        user_data=user_data,
        page=page,
        total_pages=total_pages,
        search_query=search_query,
        filter_type=filter_type,
        presentation_types=PRESENTATION_TYPES
    )

@app.route('/presentation/delete', methods=['POST'])
@login_required
def delete_presentation():
    """Delete user's presentation"""
    # Redirect admins
    if hasattr(current_user, 'is_admin_user') and current_user.is_admin_user:
        flash('‚ùå Admins cannot delete presentations from user dashboard', 'error')
        return redirect(url_for('admin_dashboard'))
    
    presentation_id = request.form.get('presentation_id')
    if not presentation_id:
        flash('‚ùå Invalid request', 'error')
        return redirect(url_for('user_dashboard'))
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # Verify ownership
        cursor.execute(
            'SELECT * FROM presentations WHERE id = ? AND user_id = ?',
            (presentation_id, current_user.id)
        )
        presentation = cursor.fetchone()
        
        if not presentation:
            conn.close()
            flash('‚ùå Presentation not found or access denied', 'error')
            return redirect(url_for('user_dashboard'))
        
        # Delete presentation
        cursor.execute('DELETE FROM presentations WHERE id = ?', (presentation_id,))
        conn.commit()
        conn.close()
        
        flash('‚úÖ Presentation deleted successfully', 'success')
    except Exception as e:
        print(f"Error deleting presentation: {e}")
        flash('‚ùå Error deleting presentation', 'error')
    
    # Preserve search and pagination
    search = request.form.get('search', '')
    page = request.form.get('page', 1, type=int)
    
    return redirect(url_for('user_dashboard', search=search, page=page))

@app.route('/profile/edit', methods=['GET', 'POST'])
@login_required
def edit_profile():
    """Edit user profile"""
    # Redirect admins
    if hasattr(current_user, 'is_admin_user') and current_user.is_admin_user:
        flash('‚ùå Admins cannot edit profile from user dashboard', 'error')
        return redirect(url_for('admin_dashboard'))
    
    # Get user data
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM users WHERE id = ?', (current_user.id,))
        user_data = dict(cursor.fetchone())
        conn.close()
    except Exception as e:
        print(f"Error fetching user data: {e}")
        user_data = None
    
    if request.method == 'POST':
        # Only allow password change for non-Google users
        if user_data and not user_data.get('google_id'):
            current_password = request.form.get('current_password', '')
            new_password = request.form.get('new_password', '')
            confirm_password = request.form.get('confirm_password', '')
            
            if current_password or new_password or confirm_password:
                # Validate current password
                if not current_password:
                    flash('‚ùå Please enter your current password', 'error')
                    return render_template('profile_edit.html', user_data=user_data)
                
                # Verify current password
                if not check_password_hash(user_data['password_hash'], current_password):
                    flash('‚ùå Current password is incorrect', 'error')
                    return render_template('profile_edit.html', user_data=user_data)
                
                # Validate new password
                is_valid, error_msg = validate_password(new_password)
                if not is_valid:
                    flash(f'‚ùå {error_msg}', 'error')
                    return render_template('profile_edit.html', user_data=user_data)
                
                # Check password confirmation
                if new_password != confirm_password:
                    flash('‚ùå New passwords do not match', 'error')
                    return render_template('profile_edit.html', user_data=user_data)
                
                # Update password
                try:
                    conn = sqlite3.connect(DB_PATH)
                    cursor = conn.cursor()
                    new_password_hash = generate_password_hash(new_password)
                    cursor.execute(
                        'UPDATE users SET password_hash = ? WHERE id = ?',
                        (new_password_hash, current_user.id)
                    )
                    conn.commit()
                    conn.close()
                    
                    flash('‚úÖ Password updated successfully!', 'success')
                    return redirect(url_for('user_dashboard'))
                except Exception as e:
                    print(f"Error updating password: {e}")
                    flash('‚ùå Error updating password', 'error')
        else:
            flash('‚ÑπÔ∏è No changes to save', 'error')
    
    return render_template('profile_edit.html', user_data=user_data)

@app.route('/admin/login', methods=['GET', 'POST'])
def admin_login():
    """Admin login page"""
    if request.method == 'POST':
        username = request.form['username']
        password = request.form['password']
        
        # Check if user exists and password is correct
        if username in ADMIN_USERS and check_password_hash(ADMIN_USERS[username]['password_hash'], password):
            user = User(username, is_admin_user=True)
            login_user(user)
            flash('Logged in successfully.', 'success')
            return redirect(url_for('admin_dashboard'))
        else:
            flash('Invalid username or password.', 'error')
    
    return render_template('admin/login.html')

@app.route('/admin/logout')
@login_required
def admin_logout():
    """Admin logout"""
    logout_user()
    flash('You have been logged out.', 'success')
    return redirect(url_for('admin_login'))


# Application entry point - MUST BE AT THE END OF FILE
if __name__ == '__main__':
    print("\n" + "="*60)
    print("  üé® AI SlideRush - Presentation Service")
    print("="*60)
    
    # Environment Check
    print("\nüîß CONFIGURATION CHECK:")
    print(f"   OpenAI API Key: {'‚úÖ Configured' if OPENAI_API_KEY else '‚ùå Missing'}")
    
    # Image Provider Configuration
    print("\nüñºÔ∏è IMAGE PROVIDERS:")
    print(f"   Mode: {IMAGE_PROVIDER_MODE.upper()}")
    print(f"   Pexels API: {'‚úÖ Configured' if PEXELS_API_KEY else '‚ö†Ô∏è Missing'}")
    print(f"   Unsplash API: {'‚úÖ Configured' if UNSPLASH_ACCESS_KEY else '‚ö†Ô∏è Not configured (optional)'}")
    
    if IMAGE_PROVIDER_MODE == 'mixed':
        print("   Strategy: Pexels ‚Üí Unsplash fallback")
    elif IMAGE_PROVIDER_MODE == 'pexels':
        print("   Strategy: Pexels only")
    elif IMAGE_PROVIDER_MODE == 'unsplash':
        print("   Strategy: Unsplash only")
    
    # LibreTranslate / Translation
    print("\nüåç TRANSLATION:")
    print(f"   Enabled: {TRANSLATION_ENABLED}")
    print(f"   Provider: {TRANSLATION_PROVIDER}")
    if TRANSLATION_ENABLED and TRANSLATION_PROVIDER == 'libre':
        print(f"   LibreTranslate URL: {LIBRETRANSLATE_URL}")
        print(f"   Reachable: {is_libretranslate_available()}")
    elif TRANSLATION_ENABLED and TRANSLATION_PROVIDER == 'external':
        print(f"   External URL: {EXTERNAL_TRANSLATE_URL if EXTERNAL_TRANSLATE_URL else 'Not configured'}")
    
    # Server Start
    port = int(os.environ.get("PORT", 5000))
    print("\nüöÄ STARTING SERVER:")
    print(f"   Port: {port}")
    print(f"   URL: http://localhost:{port}")
    print(f"   Debug Mode: True")
    print("\n" + "="*60)
    print("üéâ Server is ready! Press CTRL+C to stop.")
    print("="*60 + "\n")
    
    app.run(debug=True, host='0.0.0.0', port=port)
